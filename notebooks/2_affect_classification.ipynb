{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Database of Remote Affective Physiological Signals and Continuous Ratings Collected in Virtual Reality `DRAP`\n",
    "\n",
    "Check `1_preprocess...ipynb` to see details on how to use the drap scripts to generate a preprocessed dataset compatible with this notebook.\n",
    "\n",
    "This notebook takes a single postprocessed file `Dataset_DRAP_full_postprocessed.csv` to generate the statistical analysis and feature-based classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Path: e:\\dsv\\dev\\git_repos\\DRAP\\notebooks/\n"
     ]
    }
   ],
   "source": [
    "# Add files to sys.path\n",
    "from pathlib import Path\n",
    "import sys,os\n",
    "this_path = None\n",
    "try:    # WORKS WITH .py\n",
    "    this_path = str(os.path.dirname(os.path.abspath(__file__)))\n",
    "except: # WORKS WITH .ipynb\n",
    "    this_path = str(Path().absolute())+\"/\" \n",
    "print(\"File Path:\", this_path)\n",
    "\n",
    "# Add the level up to the file path so it recognizes the scripts inside `drap`\n",
    "sys.path.append(os.path.join(this_path, \"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import classes\n",
    "import drap.preprocessing       # Generate dataset index, load files, and plots.\n",
    "\n",
    "# Utils for generation of files and paths\n",
    "from drap.utils import files_handler\n",
    "\n",
    "# Import data science libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "#matplotlib.rcParams['text.usetex'] = True\n",
    "import seaborn as sns\n",
    "\n",
    "# Statistical tests\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# Preprocessing\n",
    "import neurokit2 as nk\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Feature based classification\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import Lasso, RidgeClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "# Feature selection\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.feature_selection import RFE\n",
    "# from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "# from lime import lime_tabular\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup\n",
    "\n",
    "Global variables and functions for file management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### General configuration\n",
    "\n",
    "# Path to the participants' folder w.r.t this notebook's filepath\n",
    "DATASET_ROOT_FOLDER = \"../data/\"\n",
    "\n",
    "# Used to generate the path of temporary subfolders\n",
    "NOTEBOOK_NAME = \"DRAP_2_affect\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to generate filepaths\n",
    "\n",
    "# MAIN FOLDERS FOR OUTPUT FILES\n",
    "ROOT = this_path + \"\"   # Root folder for all the files w.r.t this file\n",
    "TEMP_FOLDER = ROOT+\"temp/\"  # Main folder for temp files with intermediate calculations\n",
    "RESULTS_FOLDER = ROOT+\"results/\"    # Folder to recreate plots and results from analyses\n",
    "\n",
    "EXPORT_PLOTS = True\n",
    "IMG_FORMAT = \".pdf\"\n",
    "\n",
    "# Generates paths for files created from this script\n",
    "\n",
    "def gen_path_plot(filename):\n",
    "    # Generates full paths for PLOTS just by specifying a name\n",
    "    return files_handler.generate_complete_path(filename, \\\n",
    "                                        main_folder=RESULTS_FOLDER, \\\n",
    "                                        subfolders=NOTEBOOK_NAME+\"/plots/\", \\\n",
    "                                        file_extension=IMG_FORMAT, save_files=EXPORT_PLOTS)\n",
    "\n",
    "def gen_path_temp(filename, extension, subfolders=\"\"):\n",
    "    # Generates full paths for TEMP FILES just by specifying a name\n",
    "    return files_handler.generate_complete_path(filename, \\\n",
    "                                        main_folder=TEMP_FOLDER, \\\n",
    "                                        subfolders=NOTEBOOK_NAME+\"/\"+subfolders, \\\n",
    "                                        file_extension=extension)\n",
    "\n",
    "def gen_path_results(filename, subfolders=\"\", extension=\"\"):\n",
    "    # Generates full paths for RESULTS FILES (like pandas dataframes)\n",
    "    return files_handler.generate_complete_path(filename, \\\n",
    "                                        main_folder=RESULTS_FOLDER, \\\n",
    "                                        subfolders=NOTEBOOK_NAME+\"/\"+subfolders, \\\n",
    "                                        file_extension=extension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup of overlapping windows to extract features from time series\n",
    "SAMPLING_PERIOD_TS = 1 # seconds\n",
    "\n",
    "#### Classification methods to apply.\n",
    "DICT_CLASSIFIERS = {\n",
    "    # \"KNN\":    KNeighborsClassifier(n_neighbors=experiment_config.KNN_N_NEIGH),\n",
    "    # \"DT\":     DecisionTreeClassifier(max_depth=experiment_config.DT_MAX_DEPTH, criterion='entropy', random_state=experiment_config.MC_RANDOM_SEED),\n",
    "    # \"RF\":     RandomForestClassifier(n_estimators=experiment_config.RF_N_ESTIMATORS, max_depth=experiment_config.RF_MAX_DEPTH, criterion='entropy', random_state=experiment_config.MC_RANDOM_SEED),\n",
    "    # \"GBM\":    GradientBoostingClassifier(n_estimators=experiment_config.GBM_N_ESTIMATORS, max_depth=experiment_config.GBM_MAX_DEPTH, criterion='friedman_mse', random_state=experiment_config.MC_RANDOM_SEED)\n",
    "}\n",
    "\n",
    "## K-Fold partition\n",
    "N_SPLITS_CV = 10 # Number of folds for Cross-validation\n",
    "\n",
    "# Scoring parameters: https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "SCORING_METRICS = [\"accuracy\", \"precision_macro\", \"recall_macro\", \"f1_macro\"]\n",
    "\n",
    "\n",
    "##########################\n",
    "### CLASSIFIERS\n",
    "##########################\n",
    "\n",
    "# Classes: Which column from the demographics.csv is used as target class label\n",
    "CLASS_COLUMN_NAME = \"videoId\" #\"user\"  # \"videoId\": Tries to classify the videos. \"user\" tries to classify the people.\n",
    "\n",
    "#### FEATURE-BASED CLASSIFIERS CLASSIFIERS SETUP\n",
    "\n",
    "MC_RANDOM_SEED = 1234\n",
    "CV_NUM_FOLDS = 10\n",
    "\n",
    "# KNN\n",
    "KNN_N_NEIGH = 9\n",
    "# DT\n",
    "DT_MAX_DEPTH = 100\n",
    "# RF\n",
    "RF_N_ESTIMATORS = 100\n",
    "RF_MAX_DEPTH = 10\n",
    "# GBM\n",
    "GBM_N_ESTIMATORS = 50\n",
    "GBM_MAX_DEPTH = 5\n",
    "\n",
    "\n",
    "#### STATE-OF-THE-ART CLASSIFIERS SETUP\n",
    "\n",
    "# KNN-TS\n",
    "# KNN_TS_N_NEIGH = drapAffect.Classifiers.KNN_1\n",
    "KNN_TS_DTW_WARPING_WINDOW = 0.05\n",
    "\n",
    "# Mr-SEQL (Multivariate)\n",
    "# No params required\n",
    "\n",
    "# STSF (Univariate)\n",
    "STSF_N_ESTIMATORS = 200\n",
    "\n",
    "# TDE (Multivariate)\n",
    "TDE_MAX_TIME = 5\n",
    "TDE_MAX_ENSEMBLE_SIZE = 50\n",
    "TDE_MAX_SELECTED_PARAMS = 50\n",
    "\n",
    "# ROCKET (Multivariate)\n",
    "ROCKET_N_KERNELS = 10000\n",
    "\n",
    "# MiniRocket (Multivariate)\n",
    "MINIROCKET_N_KERNELS = 10000\n",
    "MINIROCKET_MAX_DILATIONS = 32\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Analysis 1: Validation of Subjective Self-reported Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Valence-Arousal ratings per video across all data from participants\n",
    "\n",
    "*Conclusion from statistical tests and plot:*\n",
    "- It shows how the video categories: `Negative` and `Positive` can be discriminated from the Valence component, but not from the arousal. As expected.\n",
    "- The categories in Valence may be used as ground-truth for the ML task. But not the presumed labels in Arousal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index already exists: Loading from  e:\\dsv\\dev\\git_repos\\DRAP\\notebooks/temp/drap_index/drap_tree_index.json\n",
      "Participant 0 with folder id: 101 was part of protocol: v1\n",
      "Participant 1 with folder id: 216 was part of protocol: v1\n",
      "Participant 2 with folder id: 219 was part of protocol: v1\n",
      "Participant 3 with folder id: 222 was part of protocol: v1\n",
      "Participant 4 with folder id: 247 was part of protocol: v1\n",
      "Participant 5 with folder id: 248 was part of protocol: v1\n",
      "Participant 6 with folder id: 268 was part of protocol: v1\n",
      "Participant 7 with folder id: 270 was part of protocol: v1\n",
      "Participant 8 with folder id: 278 was part of protocol: v1\n",
      "Participant 9 with folder id: 290 was part of protocol: v1\n",
      "Participant 10 with folder id: 293 was part of protocol: v1\n",
      "Participant 11 with folder id: 299 was part of protocol: v1\n",
      "Participant 12 with folder id: 307 was part of protocol: v1\n",
      "Participant 13 with folder id: 308 was part of protocol: v1\n",
      "Participant 14 with folder id: 309 was part of protocol: v1\n",
      "Participant 15 with folder id: 310 was part of protocol: v1\n",
      "Participant 16 with folder id: 312 was part of protocol: v1\n",
      "Participant 17 with folder id: 314 was part of protocol: v1\n",
      "Participant 18 with folder id: 321 was part of protocol: v1\n",
      "Participant 19 with folder id: 322 was part of protocol: v1\n",
      "Participant 20 with folder id: 330 was part of protocol: v1\n",
      "Participant 21 with folder id: 342 was part of protocol: v2\n",
      "Participant 22 with folder id: 343 was part of protocol: v2\n",
      "Participant 23 with folder id: 346 was part of protocol: v2\n",
      "Participant 24 with folder id: 348 was part of protocol: v2\n",
      "Participant 25 with folder id: 349 was part of protocol: v2\n",
      "Participant 26 with folder id: 350 was part of protocol: v2\n",
      "Participant 27 with folder id: 351 was part of protocol: v2\n",
      "Participant 28 with folder id: 355 was part of protocol: v2\n",
      "Participant 29 with folder id: 360 was part of protocol: v2\n",
      "Participant 30 with folder id: 362 was part of protocol: v2\n",
      "Participant 31 with folder id: 363 was part of protocol: v2\n",
      "Participant 32 with folder id: 365 was part of protocol: v2\n",
      "Participant 33 with folder id: 369 was part of protocol: v2\n",
      "Participant 34 with folder id: 370 was part of protocol: v2\n",
      "Participant 35 with folder id: 379 was part of protocol: v2\n",
      "Participant 36 with folder id: 381 was part of protocol: v2\n",
      "Participant 37 with folder id: 382 was part of protocol: v2\n",
      "Participant 38 with folder id: 384 was part of protocol: v1\n"
     ]
    }
   ],
   "source": [
    "# The preprocessing manager analyzes the original data folder\n",
    "# to create an index and facilitate preprocessing.\n",
    "data_loader = drap.preprocessing.Manager(DATASET_ROOT_FOLDER, index_files_path = TEMP_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total participants\n",
    "participants_ids = data_loader.summary[\"index_id\"].unique()\n",
    "participants_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['video_1', 'video_2', 'video_3', 'video_4', 'video_5'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total sessions\n",
    "experiment_segment_names = data_loader.summary[\"Segment\"].unique()\n",
    "experiment_segment_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the videoIds to each of the unaltered affective ratings\n",
    "affect_ratings_matched_video_id = None\n",
    "for participant in participants_ids:\n",
    "    this_affect_ratings_merged = pd.merge_asof(data_loader.emotions[participant], \n",
    "                                                data_loader.segments[participant].drop([\"Session\"],axis=1), # Session is duplicated\n",
    "                                                left_index=True, right_index=True, direction=\"forward\")\n",
    "    this_affect_ratings_merged.insert(0,\"p_index_id\",participant)\n",
    "    this_affect_ratings_merged.insert(1,\"participant_id\",int(data_loader.index[participant][\"participant_id\"]))\n",
    "    \n",
    "    affect_ratings_matched_video_id = this_affect_ratings_merged if (affect_ratings_matched_video_id is None) else \\\n",
    "                                        pd.concat([affect_ratings_matched_video_id,this_affect_ratings_merged], axis=0, ignore_index=True)\n",
    "\n",
    "# Show result\n",
    "MATCHED_AFFECTIVE_RATINGS_FILENAME = gen_path_temp(\"AffectiveRatingsMatchedVideoId\",extension=\".csv\")\n",
    "affect_ratings_matched_video_id.to_csv( MATCHED_AFFECTIVE_RATINGS_FILENAME, index=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "p_index_id          0\n",
       "participant_id      0\n",
       "Session             0\n",
       "Valence             0\n",
       "Arousal             0\n",
       "RawX                0\n",
       "RawY                0\n",
       "Segment            77\n",
       "VideoId           364\n",
       "Trigger            77\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "affect_ratings_matched_video_id.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rows with `VideoId=NaN` mean that an affective ratings was generated outside the valid experimental segments. Valid segments are within the 120s-long resting stage or the 300s-long videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_index_id</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>Session</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Arousal</th>\n",
       "      <th>RawX</th>\n",
       "      <th>RawY</th>\n",
       "      <th>Segment</th>\n",
       "      <th>VideoId</th>\n",
       "      <th>Trigger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>video_1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>94</td>\n",
       "      <td>124</td>\n",
       "      <td>Positive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>StartSegment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>video_2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>128</td>\n",
       "      <td>122</td>\n",
       "      <td>Positive</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>End</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>video_2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>149</td>\n",
       "      <td>127</td>\n",
       "      <td>Positive</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>End</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>video_2</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>170</td>\n",
       "      <td>127</td>\n",
       "      <td>Positive</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>End</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>video_2</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>193</td>\n",
       "      <td>126</td>\n",
       "      <td>Positive</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>End</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35707</th>\n",
       "      <td>38</td>\n",
       "      <td>384</td>\n",
       "      <td>video_5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>154</td>\n",
       "      <td>74</td>\n",
       "      <td>video_5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>End</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35708</th>\n",
       "      <td>38</td>\n",
       "      <td>384</td>\n",
       "      <td>video_5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>147</td>\n",
       "      <td>70</td>\n",
       "      <td>video_5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>End</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35709</th>\n",
       "      <td>38</td>\n",
       "      <td>384</td>\n",
       "      <td>video_5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>146</td>\n",
       "      <td>71</td>\n",
       "      <td>video_5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>End</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35710</th>\n",
       "      <td>38</td>\n",
       "      <td>384</td>\n",
       "      <td>video_5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>148</td>\n",
       "      <td>81</td>\n",
       "      <td>video_5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>End</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35711</th>\n",
       "      <td>38</td>\n",
       "      <td>384</td>\n",
       "      <td>video_5</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>150</td>\n",
       "      <td>97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35712 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       p_index_id  participant_id  Session  Valence  Arousal  RawX  RawY  \\\n",
       "0               0             101  video_1        3        5    94   124   \n",
       "1               0             101  video_2        5        5   128   122   \n",
       "2               0             101  video_2        6        5   149   127   \n",
       "3               0             101  video_2        7        5   170   127   \n",
       "4               0             101  video_2        8        5   193   126   \n",
       "...           ...             ...      ...      ...      ...   ...   ...   \n",
       "35707          38             384  video_5        6        2   154    74   \n",
       "35708          38             384  video_5        5        2   147    70   \n",
       "35709          38             384  video_5        5        3   146    71   \n",
       "35710          38             384  video_5        6        3   148    81   \n",
       "35711          38             384  video_5        6        4   150    97   \n",
       "\n",
       "        Segment  VideoId       Trigger  \n",
       "0      Positive      NaN  StartSegment  \n",
       "1      Positive     -1.0           End  \n",
       "2      Positive     -1.0           End  \n",
       "3      Positive     -1.0           End  \n",
       "4      Positive     -1.0           End  \n",
       "...         ...      ...           ...  \n",
       "35707   video_5     -1.0           End  \n",
       "35708   video_5     -1.0           End  \n",
       "35709   video_5     -1.0           End  \n",
       "35710   video_5     -1.0           End  \n",
       "35711       NaN      NaN           NaN  \n",
       "\n",
       "[35712 rows x 10 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "affect_ratings_matched_video_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_index_id</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>Session</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Arousal</th>\n",
       "      <th>RawX</th>\n",
       "      <th>RawY</th>\n",
       "      <th>Segment</th>\n",
       "      <th>VideoId</th>\n",
       "      <th>Trigger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>video_2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>128</td>\n",
       "      <td>122</td>\n",
       "      <td>Positive</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>End</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>video_2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>149</td>\n",
       "      <td>127</td>\n",
       "      <td>Positive</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>End</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>video_2</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>170</td>\n",
       "      <td>127</td>\n",
       "      <td>Positive</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>End</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>video_2</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>193</td>\n",
       "      <td>126</td>\n",
       "      <td>Positive</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>End</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>video_2</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>191</td>\n",
       "      <td>125</td>\n",
       "      <td>Positive</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>End</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35706</th>\n",
       "      <td>38</td>\n",
       "      <td>384</td>\n",
       "      <td>video_5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>155</td>\n",
       "      <td>100</td>\n",
       "      <td>video_5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>End</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35707</th>\n",
       "      <td>38</td>\n",
       "      <td>384</td>\n",
       "      <td>video_5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>154</td>\n",
       "      <td>74</td>\n",
       "      <td>video_5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>End</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35708</th>\n",
       "      <td>38</td>\n",
       "      <td>384</td>\n",
       "      <td>video_5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>147</td>\n",
       "      <td>70</td>\n",
       "      <td>video_5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>End</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35709</th>\n",
       "      <td>38</td>\n",
       "      <td>384</td>\n",
       "      <td>video_5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>146</td>\n",
       "      <td>71</td>\n",
       "      <td>video_5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>End</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35710</th>\n",
       "      <td>38</td>\n",
       "      <td>384</td>\n",
       "      <td>video_5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>148</td>\n",
       "      <td>81</td>\n",
       "      <td>video_5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>End</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35348 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       p_index_id  participant_id  Session  Valence  Arousal  RawX  RawY  \\\n",
       "1               0             101  video_2        5        5   128   122   \n",
       "2               0             101  video_2        6        5   149   127   \n",
       "3               0             101  video_2        7        5   170   127   \n",
       "4               0             101  video_2        8        5   193   126   \n",
       "5               0             101  video_2        7        5   191   125   \n",
       "...           ...             ...      ...      ...      ...   ...   ...   \n",
       "35706          38             384  video_5        6        3   155   100   \n",
       "35707          38             384  video_5        6        2   154    74   \n",
       "35708          38             384  video_5        5        2   147    70   \n",
       "35709          38             384  video_5        5        3   146    71   \n",
       "35710          38             384  video_5        6        3   148    81   \n",
       "\n",
       "        Segment  VideoId Trigger  \n",
       "1      Positive     -1.0     End  \n",
       "2      Positive     -1.0     End  \n",
       "3      Positive     -1.0     End  \n",
       "4      Positive     -1.0     End  \n",
       "5      Positive     -1.0     End  \n",
       "...         ...      ...     ...  \n",
       "35706   video_5     -1.0     End  \n",
       "35707   video_5     -1.0     End  \n",
       "35708   video_5     -1.0     End  \n",
       "35709   video_5     -1.0     End  \n",
       "35710   video_5     -1.0     End  \n",
       "\n",
       "[35348 rows x 10 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "affect_ratings_matched_video_id.dropna(axis=0, subset=[\"VideoId\"], inplace=True)\n",
    "affect_ratings_matched_video_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_index_id</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>Session</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Arousal</th>\n",
       "      <th>RawX</th>\n",
       "      <th>RawY</th>\n",
       "      <th>Segment</th>\n",
       "      <th>VideoId</th>\n",
       "      <th>Trigger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>video_2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>128</td>\n",
       "      <td>122</td>\n",
       "      <td>Positive</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>End</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>video_2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>149</td>\n",
       "      <td>127</td>\n",
       "      <td>Positive</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>End</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>video_2</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>170</td>\n",
       "      <td>127</td>\n",
       "      <td>Positive</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>End</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>video_2</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>193</td>\n",
       "      <td>126</td>\n",
       "      <td>Positive</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>End</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>video_2</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>191</td>\n",
       "      <td>125</td>\n",
       "      <td>Positive</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>End</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35583</th>\n",
       "      <td>38</td>\n",
       "      <td>384</td>\n",
       "      <td>video_4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>147</td>\n",
       "      <td>77</td>\n",
       "      <td>Positive</td>\n",
       "      <td>41.0</td>\n",
       "      <td>End</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35584</th>\n",
       "      <td>38</td>\n",
       "      <td>384</td>\n",
       "      <td>video_4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>143</td>\n",
       "      <td>93</td>\n",
       "      <td>Positive</td>\n",
       "      <td>41.0</td>\n",
       "      <td>End</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35585</th>\n",
       "      <td>38</td>\n",
       "      <td>384</td>\n",
       "      <td>video_4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>145</td>\n",
       "      <td>103</td>\n",
       "      <td>Positive</td>\n",
       "      <td>41.0</td>\n",
       "      <td>End</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35586</th>\n",
       "      <td>38</td>\n",
       "      <td>384</td>\n",
       "      <td>video_4</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>161</td>\n",
       "      <td>101</td>\n",
       "      <td>Positive</td>\n",
       "      <td>41.0</td>\n",
       "      <td>End</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35587</th>\n",
       "      <td>38</td>\n",
       "      <td>384</td>\n",
       "      <td>video_4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>161</td>\n",
       "      <td>102</td>\n",
       "      <td>Positive</td>\n",
       "      <td>41.0</td>\n",
       "      <td>End</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32770 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       p_index_id  participant_id  Session  Valence  Arousal  RawX  RawY  \\\n",
       "1               0             101  video_2        5        5   128   122   \n",
       "2               0             101  video_2        6        5   149   127   \n",
       "3               0             101  video_2        7        5   170   127   \n",
       "4               0             101  video_2        8        5   193   126   \n",
       "5               0             101  video_2        7        5   191   125   \n",
       "...           ...             ...      ...      ...      ...   ...   ...   \n",
       "35583          38             384  video_4        5        3   147    77   \n",
       "35584          38             384  video_4        5        4   143    93   \n",
       "35585          38             384  video_4        6        4   145   103   \n",
       "35586          38             384  video_4        7        4   161   101   \n",
       "35587          38             384  video_4        6        4   161   102   \n",
       "\n",
       "        Segment  VideoId Trigger  \n",
       "1      Positive     -1.0     End  \n",
       "2      Positive     -1.0     End  \n",
       "3      Positive     -1.0     End  \n",
       "4      Positive     -1.0     End  \n",
       "5      Positive     -1.0     End  \n",
       "...         ...      ...     ...  \n",
       "35583  Positive     41.0     End  \n",
       "35584  Positive     41.0     End  \n",
       "35585  Positive     41.0     End  \n",
       "35586  Positive     41.0     End  \n",
       "35587  Positive     41.0     End  \n",
       "\n",
       "[32770 rows x 10 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep the data from affect segments (excluding `video_1` and `video_5`) corresponding to resting stages.\n",
    "Q = ( (affect_ratings_matched_video_id[\"Segment\"]==\"Positive\") | \\\n",
    "        (affect_ratings_matched_video_id[\"Segment\"]==\"Negative\") | \\\n",
    "        (affect_ratings_matched_video_id[\"Segment\"]==\"Neutral\"))\n",
    "affect_ratings_matched_video_id = affect_ratings_matched_video_id[ Q ]\n",
    "affect_ratings_matched_video_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the resting videoId with text for plot\n",
    "affect_ratings_matched_video_id = affect_ratings_matched_video_id.astype({\"VideoId\":int})\n",
    "# Resting in positive segment\n",
    "Q = ( (affect_ratings_matched_video_id[\"Segment\"]==\"Positive\") & (affect_ratings_matched_video_id[\"VideoId\"]==-1) )\n",
    "affect_ratings_matched_video_id.loc[Q,\"VideoId\"]=\"R+\"\n",
    "# Resting in positive segment\n",
    "Q = ( (affect_ratings_matched_video_id[\"Segment\"]==\"Neutral\") & (affect_ratings_matched_video_id[\"VideoId\"]==-1) )\n",
    "affect_ratings_matched_video_id.loc[Q,\"VideoId\"]=\"Rn\"\n",
    "# Resting in positive segment\n",
    "Q = ( (affect_ratings_matched_video_id[\"Segment\"]==\"Negative\") & (affect_ratings_matched_video_id[\"VideoId\"]==-1) )\n",
    "affect_ratings_matched_video_id.loc[Q,\"VideoId\"]=\"R-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Number of ratings per videoId\n",
    "affect_ratings_matched_video_id[\"VideoId\"].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_index_id</th>\n",
       "      <th>VideoId</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Arousal</th>\n",
       "      <th>RawX</th>\n",
       "      <th>RawY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>101.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>46.500000</td>\n",
       "      <td>179.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>101.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.750000</td>\n",
       "      <td>65.250000</td>\n",
       "      <td>173.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>3.076923</td>\n",
       "      <td>6.615385</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>149.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>101.0</td>\n",
       "      <td>1.619048</td>\n",
       "      <td>7.809524</td>\n",
       "      <td>67.428571</td>\n",
       "      <td>169.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>101.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.166667</td>\n",
       "      <td>51.333333</td>\n",
       "      <td>177.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>38</td>\n",
       "      <td>56</td>\n",
       "      <td>384.0</td>\n",
       "      <td>6.515152</td>\n",
       "      <td>5.727273</td>\n",
       "      <td>167.393939</td>\n",
       "      <td>135.696970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>38</td>\n",
       "      <td>57</td>\n",
       "      <td>384.0</td>\n",
       "      <td>6.576923</td>\n",
       "      <td>6.384615</td>\n",
       "      <td>166.269231</td>\n",
       "      <td>147.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132</th>\n",
       "      <td>38</td>\n",
       "      <td>R+</td>\n",
       "      <td>384.0</td>\n",
       "      <td>4.967213</td>\n",
       "      <td>4.754098</td>\n",
       "      <td>135.114754</td>\n",
       "      <td>117.991803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1133</th>\n",
       "      <td>38</td>\n",
       "      <td>R-</td>\n",
       "      <td>384.0</td>\n",
       "      <td>4.886076</td>\n",
       "      <td>1.746835</td>\n",
       "      <td>136.367089</td>\n",
       "      <td>55.481013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134</th>\n",
       "      <td>38</td>\n",
       "      <td>Rn</td>\n",
       "      <td>384.0</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>126.950000</td>\n",
       "      <td>161.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1135 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      p_index_id VideoId  participant_id   Valence   Arousal        RawX  \\\n",
       "0              0       3           101.0  1.000000  8.250000   46.500000   \n",
       "1              0       4           101.0  1.000000  7.750000   65.250000   \n",
       "2              0       6           101.0  3.076923  6.615385  100.000000   \n",
       "3              0      10           101.0  1.619048  7.809524   67.428571   \n",
       "4              0      12           101.0  1.000000  8.166667   51.333333   \n",
       "...          ...     ...             ...       ...       ...         ...   \n",
       "1130          38      56           384.0  6.515152  5.727273  167.393939   \n",
       "1131          38      57           384.0  6.576923  6.384615  166.269231   \n",
       "1132          38      R+           384.0  4.967213  4.754098  135.114754   \n",
       "1133          38      R-           384.0  4.886076  1.746835  136.367089   \n",
       "1134          38      Rn           384.0  4.300000  6.950000  126.950000   \n",
       "\n",
       "            RawY  \n",
       "0     179.375000  \n",
       "1     173.250000  \n",
       "2     149.615385  \n",
       "3     169.952381  \n",
       "4     177.666667  \n",
       "...          ...  \n",
       "1130  135.696970  \n",
       "1131  147.538462  \n",
       "1132  117.991803  \n",
       "1133   55.481013  \n",
       "1134  161.750000  \n",
       "\n",
       "[1135 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average ratings per video\n",
    "df_results_avg_affect_per_video = affect_ratings_matched_video_id.groupby(['p_index_id','VideoId']).mean().reset_index()\n",
    "df_results_avg_affect_per_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VideoId\n",
       "3     Negative\n",
       "4     Negative\n",
       "5     Negative\n",
       "6     Negative\n",
       "10    Negative\n",
       "12    Negative\n",
       "13    Negative\n",
       "18    Negative\n",
       "19    Negative\n",
       "20    Negative\n",
       "21     Neutral\n",
       "22     Neutral\n",
       "23     Neutral\n",
       "25     Neutral\n",
       "29     Neutral\n",
       "31     Neutral\n",
       "33     Neutral\n",
       "37     Neutral\n",
       "38     Neutral\n",
       "39     Neutral\n",
       "41    Positive\n",
       "42    Positive\n",
       "46    Positive\n",
       "48    Positive\n",
       "49    Positive\n",
       "51    Positive\n",
       "55    Positive\n",
       "56    Positive\n",
       "57    Positive\n",
       "58    Positive\n",
       "R+    Positive\n",
       "R-    Negative\n",
       "Rn     Neutral\n",
       "Name: Segment, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matching_video_segment = affect_ratings_matched_video_id.groupby(\"VideoId\").first()[\"Segment\"]\n",
    "matching_video_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python37\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VideoId</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Arousal</th>\n",
       "      <th>Segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2.925160</td>\n",
       "      <td>6.644785</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2.537590</td>\n",
       "      <td>6.720390</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>3.555353</td>\n",
       "      <td>5.379763</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>3.085210</td>\n",
       "      <td>5.903473</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>3.144464</td>\n",
       "      <td>6.608573</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>3.427129</td>\n",
       "      <td>6.207243</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13</td>\n",
       "      <td>2.617130</td>\n",
       "      <td>6.623608</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>18</td>\n",
       "      <td>3.227944</td>\n",
       "      <td>5.646558</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19</td>\n",
       "      <td>2.666078</td>\n",
       "      <td>5.542982</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20</td>\n",
       "      <td>3.049042</td>\n",
       "      <td>6.494111</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>21</td>\n",
       "      <td>4.753144</td>\n",
       "      <td>4.403739</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>22</td>\n",
       "      <td>5.021523</td>\n",
       "      <td>3.773649</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>23</td>\n",
       "      <td>5.295451</td>\n",
       "      <td>3.941612</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>25</td>\n",
       "      <td>4.536059</td>\n",
       "      <td>4.414821</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>29</td>\n",
       "      <td>4.471663</td>\n",
       "      <td>4.835505</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>31</td>\n",
       "      <td>4.670951</td>\n",
       "      <td>4.775232</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>33</td>\n",
       "      <td>5.320154</td>\n",
       "      <td>4.575899</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>37</td>\n",
       "      <td>5.977425</td>\n",
       "      <td>5.038622</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>38</td>\n",
       "      <td>5.446961</td>\n",
       "      <td>3.613977</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>39</td>\n",
       "      <td>5.680218</td>\n",
       "      <td>4.335024</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>41</td>\n",
       "      <td>6.573161</td>\n",
       "      <td>5.847535</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>42</td>\n",
       "      <td>5.850530</td>\n",
       "      <td>5.909107</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>46</td>\n",
       "      <td>5.671792</td>\n",
       "      <td>5.828644</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>48</td>\n",
       "      <td>6.843087</td>\n",
       "      <td>6.011634</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>49</td>\n",
       "      <td>6.664892</td>\n",
       "      <td>6.126926</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>51</td>\n",
       "      <td>6.331989</td>\n",
       "      <td>5.819468</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>55</td>\n",
       "      <td>6.075956</td>\n",
       "      <td>5.734959</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>56</td>\n",
       "      <td>6.824453</td>\n",
       "      <td>6.328092</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>57</td>\n",
       "      <td>6.565639</td>\n",
       "      <td>6.309483</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>58</td>\n",
       "      <td>6.745460</td>\n",
       "      <td>6.282918</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>R+</td>\n",
       "      <td>5.380106</td>\n",
       "      <td>3.627818</td>\n",
       "      <td>Rest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>R-</td>\n",
       "      <td>5.326414</td>\n",
       "      <td>3.789493</td>\n",
       "      <td>Rest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Rn</td>\n",
       "      <td>5.254591</td>\n",
       "      <td>4.050144</td>\n",
       "      <td>Rest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VideoId   Valence   Arousal   Segment\n",
       "0        3  2.925160  6.644785  Negative\n",
       "1        4  2.537590  6.720390  Negative\n",
       "2        5  3.555353  5.379763  Negative\n",
       "3        6  3.085210  5.903473  Negative\n",
       "4       10  3.144464  6.608573  Negative\n",
       "5       12  3.427129  6.207243  Negative\n",
       "6       13  2.617130  6.623608  Negative\n",
       "7       18  3.227944  5.646558  Negative\n",
       "8       19  2.666078  5.542982  Negative\n",
       "9       20  3.049042  6.494111  Negative\n",
       "10      21  4.753144  4.403739   Neutral\n",
       "11      22  5.021523  3.773649   Neutral\n",
       "12      23  5.295451  3.941612   Neutral\n",
       "13      25  4.536059  4.414821   Neutral\n",
       "14      29  4.471663  4.835505   Neutral\n",
       "15      31  4.670951  4.775232   Neutral\n",
       "16      33  5.320154  4.575899   Neutral\n",
       "17      37  5.977425  5.038622   Neutral\n",
       "18      38  5.446961  3.613977   Neutral\n",
       "19      39  5.680218  4.335024   Neutral\n",
       "20      41  6.573161  5.847535  Positive\n",
       "21      42  5.850530  5.909107  Positive\n",
       "22      46  5.671792  5.828644  Positive\n",
       "23      48  6.843087  6.011634  Positive\n",
       "24      49  6.664892  6.126926  Positive\n",
       "25      51  6.331989  5.819468  Positive\n",
       "26      55  6.075956  5.734959  Positive\n",
       "27      56  6.824453  6.328092  Positive\n",
       "28      57  6.565639  6.309483  Positive\n",
       "29      58  6.745460  6.282918  Positive\n",
       "30      R+  5.380106  3.627818      Rest\n",
       "31      R-  5.326414  3.789493      Rest\n",
       "32      Rn  5.254591  4.050144      Rest"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_aff = df_results_avg_affect_per_video.groupby([\"VideoId\"]).mean()[[\"Valence\",\"Arousal\"]].join(matching_video_segment).reset_index()\n",
    "avg_aff[\"Segment\"].iloc[ avg_aff[\"VideoId\"].str.startswith(\"R\").replace(np.nan, False) ] = \"Rest\"\n",
    "avg_aff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generate_plot_affect_coordinates_ratings(df, ax):\n",
    "\n",
    "    av_aff = df.copy()\n",
    "    kwargs = {\"Negative\":{\n",
    "                            \"c\":\"darkorange\", \"marker\":\"s\"\n",
    "                            },\n",
    "                    \"Positive\":{\n",
    "                            \"c\":\"forestgreen\", \"marker\":\"D\"\n",
    "                        },\n",
    "                    \"Neutral\":{\n",
    "                            \"c\":\"grey\", \"marker\":\"^\"\n",
    "                        },\n",
    "                    \"Rest\":{\n",
    "                            \"c\":\"dodgerblue\", \"marker\":\"o\", \"edgecolor\":\"k\", \"linewidths\":1\n",
    "                        }\n",
    "                    }\n",
    "\n",
    "    # colors = [kwargs[val]['c'] for val in avg_aff[\"Segment\"]]\n",
    "    # markers = [kwargs[val]['marker'] for val in avg_aff[\"Segment\"]]\n",
    "    # avg_aff.plot.scatter(ax=ax, x=\"Valence\",y=\"Arousal\",color=colors, markers=markers, legend=True)\n",
    "\n",
    "    ax = plt.gca()\n",
    "    # Plot\n",
    "    offset_min = 2.5\n",
    "    offset_max = 7.5\n",
    "    ax.set(xlim=[offset_min,offset_max], ylim=[offset_min,offset_max])\n",
    "    ax.set_xlabel(\"Valence\")\n",
    "    ax.set_ylabel(\"Arousal\")\n",
    "    # ax.set_title(f\"Average Perceived Valence-Arousal ratings per video\")\n",
    "\n",
    "    ax.vlines([(offset_max+offset_min)/2], ymin=offset_min, ymax=offset_max, color=\"gray\", linestyle='dashed', linewidth=2)\n",
    "    ax.hlines([(offset_max+offset_min)/2], xmin=offset_min, xmax=offset_max, color=\"gray\", linestyle='dashed', linewidth=2)\n",
    "    ax.grid(True)\n",
    "    ax.legend(loc=\"lower right\")\n",
    "\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "\n",
    "    for segment in av_aff[\"Segment\"].unique():\n",
    "        df_test = av_aff[ (av_aff[\"Segment\"] == segment)]\n",
    "        avg_V = df_test[\"Valence\"] #((df_test.sum_RawX/df_test.N)-128)/256 # Normalized affect between 0-1\n",
    "        avg_A = df_test[\"Arousal\"] #((df_test.sum_RawY/df_test.N)-128)/256\n",
    "\n",
    "        ax.scatter( avg_V, avg_A, label=segment, s=30, **kwargs[segment] ) #c=colors[segment], s=80, marker=markers[segment])\n",
    "\n",
    "        for i, videoId in enumerate(df_test[\"VideoId\"].values):\n",
    "            avg_V = df_test[\"Valence\"]\n",
    "            avg_A = df_test[\"Arousal\"]\n",
    "\n",
    "            # Defines where to offset the annotations depending on how many neighbors are there\n",
    "            offsetX = 0.2\n",
    "            offsetY = 0.2\n",
    "\n",
    "            offset_dict = {\n",
    "                0: [0, -offsetY],\n",
    "                1: [0, offsetY],\n",
    "                2: [-offsetX, 0],\n",
    "                3: [offsetX, 0]\n",
    "            }\n",
    "            # Define offset based on how many points are close to the value\n",
    "            # np.random.seed(345)\n",
    "            # offset_annotation = offset_dict[np.floor(np.random.randint(4))] #offset_dict[0] #offset_dict[np.floor(np.random.randint(4))]\n",
    "            thresh = 0.2\n",
    "            radius = np.sqrt(np.abs(avg_A.iloc[i] - avg_A.iloc[:i])**2 + (np.abs(avg_V.iloc[i] - avg_V.iloc[:i])**2))\n",
    "            n_close_neighbors = (radius<thresh).sum()\n",
    "            offset_annotation = offset_dict[n_close_neighbors]\n",
    "\n",
    "            # Annotate\n",
    "            if(segment != \"Rest\"):\n",
    "                ax.annotate(videoId, (avg_V.iloc[i]+offset_annotation[0], \n",
    "                                    avg_A.iloc[i]+offset_annotation[1]), \n",
    "                                    fontsize=9, ha='center', va='center',\n",
    "                                    color='k')  #kwargs[segment][\"c\"])\n",
    "    \n",
    "    ax.grid(True)\n",
    "    ax.legend(loc=\"lower right\")\n",
    "\n",
    "    return ax\n",
    "\n",
    "# Plotting how each video was rated among all self-reported datapoints across all 15 participants.\n",
    "save_path_plot = gen_path_plot(\"affect-coordinates-ratings-per-video\")\n",
    "\n",
    "NUM_ROWS = 1\n",
    "NUM_COLS = 1\n",
    "fig,axes = plt.subplots(NUM_ROWS, NUM_COLS, sharex=False, sharey=True, figsize=(6*NUM_COLS, 4*NUM_ROWS))\n",
    "\n",
    "axes = generate_plot_affect_coordinates_ratings(avg_aff, axes)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_path_plot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical analysis tests\n",
    "\n",
    "Validate whether the average self-reported **valence** and **arousal** ratings differ between video categories aiming to induce `Negative`, `Neutral`, and `Positive` affect.\n",
    "\n",
    "**Method:** Paired t-test to compare the mean of two samples.\n",
    "\n",
    "*Test 1*: $H_0: \\mu_- \\geq \\mu_N$ | $H_1: \\mu_- < \\mu_N$\n",
    "\n",
    "If $p<0.01$, we reject the null hypothesis that the mean **reported valence/arousal** in the `Negative` videos $\\mu_-$ is *greater or equal*  than in the `Neutral` videos $\\mu_N$\n",
    "\n",
    "*Test 2*: $H_0: \\mu_+ \\leq \\mu_N$ | $H_1: \\mu_+ > \\mu_N$\n",
    "\n",
    "If $p<0.01$, we reject the null hypothesis that the mean **reported valence/arousal** in the `Positive` videos $\\mu_-$ is *lower or equal* than in the `Neutral` videos $\\mu_N$\n",
    "\n",
    "\n",
    "**Conclusions**\n",
    "\n",
    "Regarding *valence*, the mean ratings in the negative videos are significantly lower than the ratings in the neutral videos ($T=-11.22;N=10;p<0.01$). Similarly, the mean *valence* ratings in the positive videos are greater than in the neutral ($T=6.64;N=10;p<0.001$). Regarding arousal, the mean ratings in the positive videos are greater than in the neutral ($T=9.91;N=10;p<0.001$). However, the mean ratings in the positive videos are not significantly greater than the ratings in the neutral videos ($T=6.81;N=10;p=0.9$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_index_id</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>Session</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Arousal</th>\n",
       "      <th>RawX</th>\n",
       "      <th>RawY</th>\n",
       "      <th>Segment</th>\n",
       "      <th>VideoId</th>\n",
       "      <th>Trigger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>video_2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>128</td>\n",
       "      <td>122</td>\n",
       "      <td>Positive</td>\n",
       "      <td>R+</td>\n",
       "      <td>End</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>video_2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>149</td>\n",
       "      <td>127</td>\n",
       "      <td>Positive</td>\n",
       "      <td>R+</td>\n",
       "      <td>End</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>video_2</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>170</td>\n",
       "      <td>127</td>\n",
       "      <td>Positive</td>\n",
       "      <td>R+</td>\n",
       "      <td>End</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>video_2</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>193</td>\n",
       "      <td>126</td>\n",
       "      <td>Positive</td>\n",
       "      <td>R+</td>\n",
       "      <td>End</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>video_2</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>191</td>\n",
       "      <td>125</td>\n",
       "      <td>Positive</td>\n",
       "      <td>R+</td>\n",
       "      <td>End</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35583</th>\n",
       "      <td>38</td>\n",
       "      <td>384</td>\n",
       "      <td>video_4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>147</td>\n",
       "      <td>77</td>\n",
       "      <td>Positive</td>\n",
       "      <td>41</td>\n",
       "      <td>End</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35584</th>\n",
       "      <td>38</td>\n",
       "      <td>384</td>\n",
       "      <td>video_4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>143</td>\n",
       "      <td>93</td>\n",
       "      <td>Positive</td>\n",
       "      <td>41</td>\n",
       "      <td>End</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35585</th>\n",
       "      <td>38</td>\n",
       "      <td>384</td>\n",
       "      <td>video_4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>145</td>\n",
       "      <td>103</td>\n",
       "      <td>Positive</td>\n",
       "      <td>41</td>\n",
       "      <td>End</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35586</th>\n",
       "      <td>38</td>\n",
       "      <td>384</td>\n",
       "      <td>video_4</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>161</td>\n",
       "      <td>101</td>\n",
       "      <td>Positive</td>\n",
       "      <td>41</td>\n",
       "      <td>End</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35587</th>\n",
       "      <td>38</td>\n",
       "      <td>384</td>\n",
       "      <td>video_4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>161</td>\n",
       "      <td>102</td>\n",
       "      <td>Positive</td>\n",
       "      <td>41</td>\n",
       "      <td>End</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32770 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       p_index_id  participant_id  Session  Valence  Arousal  RawX  RawY  \\\n",
       "1               0             101  video_2        5        5   128   122   \n",
       "2               0             101  video_2        6        5   149   127   \n",
       "3               0             101  video_2        7        5   170   127   \n",
       "4               0             101  video_2        8        5   193   126   \n",
       "5               0             101  video_2        7        5   191   125   \n",
       "...           ...             ...      ...      ...      ...   ...   ...   \n",
       "35583          38             384  video_4        5        3   147    77   \n",
       "35584          38             384  video_4        5        4   143    93   \n",
       "35585          38             384  video_4        6        4   145   103   \n",
       "35586          38             384  video_4        7        4   161   101   \n",
       "35587          38             384  video_4        6        4   161   102   \n",
       "\n",
       "        Segment VideoId Trigger  \n",
       "1      Positive      R+     End  \n",
       "2      Positive      R+     End  \n",
       "3      Positive      R+     End  \n",
       "4      Positive      R+     End  \n",
       "5      Positive      R+     End  \n",
       "...         ...     ...     ...  \n",
       "35583  Positive      41     End  \n",
       "35584  Positive      41     End  \n",
       "35585  Positive      41     End  \n",
       "35586  Positive      41     End  \n",
       "35587  Positive      41     End  \n",
       "\n",
       "[32770 rows x 10 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "affect_ratings_matched_video_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace columns as categorical to get all factors when grouping by\n",
    "X = affect_ratings_matched_video_id.copy()\n",
    "# X[\"p_index_id\"] = pd.Categorical(X[\"p_index_id\"], categories=X[\"p_index_id\"].unique(), ordered=False)\n",
    "# X[\"participant_id\"] = pd.Categorical(X[\"participant_id\"].astype(int), categories=X[\"participant_id\"].unique().astype(int), ordered=False)\n",
    "X[\"VideoId\"] = pd.Categorical(X[\"VideoId\"], categories=X[\"VideoId\"].unique(), ordered=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_index_id</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Arousal</th>\n",
       "      <th>RawX</th>\n",
       "      <th>RawY</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VideoId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>R+</th>\n",
       "      <td>0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>6.586957</td>\n",
       "      <td>3.086957</td>\n",
       "      <td>164.565217</td>\n",
       "      <td>89.456522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>5.562500</td>\n",
       "      <td>6.468750</td>\n",
       "      <td>147.593750</td>\n",
       "      <td>147.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>171.400000</td>\n",
       "      <td>154.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>7.750000</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>191.250000</td>\n",
       "      <td>118.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>8.272727</td>\n",
       "      <td>5.363636</td>\n",
       "      <td>206.363636</td>\n",
       "      <td>127.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>38</td>\n",
       "      <td>384.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>143.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>38</td>\n",
       "      <td>384.0</td>\n",
       "      <td>2.851852</td>\n",
       "      <td>4.962963</td>\n",
       "      <td>91.555556</td>\n",
       "      <td>119.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>38</td>\n",
       "      <td>384.0</td>\n",
       "      <td>2.593750</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>90.593750</td>\n",
       "      <td>101.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>38</td>\n",
       "      <td>384.0</td>\n",
       "      <td>3.906250</td>\n",
       "      <td>4.468750</td>\n",
       "      <td>117.375000</td>\n",
       "      <td>112.156250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1287 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         p_index_id  participant_id   Valence   Arousal        RawX  \\\n",
       "VideoId                                                               \n",
       "R+                0           101.0  6.586957  3.086957  164.565217   \n",
       "49                0           101.0  5.562500  6.468750  147.593750   \n",
       "46                0           101.0  6.800000  6.900000  171.400000   \n",
       "41                0           101.0  7.750000  4.750000  191.250000   \n",
       "48                0           101.0  8.272727  5.363636  206.363636   \n",
       "...             ...             ...       ...       ...         ...   \n",
       "42               38           384.0  6.000000  6.166667  155.000000   \n",
       "51               38             NaN       NaN       NaN         NaN   \n",
       "18               38           384.0  2.851852  4.962963   91.555556   \n",
       "5                38           384.0  2.593750  4.000000   90.593750   \n",
       "29               38           384.0  3.906250  4.468750  117.375000   \n",
       "\n",
       "               RawY  \n",
       "VideoId              \n",
       "R+        89.456522  \n",
       "49       147.125000  \n",
       "46       154.200000  \n",
       "41       118.375000  \n",
       "48       127.727273  \n",
       "...             ...  \n",
       "42       143.666667  \n",
       "51              NaN  \n",
       "18       119.555556  \n",
       "5        101.843750  \n",
       "29       112.156250  \n",
       "\n",
       "[1287 rows x 6 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate DF with all participants and all videoIds (even if they have no ratings)\n",
    "# result should be an array of 39 participants * 3 affect segments * (10+1) videos per segment = 1287\n",
    "df_avg_per_participant_and_video = X.groupby([\"p_index_id\",\"VideoId\"]).mean().reset_index().set_index([\"VideoId\"])\n",
    "df_avg_per_participant_and_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python37\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VideoId</th>\n",
       "      <th>p_index_id</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Arousal</th>\n",
       "      <th>RawX</th>\n",
       "      <th>RawY</th>\n",
       "      <th>Segment</th>\n",
       "      <th>stage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R+</td>\n",
       "      <td>19.0</td>\n",
       "      <td>314.333333</td>\n",
       "      <td>5.380106</td>\n",
       "      <td>3.627818</td>\n",
       "      <td>142.515384</td>\n",
       "      <td>94.849119</td>\n",
       "      <td>Positive</td>\n",
       "      <td>rest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>19.0</td>\n",
       "      <td>315.888889</td>\n",
       "      <td>6.664892</td>\n",
       "      <td>6.126926</td>\n",
       "      <td>168.042754</td>\n",
       "      <td>142.629690</td>\n",
       "      <td>Positive</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>19.0</td>\n",
       "      <td>310.333333</td>\n",
       "      <td>5.671792</td>\n",
       "      <td>5.828644</td>\n",
       "      <td>149.131776</td>\n",
       "      <td>136.989660</td>\n",
       "      <td>Positive</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41</td>\n",
       "      <td>19.0</td>\n",
       "      <td>314.210526</td>\n",
       "      <td>6.573161</td>\n",
       "      <td>5.847535</td>\n",
       "      <td>167.393782</td>\n",
       "      <td>137.963389</td>\n",
       "      <td>Positive</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48</td>\n",
       "      <td>19.0</td>\n",
       "      <td>316.093750</td>\n",
       "      <td>6.843087</td>\n",
       "      <td>6.011634</td>\n",
       "      <td>171.598356</td>\n",
       "      <td>139.996372</td>\n",
       "      <td>Positive</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>57</td>\n",
       "      <td>19.0</td>\n",
       "      <td>311.833333</td>\n",
       "      <td>6.565639</td>\n",
       "      <td>6.309483</td>\n",
       "      <td>167.096468</td>\n",
       "      <td>145.678304</td>\n",
       "      <td>Positive</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>56</td>\n",
       "      <td>19.0</td>\n",
       "      <td>316.297297</td>\n",
       "      <td>6.824453</td>\n",
       "      <td>6.328092</td>\n",
       "      <td>171.474719</td>\n",
       "      <td>145.624634</td>\n",
       "      <td>Positive</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>58</td>\n",
       "      <td>19.0</td>\n",
       "      <td>304.464286</td>\n",
       "      <td>6.745460</td>\n",
       "      <td>6.282918</td>\n",
       "      <td>170.328075</td>\n",
       "      <td>145.118006</td>\n",
       "      <td>Positive</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>55</td>\n",
       "      <td>19.0</td>\n",
       "      <td>314.500000</td>\n",
       "      <td>6.075956</td>\n",
       "      <td>5.734959</td>\n",
       "      <td>157.270185</td>\n",
       "      <td>134.685001</td>\n",
       "      <td>Positive</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>R-</td>\n",
       "      <td>19.0</td>\n",
       "      <td>315.800000</td>\n",
       "      <td>5.326414</td>\n",
       "      <td>3.789493</td>\n",
       "      <td>142.073991</td>\n",
       "      <td>98.266930</td>\n",
       "      <td>Negative</td>\n",
       "      <td>rest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>19.0</td>\n",
       "      <td>311.542857</td>\n",
       "      <td>3.144464</td>\n",
       "      <td>6.608573</td>\n",
       "      <td>101.254904</td>\n",
       "      <td>151.647997</td>\n",
       "      <td>Negative</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>19.0</td>\n",
       "      <td>313.210526</td>\n",
       "      <td>2.617130</td>\n",
       "      <td>6.623608</td>\n",
       "      <td>90.346304</td>\n",
       "      <td>151.517348</td>\n",
       "      <td>Negative</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>19.0</td>\n",
       "      <td>311.400000</td>\n",
       "      <td>3.427129</td>\n",
       "      <td>6.207243</td>\n",
       "      <td>105.024316</td>\n",
       "      <td>144.577650</td>\n",
       "      <td>Negative</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>19</td>\n",
       "      <td>19.0</td>\n",
       "      <td>319.342857</td>\n",
       "      <td>2.666078</td>\n",
       "      <td>5.542982</td>\n",
       "      <td>90.491708</td>\n",
       "      <td>132.314307</td>\n",
       "      <td>Negative</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>19.0</td>\n",
       "      <td>316.363636</td>\n",
       "      <td>2.925160</td>\n",
       "      <td>6.644785</td>\n",
       "      <td>97.033245</td>\n",
       "      <td>151.703615</td>\n",
       "      <td>Negative</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>19.0</td>\n",
       "      <td>316.027778</td>\n",
       "      <td>2.537590</td>\n",
       "      <td>6.720390</td>\n",
       "      <td>88.112065</td>\n",
       "      <td>153.773705</td>\n",
       "      <td>Negative</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20</td>\n",
       "      <td>19.0</td>\n",
       "      <td>315.571429</td>\n",
       "      <td>3.049042</td>\n",
       "      <td>6.494111</td>\n",
       "      <td>99.351835</td>\n",
       "      <td>149.235643</td>\n",
       "      <td>Negative</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6</td>\n",
       "      <td>19.0</td>\n",
       "      <td>309.766667</td>\n",
       "      <td>3.085210</td>\n",
       "      <td>5.903473</td>\n",
       "      <td>99.152014</td>\n",
       "      <td>138.337908</td>\n",
       "      <td>Negative</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Rn</td>\n",
       "      <td>19.0</td>\n",
       "      <td>315.314286</td>\n",
       "      <td>5.254591</td>\n",
       "      <td>4.050144</td>\n",
       "      <td>141.232734</td>\n",
       "      <td>103.447393</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>rest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>25</td>\n",
       "      <td>19.0</td>\n",
       "      <td>320.030303</td>\n",
       "      <td>4.536059</td>\n",
       "      <td>4.414821</td>\n",
       "      <td>128.453579</td>\n",
       "      <td>109.055088</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>38</td>\n",
       "      <td>19.0</td>\n",
       "      <td>314.181818</td>\n",
       "      <td>5.446961</td>\n",
       "      <td>3.613977</td>\n",
       "      <td>143.854003</td>\n",
       "      <td>94.625761</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>37</td>\n",
       "      <td>19.0</td>\n",
       "      <td>313.805556</td>\n",
       "      <td>5.977425</td>\n",
       "      <td>5.038622</td>\n",
       "      <td>153.784372</td>\n",
       "      <td>120.874360</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>31</td>\n",
       "      <td>19.0</td>\n",
       "      <td>309.529412</td>\n",
       "      <td>4.670951</td>\n",
       "      <td>4.775232</td>\n",
       "      <td>131.446546</td>\n",
       "      <td>117.182016</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>33</td>\n",
       "      <td>19.0</td>\n",
       "      <td>317.500000</td>\n",
       "      <td>5.320154</td>\n",
       "      <td>4.575899</td>\n",
       "      <td>142.886353</td>\n",
       "      <td>114.036227</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>22</td>\n",
       "      <td>19.0</td>\n",
       "      <td>317.633333</td>\n",
       "      <td>5.021523</td>\n",
       "      <td>3.773649</td>\n",
       "      <td>137.149312</td>\n",
       "      <td>97.926597</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>39</td>\n",
       "      <td>19.0</td>\n",
       "      <td>316.114286</td>\n",
       "      <td>5.680218</td>\n",
       "      <td>4.335024</td>\n",
       "      <td>147.807845</td>\n",
       "      <td>109.271590</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>23</td>\n",
       "      <td>19.0</td>\n",
       "      <td>321.257143</td>\n",
       "      <td>5.295451</td>\n",
       "      <td>3.941612</td>\n",
       "      <td>142.318219</td>\n",
       "      <td>101.052685</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>21</td>\n",
       "      <td>19.0</td>\n",
       "      <td>314.805556</td>\n",
       "      <td>4.753144</td>\n",
       "      <td>4.403739</td>\n",
       "      <td>131.931404</td>\n",
       "      <td>109.768878</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>42</td>\n",
       "      <td>19.0</td>\n",
       "      <td>316.235294</td>\n",
       "      <td>5.850530</td>\n",
       "      <td>5.909107</td>\n",
       "      <td>152.474732</td>\n",
       "      <td>138.481924</td>\n",
       "      <td>Positive</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>51</td>\n",
       "      <td>19.0</td>\n",
       "      <td>323.406250</td>\n",
       "      <td>6.331989</td>\n",
       "      <td>5.819468</td>\n",
       "      <td>162.180940</td>\n",
       "      <td>136.548523</td>\n",
       "      <td>Positive</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>18</td>\n",
       "      <td>19.0</td>\n",
       "      <td>318.228571</td>\n",
       "      <td>3.227944</td>\n",
       "      <td>5.646558</td>\n",
       "      <td>100.136300</td>\n",
       "      <td>133.770107</td>\n",
       "      <td>Negative</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>5</td>\n",
       "      <td>19.0</td>\n",
       "      <td>319.277778</td>\n",
       "      <td>3.555353</td>\n",
       "      <td>5.379763</td>\n",
       "      <td>109.393235</td>\n",
       "      <td>128.650091</td>\n",
       "      <td>Negative</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>29</td>\n",
       "      <td>19.0</td>\n",
       "      <td>321.545455</td>\n",
       "      <td>4.471663</td>\n",
       "      <td>4.835505</td>\n",
       "      <td>127.126007</td>\n",
       "      <td>118.788776</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VideoId  p_index_id  participant_id   Valence   Arousal        RawX  \\\n",
       "0       R+        19.0      314.333333  5.380106  3.627818  142.515384   \n",
       "1       49        19.0      315.888889  6.664892  6.126926  168.042754   \n",
       "2       46        19.0      310.333333  5.671792  5.828644  149.131776   \n",
       "3       41        19.0      314.210526  6.573161  5.847535  167.393782   \n",
       "4       48        19.0      316.093750  6.843087  6.011634  171.598356   \n",
       "5       57        19.0      311.833333  6.565639  6.309483  167.096468   \n",
       "6       56        19.0      316.297297  6.824453  6.328092  171.474719   \n",
       "7       58        19.0      304.464286  6.745460  6.282918  170.328075   \n",
       "8       55        19.0      314.500000  6.075956  5.734959  157.270185   \n",
       "9       R-        19.0      315.800000  5.326414  3.789493  142.073991   \n",
       "10      10        19.0      311.542857  3.144464  6.608573  101.254904   \n",
       "11      13        19.0      313.210526  2.617130  6.623608   90.346304   \n",
       "12      12        19.0      311.400000  3.427129  6.207243  105.024316   \n",
       "13      19        19.0      319.342857  2.666078  5.542982   90.491708   \n",
       "14       3        19.0      316.363636  2.925160  6.644785   97.033245   \n",
       "15       4        19.0      316.027778  2.537590  6.720390   88.112065   \n",
       "16      20        19.0      315.571429  3.049042  6.494111   99.351835   \n",
       "17       6        19.0      309.766667  3.085210  5.903473   99.152014   \n",
       "18      Rn        19.0      315.314286  5.254591  4.050144  141.232734   \n",
       "19      25        19.0      320.030303  4.536059  4.414821  128.453579   \n",
       "20      38        19.0      314.181818  5.446961  3.613977  143.854003   \n",
       "21      37        19.0      313.805556  5.977425  5.038622  153.784372   \n",
       "22      31        19.0      309.529412  4.670951  4.775232  131.446546   \n",
       "23      33        19.0      317.500000  5.320154  4.575899  142.886353   \n",
       "24      22        19.0      317.633333  5.021523  3.773649  137.149312   \n",
       "25      39        19.0      316.114286  5.680218  4.335024  147.807845   \n",
       "26      23        19.0      321.257143  5.295451  3.941612  142.318219   \n",
       "27      21        19.0      314.805556  4.753144  4.403739  131.931404   \n",
       "28      42        19.0      316.235294  5.850530  5.909107  152.474732   \n",
       "29      51        19.0      323.406250  6.331989  5.819468  162.180940   \n",
       "30      18        19.0      318.228571  3.227944  5.646558  100.136300   \n",
       "31       5        19.0      319.277778  3.555353  5.379763  109.393235   \n",
       "32      29        19.0      321.545455  4.471663  4.835505  127.126007   \n",
       "\n",
       "          RawY   Segment  stage  \n",
       "0    94.849119  Positive   rest  \n",
       "1   142.629690  Positive  video  \n",
       "2   136.989660  Positive  video  \n",
       "3   137.963389  Positive  video  \n",
       "4   139.996372  Positive  video  \n",
       "5   145.678304  Positive  video  \n",
       "6   145.624634  Positive  video  \n",
       "7   145.118006  Positive  video  \n",
       "8   134.685001  Positive  video  \n",
       "9    98.266930  Negative   rest  \n",
       "10  151.647997  Negative  video  \n",
       "11  151.517348  Negative  video  \n",
       "12  144.577650  Negative  video  \n",
       "13  132.314307  Negative  video  \n",
       "14  151.703615  Negative  video  \n",
       "15  153.773705  Negative  video  \n",
       "16  149.235643  Negative  video  \n",
       "17  138.337908  Negative  video  \n",
       "18  103.447393   Neutral   rest  \n",
       "19  109.055088   Neutral  video  \n",
       "20   94.625761   Neutral  video  \n",
       "21  120.874360   Neutral  video  \n",
       "22  117.182016   Neutral  video  \n",
       "23  114.036227   Neutral  video  \n",
       "24   97.926597   Neutral  video  \n",
       "25  109.271590   Neutral  video  \n",
       "26  101.052685   Neutral  video  \n",
       "27  109.768878   Neutral  video  \n",
       "28  138.481924  Positive  video  \n",
       "29  136.548523  Positive  video  \n",
       "30  133.770107  Negative  video  \n",
       "31  128.650091  Negative  video  \n",
       "32  118.788776   Neutral  video  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a DF with summary affect ratings across participants, and join with corresponding affect segment\n",
    "df_statistical_comparison = df_avg_per_participant_and_video.groupby(\"VideoId\").mean().join(matching_video_segment).reset_index()\n",
    "df_statistical_comparison[\"stage\"] = \"video\"\n",
    "df_statistical_comparison[\"stage\"].iloc[ df_statistical_comparison[\"VideoId\"].str.startswith(\"R\").replace(np.nan, False) ] = \"rest\"\n",
    "\n",
    "# Save file\n",
    "STATISTICAL_TESTS_FILENAME = gen_path_results(\"1_AvgAffectRatingsPerVideoId\", extension=\".csv\")\n",
    "df_statistical_comparison.to_csv( STATISTICAL_TESTS_FILENAME, index=False)\n",
    "\n",
    "df_statistical_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Valence**\n",
    "\n",
    "We analyze `RawX` instead of `Valence` because it contains the raw reported values from the joystick and has not been quantisized in the `9-level` variable of valence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VideoId</th>\n",
       "      <th>p_index_id</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Arousal</th>\n",
       "      <th>RawX</th>\n",
       "      <th>RawY</th>\n",
       "      <th>Segment</th>\n",
       "      <th>stage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>19.0</td>\n",
       "      <td>315.888889</td>\n",
       "      <td>6.664892</td>\n",
       "      <td>6.126926</td>\n",
       "      <td>168.042754</td>\n",
       "      <td>142.629690</td>\n",
       "      <td>Positive</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>19.0</td>\n",
       "      <td>310.333333</td>\n",
       "      <td>5.671792</td>\n",
       "      <td>5.828644</td>\n",
       "      <td>149.131776</td>\n",
       "      <td>136.989660</td>\n",
       "      <td>Positive</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41</td>\n",
       "      <td>19.0</td>\n",
       "      <td>314.210526</td>\n",
       "      <td>6.573161</td>\n",
       "      <td>5.847535</td>\n",
       "      <td>167.393782</td>\n",
       "      <td>137.963389</td>\n",
       "      <td>Positive</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48</td>\n",
       "      <td>19.0</td>\n",
       "      <td>316.093750</td>\n",
       "      <td>6.843087</td>\n",
       "      <td>6.011634</td>\n",
       "      <td>171.598356</td>\n",
       "      <td>139.996372</td>\n",
       "      <td>Positive</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>57</td>\n",
       "      <td>19.0</td>\n",
       "      <td>311.833333</td>\n",
       "      <td>6.565639</td>\n",
       "      <td>6.309483</td>\n",
       "      <td>167.096468</td>\n",
       "      <td>145.678304</td>\n",
       "      <td>Positive</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>56</td>\n",
       "      <td>19.0</td>\n",
       "      <td>316.297297</td>\n",
       "      <td>6.824453</td>\n",
       "      <td>6.328092</td>\n",
       "      <td>171.474719</td>\n",
       "      <td>145.624634</td>\n",
       "      <td>Positive</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>58</td>\n",
       "      <td>19.0</td>\n",
       "      <td>304.464286</td>\n",
       "      <td>6.745460</td>\n",
       "      <td>6.282918</td>\n",
       "      <td>170.328075</td>\n",
       "      <td>145.118006</td>\n",
       "      <td>Positive</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>55</td>\n",
       "      <td>19.0</td>\n",
       "      <td>314.500000</td>\n",
       "      <td>6.075956</td>\n",
       "      <td>5.734959</td>\n",
       "      <td>157.270185</td>\n",
       "      <td>134.685001</td>\n",
       "      <td>Positive</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>19.0</td>\n",
       "      <td>311.542857</td>\n",
       "      <td>3.144464</td>\n",
       "      <td>6.608573</td>\n",
       "      <td>101.254904</td>\n",
       "      <td>151.647997</td>\n",
       "      <td>Negative</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>19.0</td>\n",
       "      <td>313.210526</td>\n",
       "      <td>2.617130</td>\n",
       "      <td>6.623608</td>\n",
       "      <td>90.346304</td>\n",
       "      <td>151.517348</td>\n",
       "      <td>Negative</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>19.0</td>\n",
       "      <td>311.400000</td>\n",
       "      <td>3.427129</td>\n",
       "      <td>6.207243</td>\n",
       "      <td>105.024316</td>\n",
       "      <td>144.577650</td>\n",
       "      <td>Negative</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>19</td>\n",
       "      <td>19.0</td>\n",
       "      <td>319.342857</td>\n",
       "      <td>2.666078</td>\n",
       "      <td>5.542982</td>\n",
       "      <td>90.491708</td>\n",
       "      <td>132.314307</td>\n",
       "      <td>Negative</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>19.0</td>\n",
       "      <td>316.363636</td>\n",
       "      <td>2.925160</td>\n",
       "      <td>6.644785</td>\n",
       "      <td>97.033245</td>\n",
       "      <td>151.703615</td>\n",
       "      <td>Negative</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>19.0</td>\n",
       "      <td>316.027778</td>\n",
       "      <td>2.537590</td>\n",
       "      <td>6.720390</td>\n",
       "      <td>88.112065</td>\n",
       "      <td>153.773705</td>\n",
       "      <td>Negative</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20</td>\n",
       "      <td>19.0</td>\n",
       "      <td>315.571429</td>\n",
       "      <td>3.049042</td>\n",
       "      <td>6.494111</td>\n",
       "      <td>99.351835</td>\n",
       "      <td>149.235643</td>\n",
       "      <td>Negative</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6</td>\n",
       "      <td>19.0</td>\n",
       "      <td>309.766667</td>\n",
       "      <td>3.085210</td>\n",
       "      <td>5.903473</td>\n",
       "      <td>99.152014</td>\n",
       "      <td>138.337908</td>\n",
       "      <td>Negative</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>25</td>\n",
       "      <td>19.0</td>\n",
       "      <td>320.030303</td>\n",
       "      <td>4.536059</td>\n",
       "      <td>4.414821</td>\n",
       "      <td>128.453579</td>\n",
       "      <td>109.055088</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>38</td>\n",
       "      <td>19.0</td>\n",
       "      <td>314.181818</td>\n",
       "      <td>5.446961</td>\n",
       "      <td>3.613977</td>\n",
       "      <td>143.854003</td>\n",
       "      <td>94.625761</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>37</td>\n",
       "      <td>19.0</td>\n",
       "      <td>313.805556</td>\n",
       "      <td>5.977425</td>\n",
       "      <td>5.038622</td>\n",
       "      <td>153.784372</td>\n",
       "      <td>120.874360</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>31</td>\n",
       "      <td>19.0</td>\n",
       "      <td>309.529412</td>\n",
       "      <td>4.670951</td>\n",
       "      <td>4.775232</td>\n",
       "      <td>131.446546</td>\n",
       "      <td>117.182016</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>33</td>\n",
       "      <td>19.0</td>\n",
       "      <td>317.500000</td>\n",
       "      <td>5.320154</td>\n",
       "      <td>4.575899</td>\n",
       "      <td>142.886353</td>\n",
       "      <td>114.036227</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>22</td>\n",
       "      <td>19.0</td>\n",
       "      <td>317.633333</td>\n",
       "      <td>5.021523</td>\n",
       "      <td>3.773649</td>\n",
       "      <td>137.149312</td>\n",
       "      <td>97.926597</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>39</td>\n",
       "      <td>19.0</td>\n",
       "      <td>316.114286</td>\n",
       "      <td>5.680218</td>\n",
       "      <td>4.335024</td>\n",
       "      <td>147.807845</td>\n",
       "      <td>109.271590</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>23</td>\n",
       "      <td>19.0</td>\n",
       "      <td>321.257143</td>\n",
       "      <td>5.295451</td>\n",
       "      <td>3.941612</td>\n",
       "      <td>142.318219</td>\n",
       "      <td>101.052685</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>21</td>\n",
       "      <td>19.0</td>\n",
       "      <td>314.805556</td>\n",
       "      <td>4.753144</td>\n",
       "      <td>4.403739</td>\n",
       "      <td>131.931404</td>\n",
       "      <td>109.768878</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>42</td>\n",
       "      <td>19.0</td>\n",
       "      <td>316.235294</td>\n",
       "      <td>5.850530</td>\n",
       "      <td>5.909107</td>\n",
       "      <td>152.474732</td>\n",
       "      <td>138.481924</td>\n",
       "      <td>Positive</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>51</td>\n",
       "      <td>19.0</td>\n",
       "      <td>323.406250</td>\n",
       "      <td>6.331989</td>\n",
       "      <td>5.819468</td>\n",
       "      <td>162.180940</td>\n",
       "      <td>136.548523</td>\n",
       "      <td>Positive</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>18</td>\n",
       "      <td>19.0</td>\n",
       "      <td>318.228571</td>\n",
       "      <td>3.227944</td>\n",
       "      <td>5.646558</td>\n",
       "      <td>100.136300</td>\n",
       "      <td>133.770107</td>\n",
       "      <td>Negative</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>5</td>\n",
       "      <td>19.0</td>\n",
       "      <td>319.277778</td>\n",
       "      <td>3.555353</td>\n",
       "      <td>5.379763</td>\n",
       "      <td>109.393235</td>\n",
       "      <td>128.650091</td>\n",
       "      <td>Negative</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>29</td>\n",
       "      <td>19.0</td>\n",
       "      <td>321.545455</td>\n",
       "      <td>4.471663</td>\n",
       "      <td>4.835505</td>\n",
       "      <td>127.126007</td>\n",
       "      <td>118.788776</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VideoId  p_index_id  participant_id   Valence   Arousal        RawX  \\\n",
       "1       49        19.0      315.888889  6.664892  6.126926  168.042754   \n",
       "2       46        19.0      310.333333  5.671792  5.828644  149.131776   \n",
       "3       41        19.0      314.210526  6.573161  5.847535  167.393782   \n",
       "4       48        19.0      316.093750  6.843087  6.011634  171.598356   \n",
       "5       57        19.0      311.833333  6.565639  6.309483  167.096468   \n",
       "6       56        19.0      316.297297  6.824453  6.328092  171.474719   \n",
       "7       58        19.0      304.464286  6.745460  6.282918  170.328075   \n",
       "8       55        19.0      314.500000  6.075956  5.734959  157.270185   \n",
       "10      10        19.0      311.542857  3.144464  6.608573  101.254904   \n",
       "11      13        19.0      313.210526  2.617130  6.623608   90.346304   \n",
       "12      12        19.0      311.400000  3.427129  6.207243  105.024316   \n",
       "13      19        19.0      319.342857  2.666078  5.542982   90.491708   \n",
       "14       3        19.0      316.363636  2.925160  6.644785   97.033245   \n",
       "15       4        19.0      316.027778  2.537590  6.720390   88.112065   \n",
       "16      20        19.0      315.571429  3.049042  6.494111   99.351835   \n",
       "17       6        19.0      309.766667  3.085210  5.903473   99.152014   \n",
       "19      25        19.0      320.030303  4.536059  4.414821  128.453579   \n",
       "20      38        19.0      314.181818  5.446961  3.613977  143.854003   \n",
       "21      37        19.0      313.805556  5.977425  5.038622  153.784372   \n",
       "22      31        19.0      309.529412  4.670951  4.775232  131.446546   \n",
       "23      33        19.0      317.500000  5.320154  4.575899  142.886353   \n",
       "24      22        19.0      317.633333  5.021523  3.773649  137.149312   \n",
       "25      39        19.0      316.114286  5.680218  4.335024  147.807845   \n",
       "26      23        19.0      321.257143  5.295451  3.941612  142.318219   \n",
       "27      21        19.0      314.805556  4.753144  4.403739  131.931404   \n",
       "28      42        19.0      316.235294  5.850530  5.909107  152.474732   \n",
       "29      51        19.0      323.406250  6.331989  5.819468  162.180940   \n",
       "30      18        19.0      318.228571  3.227944  5.646558  100.136300   \n",
       "31       5        19.0      319.277778  3.555353  5.379763  109.393235   \n",
       "32      29        19.0      321.545455  4.471663  4.835505  127.126007   \n",
       "\n",
       "          RawY   Segment  stage  \n",
       "1   142.629690  Positive  video  \n",
       "2   136.989660  Positive  video  \n",
       "3   137.963389  Positive  video  \n",
       "4   139.996372  Positive  video  \n",
       "5   145.678304  Positive  video  \n",
       "6   145.624634  Positive  video  \n",
       "7   145.118006  Positive  video  \n",
       "8   134.685001  Positive  video  \n",
       "10  151.647997  Negative  video  \n",
       "11  151.517348  Negative  video  \n",
       "12  144.577650  Negative  video  \n",
       "13  132.314307  Negative  video  \n",
       "14  151.703615  Negative  video  \n",
       "15  153.773705  Negative  video  \n",
       "16  149.235643  Negative  video  \n",
       "17  138.337908  Negative  video  \n",
       "19  109.055088   Neutral  video  \n",
       "20   94.625761   Neutral  video  \n",
       "21  120.874360   Neutral  video  \n",
       "22  117.182016   Neutral  video  \n",
       "23  114.036227   Neutral  video  \n",
       "24   97.926597   Neutral  video  \n",
       "25  109.271590   Neutral  video  \n",
       "26  101.052685   Neutral  video  \n",
       "27  109.768878   Neutral  video  \n",
       "28  138.481924  Positive  video  \n",
       "29  136.548523  Positive  video  \n",
       "30  133.770107  Negative  video  \n",
       "31  128.650091  Negative  video  \n",
       "32  118.788776   Neutral  video  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just use the data from the videos, not the resting stages\n",
    "df_comparisons = df_statistical_comparison[ df_statistical_comparison[\"stage\"]==\"video\" ]\n",
    "df_comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 10\n"
     ]
    }
   ],
   "source": [
    "# Separate columns for statistical test\n",
    "subj_valence_videos_neg = df_comparisons[df_comparisons[\"Segment\"]==\"Negative\"][\"RawX\"]\n",
    "subj_valence_videos_ntr = df_comparisons[df_comparisons[\"Segment\"]==\"Neutral\"][\"RawX\"]\n",
    "subj_valence_videos_pos = df_comparisons[df_comparisons[\"Segment\"]==\"Positive\"][\"RawX\"]\n",
    "\n",
    "print(f\"N = {subj_valence_videos_neg.size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative: \t98.02959270624305 +/- (6.758617657096512)\n",
      "Neutral: \t138.67576415178218 +/- (8.865937435742328)\n",
      "Positive: \t163.69917870723194 +/- (8.11508221003299)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Negative: \\t{subj_valence_videos_neg.mean()} +/- ({subj_valence_videos_neg.std()})\")\n",
    "print(f\"Neutral: \\t{subj_valence_videos_ntr.mean()} +/- ({subj_valence_videos_ntr.std()})\")\n",
    "print(f\"Positive: \\t{subj_valence_videos_pos.mean()} +/- ({subj_valence_videos_pos.std()})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "negative < neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_relResult(statistic=-11.223370960554844, pvalue=6.792985163699449e-07)\n"
     ]
    }
   ],
   "source": [
    "# Statistical test: paired t-test\n",
    "test1 = stats.ttest_rel(subj_valence_videos_neg, subj_valence_videos_ntr, alternative=\"less\")\n",
    "print(test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pos > neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_relResult(statistic=6.643668872886332, pvalue=4.721029137574939e-05)\n"
     ]
    }
   ],
   "source": [
    "test2 = stats.ttest_rel(subj_valence_videos_pos, subj_valence_videos_ntr, alternative=\"greater\")\n",
    "print(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path_text = gen_path_results(\"1_Affect_Valence_Paired-T-Tests\", extension=\".txt\")\n",
    "f = open(save_path_text, \"w\")\n",
    "f.write(\"Test 1: (H1) Negative < than Neutral:\\t\" + str(test1) + \"\\n\")\n",
    "f.write(\"Test 2: (H1) Positive > than Neutral:\\t\" + str(test2) + \"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Arousal**\n",
    "\n",
    "Analyzing average value from `RawY` from the joystick\n",
    "\n",
    "Conclusion: The `test1` rejects the possibility that negative is equal than neutral, and `test2` shows that positive videos are not equal than neutral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative: \t143.55283704999346 +/- (9.454596836654574)\n",
      "Neutral: \t109.2581978169394 +/- (8.95376800038605)\n",
      "Positive: \t140.37155023034336 +/- (8.11508221003299)\n"
     ]
    }
   ],
   "source": [
    "# Separate columns for statistical test\n",
    "subj_arousal_videos_neg = df_comparisons[df_comparisons[\"Segment\"]==\"Negative\"][\"RawY\"]\n",
    "subj_arousal_videos_ntr = df_comparisons[df_comparisons[\"Segment\"]==\"Neutral\"][\"RawY\"]\n",
    "subj_arousal_videos_pos = df_comparisons[df_comparisons[\"Segment\"]==\"Positive\"][\"RawY\"]\n",
    "\n",
    "print(f\"Negative: \\t{subj_arousal_videos_neg.mean()} +/- ({subj_arousal_videos_neg.std()})\")\n",
    "print(f\"Neutral: \\t{subj_arousal_videos_ntr.mean()} +/- ({subj_arousal_videos_ntr.std()})\")\n",
    "print(f\"Positive: \\t{subj_arousal_videos_pos.mean()} +/- ({subj_valence_videos_pos.std()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_relResult(statistic=6.815496362043647, pvalue=0.9999611567529778)\n",
      "Ttest_relResult(statistic=9.914398759998834, pvalue=1.921747364434939e-06)\n"
     ]
    }
   ],
   "source": [
    "# Statistical test: paired t-test\n",
    "test1 = stats.ttest_rel(subj_arousal_videos_neg, subj_arousal_videos_ntr, alternative=\"less\")\n",
    "print(test1)\n",
    "test2 = stats.ttest_rel(subj_arousal_videos_pos, subj_arousal_videos_ntr, alternative=\"greater\")\n",
    "print(test2)\n",
    "\n",
    "save_path_text = gen_path_results(\"1_Affect_Arousal_Paired-T-Tests\", extension=\".txt\")\n",
    "f = open(save_path_text, \"w\")\n",
    "f.write(\"Test 1: (H1) Negative < than Neutral:\\t\" + str(test1) + \"\\n\")\n",
    "f.write(\"Test 2: (H1) Positive > than Neutral:\\t\" + str(test2) + \"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxplots average ratings per video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VideoId</th>\n",
       "      <th>p_index_id</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Arousal</th>\n",
       "      <th>RawX</th>\n",
       "      <th>RawY</th>\n",
       "      <th>Segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>46.500000</td>\n",
       "      <td>179.375000</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>216.0</td>\n",
       "      <td>3.058824</td>\n",
       "      <td>7.117647</td>\n",
       "      <td>100.176471</td>\n",
       "      <td>162.617647</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>130.100000</td>\n",
       "      <td>159.450000</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>247.0</td>\n",
       "      <td>3.454545</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>108.772727</td>\n",
       "      <td>174.045455</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>Rn</td>\n",
       "      <td>34</td>\n",
       "      <td>370.0</td>\n",
       "      <td>4.942857</td>\n",
       "      <td>3.542857</td>\n",
       "      <td>134.142857</td>\n",
       "      <td>95.742857</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>Rn</td>\n",
       "      <td>35</td>\n",
       "      <td>379.0</td>\n",
       "      <td>5.525000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>144.225000</td>\n",
       "      <td>94.775000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>Rn</td>\n",
       "      <td>36</td>\n",
       "      <td>381.0</td>\n",
       "      <td>4.652174</td>\n",
       "      <td>2.913043</td>\n",
       "      <td>130.521739</td>\n",
       "      <td>75.956522</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>Rn</td>\n",
       "      <td>37</td>\n",
       "      <td>382.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.312500</td>\n",
       "      <td>188.812500</td>\n",
       "      <td>82.312500</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>Rn</td>\n",
       "      <td>38</td>\n",
       "      <td>384.0</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>126.950000</td>\n",
       "      <td>161.750000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1287 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     VideoId  p_index_id  participant_id   Valence   Arousal        RawX  \\\n",
       "0          3           0           101.0  1.000000  8.250000   46.500000   \n",
       "1          3           1           216.0  3.058824  7.117647  100.176471   \n",
       "2          3           2             NaN       NaN       NaN         NaN   \n",
       "3          3           3           222.0  4.600000  7.200000  130.100000   \n",
       "4          3           4           247.0  3.454545  7.500000  108.772727   \n",
       "...      ...         ...             ...       ...       ...         ...   \n",
       "1282      Rn          34           370.0  4.942857  3.542857  134.142857   \n",
       "1283      Rn          35           379.0  5.525000  3.400000  144.225000   \n",
       "1284      Rn          36           381.0  4.652174  2.913043  130.521739   \n",
       "1285      Rn          37           382.0  8.000000  2.312500  188.812500   \n",
       "1286      Rn          38           384.0  4.300000  6.950000  126.950000   \n",
       "\n",
       "            RawY   Segment  \n",
       "0     179.375000  Negative  \n",
       "1     162.617647  Negative  \n",
       "2            NaN  Negative  \n",
       "3     159.450000  Negative  \n",
       "4     174.045455  Negative  \n",
       "...          ...       ...  \n",
       "1282   95.742857   Neutral  \n",
       "1283   94.775000   Neutral  \n",
       "1284   75.956522   Neutral  \n",
       "1285   82.312500   Neutral  \n",
       "1286  161.750000   Neutral  \n",
       "\n",
       "[1287 rows x 8 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_avg_affect_with_segment = df_avg_per_participant_and_video.join(matching_video_segment).reset_index()\n",
    "df_avg_affect_with_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_plot_affect_boxplot_ratings(df_results, axis_to_plot, colname):\n",
    "    ax = axis_to_plot\n",
    "    # Sort groups\n",
    "    df_avg_affect_2 = df_results.copy()\n",
    "    df_avg_affect_2.sort_values(by=[\"VideoId\"], inplace=True, key= lambda col: col.map(lambda item: ([str,int].index(type(item)), item) ) ) # Make letters come before numbers\n",
    "    df_avg_affect_2.sort_values(by=[\"segment\"], ascending=True, kind=\"mergesort\", inplace=True) # Mergesort keeps respecting the previous sorting decision.\n",
    "\n",
    "    # Rename columns\n",
    "    df_avg_affect_2.rename( columns = {\n",
    "                \"Segment\":\"Exp. Segment\",\n",
    "                \"VideoId\": \"Video ID\",\n",
    "                \"Valence\":\"Avg. Valence\",\n",
    "                \"Arousal\":\"Avg. Arousal\"\n",
    "                }, inplace = True )\n",
    "    \n",
    "    sns.set_theme(style=\"ticks\")\n",
    "\n",
    "    PALETTE_COLORS = [\"darkorange\" ,\"dodgerblue\",\"forestgreen\", \"gray\"]\n",
    "\n",
    "    # Vertical lines separating the experimental sessions\n",
    "    ax.vlines([10.5, 21.5], ymin=1, ymax=9, color=\"black\", linestyle='dotted', linewidth=1.5)\n",
    "\n",
    "    # Filter the data that has to do with this column label\n",
    "    sns.boxplot(data=df_avg_affect_2, ax=ax,\n",
    "                x=\"Video ID\", y=colname, hue=\"Exp. Segment\", #orient=\"h\",\n",
    "                width=0.6, palette=PALETTE_COLORS, dodge =False,\n",
    "                # notch=True, \n",
    "                showcaps=False,\n",
    "                flierprops={\"marker\": \"x\"},\n",
    "                boxprops={\"edgecolor\": \"none\"},\n",
    "                # medianprops={\"color\": \"coral\"}\n",
    "                )\n",
    "    \n",
    "    sns.despine(offset=10, trim=True)\n",
    "    sns.move_legend(ax, loc=\"best\", title=None, frameon=False)\n",
    "\n",
    "    ax.set_ylabel(f\"Affect Rating - {colname.split('.')[-1]}\")\n",
    "    ax.grid(axis=\"y\")\n",
    "    return ax\n",
    "\n",
    "### Generate path to save and figure\n",
    "save_path_plot = gen_path_plot(f\"affect-boxplot-ratings-per-video\")\n",
    "\n",
    "NUM_ROWS = 1\n",
    "NUM_COLS = 2\n",
    "fig,axes = plt.subplots(NUM_ROWS, NUM_COLS, sharex=False, sharey=True, figsize=(8*NUM_COLS, 5*NUM_ROWS))\n",
    "\n",
    "COL_TITLES = [\"Avg. Valence\", \"Avg. Arousal\"]\n",
    "for i in range(len(COL_TITLES)):\n",
    "    axes[i] = generate_plot_affect_boxplot_ratings(df_avg_affect_with_segment, axes[i], COL_TITLES[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_path_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Load a postprocessed dataset\n",
    "\n",
    "The following blocks generate a compiled dataset as the one created during the notebook `1_...ipynb`. It contains a subset from the DRAP dataset with the relevant columns, synchronized events with physiological data, and resampled at 50Hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "DATASET_POSTPROCESSED_FILENAME = \"./temp/DRAP_1_preprocess/Dataset_DRAP_postprocessed.csv\"\n",
    "DATASET_POSTPROCESSED_FILENAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the file in memory (~700MB)\n",
    "dataset = pd.read_csv(DATASET_POSTPROCESSED_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General variables\n",
    "\n",
    "The following variables store important info about the dataset. How many participants? Which video segments are included? Which videoIds are contained in each affective segment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants_ids = dataset[\"Participant\"].unique()\n",
    "participants_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_segment_names = dataset[\"Stage\"].unique()\n",
    "experiment_segment_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_ids = dataset[\"VideoId\"].unique()\n",
    "print(np.sort(video_ids))\n",
    "# -1 refers to the resting stages, no video is presented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All rows inside the `video` stage should contain a VideoId differen than -1,\n",
    "# As -1 denotes a resting video. The following code verifies that there are no invalid rows.\n",
    "# NOTE: The result should be and empty DF.\n",
    "Q = (( dataset[\"VideoId\"]==-1) & ~(dataset[\"Stage\"].str.startswith(\"Resting_\")))\n",
    "dataset[Q]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a dictionary with the stage and their corresponding list of `VideoId`\n",
    "# Confirm the unique Video IDs in each experimental segment\n",
    "video_ids_per_segment = {}\n",
    "for segment in experiment_segment_names:\n",
    "    video_ids_per_segment[segment] = np.array([])\n",
    "    # Keep unique video ids\n",
    "    Q = ( dataset[\"Stage\"] == segment )\n",
    "    video_ids_per_segment[segment] = dataset[Q][\"VideoId\"].unique()\n",
    "video_ids_per_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The index is in the order [\"Participant\", \"AffectSegment\", \"Time\"]\n",
    "# It allows multidimensional manipulation in a 2D pandas structure\n",
    "data = dataset.set_index([\"Participant\",\"Stage\",\"Time\"])\n",
    "data.sort_index(inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARTICIPANT_IDX = 0\n",
    "# EXPERIMENTAL_SEGMENT = \"Positive\"\n",
    "# # Access the dictionary of videos existing in the segment, choose the first VideoID\n",
    "# VIDEO_ID = video_ids_per_segment[EXPERIMENTAL_SEGMENT][0] \n",
    "\n",
    "# ##\n",
    "# # Select a whole experimental segment\n",
    "# single_segment_ts = data.loc[(PARTICIPANT_IDX,EXPERIMENTAL_SEGMENT)]\n",
    "# # Select a specific video inside the experimental segment\n",
    "# single_video_ts = single_segment_ts[ single_segment_ts[\"VideoId\"] == VIDEO_ID]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining both images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Join image\n",
    "# save_path_plot = gen_path_plot(f\"affect-ratings-per-video\")\n",
    "\n",
    "# NUM_ROWS = 1\n",
    "# NUM_COLS = 3\n",
    "\n",
    "# fig,axes = plt.subplots(NUM_ROWS, NUM_COLS, sharex=False, sharey=True, figsize=(7*NUM_COLS, 4*NUM_ROWS))\n",
    "\n",
    "# axes[0] = generate_plot_affect_coordinates_ratings(axes[0], offset=[1,9])\n",
    "# axes[1] = generate_plot_affect_boxplot_ratings(axes[1], COL_TITLES[0])\n",
    "# axes[2] = generate_plot_affect_boxplot_ratings(axes[2], COL_TITLES[1])\n",
    "\n",
    "# # plt.suptitle(f\"Average over all {participants_ids.size} participants.\")\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(save_path_plot)\n",
    "# print(f\"Average over all {participants_ids.size} participants.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Load a postprocessed dataset\n",
    "\n",
    "The following blocks generate a compiled dataset as the one created during the notebook `1_...ipynb`. It contains a subset from the DRAP dataset with the relevant columns, synchronized events with physiological data, and resampled at 50Hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "DATASET_POSTPROCESSED_FILENAME = \"./temp/DRAP_1_preprocess/Dataset_DRAP_postprocessed.csv\"\n",
    "DATASET_POSTPROCESSED_FILENAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the file in memory (~700MB)\n",
    "dataset = pd.read_csv(DATASET_POSTPROCESSED_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General variables\n",
    "\n",
    "The following variables store important info about the dataset. How many participants? Which video segments are included? Which videoIds are contained in each affective segment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants_ids = dataset[\"Participant\"].unique()\n",
    "participants_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_segment_names = dataset[\"Stage\"].unique()\n",
    "experiment_segment_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_ids = dataset[\"VideoId\"].unique()\n",
    "print(np.sort(video_ids))\n",
    "# -1 refers to the resting stages, no video is presented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All rows inside the `video` stage should contain a VideoId differen than -1,\n",
    "# As -1 denotes a resting video. The following code verifies that there are no invalid rows.\n",
    "# NOTE: The result should be and empty DF.\n",
    "Q = (( dataset[\"VideoId\"]==-1) & ~(dataset[\"Stage\"].str.startswith(\"Resting_\")))\n",
    "dataset[Q]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a dictionary with the stage and their corresponding list of `VideoId`\n",
    "# Confirm the unique Video IDs in each experimental segment\n",
    "video_ids_per_segment = {}\n",
    "for segment in experiment_segment_names:\n",
    "    video_ids_per_segment[segment] = np.array([])\n",
    "    # Keep unique video ids\n",
    "    Q = ( dataset[\"Stage\"] == segment )\n",
    "    video_ids_per_segment[segment] = dataset[Q][\"VideoId\"].unique()\n",
    "video_ids_per_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The index is in the order [\"Participant\", \"AffectSegment\", \"Time\"]\n",
    "# It allows multidimensional manipulation in a 2D pandas structure\n",
    "data = dataset.set_index([\"Participant\",\"Stage\",\"Time\"])\n",
    "data.sort_index(inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA\n",
    "Exploratory Data Analysis (EDA) to visualize a particular experimental segment from a specific participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARTICIPANT_IDX = 0\n",
    "EXPERIMENTAL_SEGMENT = \"Positive\"\n",
    "# Access the dictionary of videos existing in the segment, choose the first VideoID\n",
    "VIDEO_ID = video_ids_per_segment[EXPERIMENTAL_SEGMENT][0] \n",
    "\n",
    "##\n",
    "# Select a whole experimental segment\n",
    "single_segment_ts = data.loc[(PARTICIPANT_IDX,EXPERIMENTAL_SEGMENT)]\n",
    "# Select a specific video inside the experimental segment\n",
    "single_video_ts = single_segment_ts[ single_segment_ts[\"VideoId\"] == VIDEO_ID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_segment_ts.plot.line(subplots=True, figsize=(15,1*single_segment_ts.shape[1]), sharex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_video_ts.plot.line(subplots=True, figsize=(5,1*single_video_ts.shape[1]), sharex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Analysis 2: Feature-based classification assuming independent samples\n",
    "\n",
    "Feature-based classification assuming that the features captured with overlapping windows act as independent samples, unlike in time-series classification.\n",
    "\n",
    "Feature extraction steps:\n",
    "1. Traverse the time-series data per participant and per experimental segment: (~300secs per video segment).\n",
    "2. Consider the following stages as target classes: `[Positive, Neutral, Positive]`.\n",
    "3. Take the corresponding resting stages ( `[Resting_Negative, Resting_Neutral, Resting_VideoPositive]`) to fit a standardizer ($\\mu=0,\\sigma=1$)\n",
    "4. Apply a sliding window of width `30sec` with overlap `7.5s` to extract **statistical features** (11 features per dimension) from: `[HEART, MOTOR, FACE]`.\n",
    "5. In addition, calculate **time-domain HRV features** from the non-standardized version of the PPG signal (5 features from PPG)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIG_SAMP_FREQUENCY_HZ = 50\n",
    "\n",
    "WINDOW_WIDTH_SECS = 30\n",
    "WINDOW_OVERLAP_SECS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the original dataset again\n",
    "data = dataset.copy().set_index([\"Participant\",\"Stage\",\"Time\"])\n",
    "data.sort_index(inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify groups of features\n",
    "basic_colnames = drap.preprocessing.COLNAMES_AFFECT\n",
    "hrv_colnames = drap.preprocessing.COLNAMES_HR + drap.preprocessing.COLNAMES_PPG\n",
    "imu_colnames = drap.preprocessing.COLNAMES_ACCELEROMETER + drap.preprocessing.COLNAMES_MAGNETOMETER + drap.preprocessing.COLNAMES_GYROSCOPE\n",
    "emg_colnames = drap.preprocessing.COLNAMES_EMG_AMPLITUDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify colnames that have relevant time-series data (exclude videoId, affect, etc.)\n",
    "TS_DATA_COLNAMES = hrv_colnames + imu_colnames + emg_colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_outliers_from_df(df, num_std = 5):\n",
    "    \"\"\"\n",
    "    Takes a multidimensional dataFrame and filter the values\n",
    "    that are `num_std` standard deviations away from the mean value\n",
    "    of the column.\n",
    "\n",
    "    First, it transforms the value in np.nan. Then, it imputes the\n",
    "    value with backward filling, and then with forward filling, in case\n",
    "    the missing values are generated on the extremes of the time-series.\n",
    "\n",
    "    Returns the filtered dataset\n",
    "    \"\"\"\n",
    "    mask = (( df > (df.mean() + num_std*df.std())) | ( df < (df.mean() - num_std*df.std())) )\n",
    "    df[ mask ] = np.nan\n",
    "    df_filtered = df.fillna(method=\"backfill\", axis=0)\n",
    "    df_filtered = df_filtered.fillna(method=\"ffill\", axis=0)\n",
    "    print(f\"\\tTotal NAs --> Generated={df.isna().sum().sum()} - After imputation={df_filtered.isna().sum().sum()}\")\n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Testing feature extraction in one instance*..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANCE\n",
    "PARTICIPANT_IDX = 1\n",
    "EXP_SEGMENT = str(drap.preprocessing.AffectSegments.VideosPositive)\n",
    "VIDEO_ID = video_ids_per_segment[EXP_SEGMENT][0]\n",
    "\n",
    "print(f\"participant={PARTICIPANT_IDX}, segment={EXP_SEGMENT}, video_id={VIDEO_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preparing resting stage as baseline for the scaler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from dataset data from a VIDEO segment and its corresponding RESTING stage\n",
    "single_segment_ts = data.loc[(PARTICIPANT_IDX,EXP_SEGMENT)]\n",
    "single_segment_ts = single_segment_ts[TS_DATA_COLNAMES] # Choose columns with relevant data\n",
    "\n",
    "# This resting stages will be used to normalize the values.\n",
    "single_segment_resting = data.loc[(PARTICIPANT_IDX,\"Resting_\"+EXP_SEGMENT)]\n",
    "\n",
    "print(f\"Video df shape: {single_segment_ts.shape}\")\n",
    "print(f\"Resting df shape: {single_segment_resting.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaler fitted on resting stage\n",
    "scaler = ColumnTransformer( [ \n",
    "                            (\"\", StandardScaler(), TS_DATA_COLNAMES) # Apply to all columns with TS data\n",
    "                        ])\n",
    "scaler.fit(single_segment_resting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sliding window to iterate over the signal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sliding_windows(df_ts, \n",
    "                        window_width_seconds,\n",
    "                        window_overlap_seconds,\n",
    "                        verbose = False\n",
    "                        ):\n",
    "    \"\"\"\n",
    "    Iterates over the dataframe in `df_ts` with overlapping windows\n",
    "    defined by `window_width_seconds` and `window_overlap_seconds`.\n",
    "\n",
    "    This function assumes that the index of `df_ts` is in seconds\n",
    "    and is sorted incrementally.\n",
    "    Returns a list of tuples with the (start,end) of each window\n",
    "    \"\"\"\n",
    "    # Generate iterator\n",
    "    w_start_indices = np.arange(df_ts.index[0], df_ts.index[-1], window_overlap_seconds)\n",
    "    return [ (w, w+window_width_seconds) for w in w_start_indices ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_sliding_windows(single_segment_ts,\n",
    "                        window_overlap_seconds = WINDOW_OVERLAP_SECS,\n",
    "                        window_width_seconds = WINDOW_WIDTH_SECS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select first window\n",
    "df_window = single_segment_ts.loc[0:WINDOW_WIDTH_SECS]\n",
    "df_window.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract HRV features from PPG**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_hrv_features(df_ppg, sampling_frequency, return_plot=False):\n",
    "    \"\"\"\n",
    "    Receives a dataframe with ppg data and returns\n",
    "    time-domain features.\n",
    "    \"\"\"\n",
    "    signals, info = nk.ppg_process(df_ppg, sampling_rate=sampling_frequency)\n",
    "    peaks = signals.PPG_Peaks\n",
    "\n",
    "    ## Plot summary\n",
    "    # nk.ppg_plot(signals, sampling_rate=ORIG_SAMP_FREQUENCY_HZ)\n",
    "\n",
    "    # Time-based features\n",
    "    hrv_time = nk.hrv_time(peaks, sampling_rate=sampling_frequency, show=False)\n",
    "\n",
    "    # `TODO: See HRV_time() from drap utils.`\n",
    "\n",
    "    # HRV features from neurokit2 that should be forwarded for final dataset\n",
    "    HRV_SUBSET_FEATURES = [\"HRV_MeanNN\",\"HRV_SDNN\",\"HRV_RMSSD\",\"HRV_MedianNN\", \"HRV_IQRNN\"]\n",
    "    hrv_time_features = hrv_time[ HRV_SUBSET_FEATURES ]\n",
    "\n",
    "    # ## NOTE: Frequency features are not used because the window width may not enough for most features!\n",
    "    # hrv_freq = nk.hrv_frequency(peaks, sampling_rate=ts_sampling_freq, show=True, normalize=True)\n",
    "    # hrv_allfeatures = nk.hrv(peaks, sampling_rate=ts_sampling_freq, show=True)\n",
    "\n",
    "    #### Save figure when `show=True`\n",
    "    # save_path_plot = gen_path_plot(f\"Preprocessing/PPG/Participant{participant}_{segment}\")\n",
    "    # fig = plt.gcf().set_size_inches(8, 5)\n",
    "    # plt.tight_layout()\n",
    "    # plt.savefig(save_path_plot)\n",
    "    # plt.close()\n",
    "    return hrv_time_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `TODO:`\n",
    "\n",
    "- Fix: Check HRV_TIim\n",
    "- Check a way to filter PPG s reliability - FitState? FacePlate? ProximitY?\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPG_COLNAME = 'Ppg/Raw.ppg'     \n",
    "calculate_hrv_features(df_window[PPG_COLNAME], ORIG_SAMP_FREQUENCY_HZ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract statistical features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_statistical_features(df):\n",
    "    \"\"\"\n",
    "    Calculates the following features per column in the dataframe,\n",
    "    adding a suffix for each processed column:\n",
    "        - mean:     mean\n",
    "        - std:      standard devaition\n",
    "        - min:      minimum value\n",
    "        - max:      maximum value\n",
    "        - median:   median\n",
    "        - irq:      interquartile range\n",
    "        - pnv:      proportion of negative values\n",
    "        - ppv:      proportion of positive values\n",
    "        - skew:     skewness of the distribution\n",
    "        - kurt:     kurtosis of the distribution\n",
    "        - energy:   sum of squared absolute values\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        df = pd.DataFrame(df)\n",
    "\n",
    "    FUNCTIONS_FEATURES = {\n",
    "        \"mean\":     np.mean,\n",
    "        \"std\":      np.std,\n",
    "        \"min\":      np.min,\n",
    "        \"max\":      np.max,\n",
    "        \"median\":   np.median,\n",
    "        \"irq\":      stats.iqr,\n",
    "        \"pnv\":      (lambda y: y[y<0].size/y.size),\n",
    "        \"ppv\":      (lambda y: y[y>0].size/y.size),\n",
    "        \"skew\":     stats.skew,\n",
    "        \"kurt\":     stats.kurtosis,\n",
    "        \"energy\":   (lambda y: np.sum(np.abs(y)**2) ),\n",
    "    }\n",
    "    \n",
    "    # Store results with features per columns\n",
    "    df_features_results = { }\n",
    "\n",
    "    for feat_name,feat_func in FUNCTIONS_FEATURES.items():\n",
    "        for col_name in list(df.columns):\n",
    "            df_features_results[f\"{col_name}_{feat_name}\"] = [ feat_func(df[col_name]) ]\n",
    "\n",
    "    return pd.DataFrame(df_features_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply standardization on the VIDEO experimental stage\n",
    "# Normalize the data from each participant w.r.t to the same variable during the corresponding resting stage.\n",
    "df_window_norm = pd.DataFrame(data = scaler.transform(df_window), \n",
    "                                                columns = TS_DATA_COLNAMES, \n",
    "                                                index = df_window.index)\n",
    "\n",
    "\"\"\" Create statistical feature \"\"\"\n",
    "statistical_features = calculate_statistical_features(df_window_norm)\n",
    "statistical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(statistical_features.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_ts_window(data_df_window, ts_sampling_freq:float,\n",
    "                                    colname_ppg:str,\n",
    "                                    fitted_scaler:object,\n",
    "                                    columns_to_normalize:list):\n",
    "    \"\"\"\n",
    "    Takes a dataframe and extracts HRV and summary features from it\n",
    "    Returns a dataframe with one row combining all features.\n",
    "    \"\"\"\n",
    "    df_window = data_df_window\n",
    "    \n",
    "    # Extract HRV features from PPG\n",
    "    hrv_time_features = calculate_hrv_features(df_window[colname_ppg], ts_sampling_freq)\n",
    "    \n",
    "    \"\"\" Create statistical feature \"\"\"\n",
    "    # Apply standardization on the VIDEO experimental stage\n",
    "    # Normalize the data from each participant w.r.t to the same variable during the corresponding resting stage.\n",
    "    df_window_norm = pd.DataFrame(data = fitted_scaler.transform(df_window), \n",
    "                                                    columns = columns_to_normalize, \n",
    "                                                    index = df_window.index)\n",
    "    \n",
    "    statistical_features = calculate_statistical_features(df_window_norm)\n",
    "\n",
    "    df_result = pd.concat([hrv_time_features, statistical_features], axis=1)\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_features_from_ts_window(single_segment_ts, ORIG_SAMP_FREQUENCY_HZ,\n",
    "                                PPG_COLNAME, scaler,\n",
    "                                columns_to_normalize=TS_DATA_COLNAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying feature extraction to all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_BASED_DATASET_FILENAME = gen_path_temp(\"Dataset_DRAP_ManualFeaturesHRVandStatistics\", extension=\".csv\")\n",
    "\n",
    "df_feature_extraction = None\n",
    "\n",
    "if (os.path.isfile(FEATURE_BASED_DATASET_FILENAME)):\n",
    "    df_feature_extraction = pd.read_csv(FEATURE_BASED_DATASET_FILENAME)\n",
    "else:\n",
    "    # Iterate over participants\n",
    "    for participant in participants_ids:\n",
    "        # Iterate over segments\n",
    "        for segment in [ str(x) for x in drap.preprocessing.utils.enums.AffectSegments]:\n",
    "\n",
    "            \"\"\" Load data from RESTING stages to standardize the data during VIDEO\"\"\"\n",
    "            # Extract data from RESTING stage\n",
    "            single_segment_resting = data.loc[(participant,\"Resting_\"+segment)]\n",
    "            single_segment_resting = single_segment_resting[ TS_DATA_COLNAMES ]\n",
    "\n",
    "            # Filter datapoints that are larger than N*std\n",
    "            single_segment_resting = filter_outliers_from_df(single_segment_resting)\n",
    "\n",
    "            # Standardizer per column over data in the resting stage\n",
    "            scaler = ColumnTransformer( [ \n",
    "                                        (\"\", StandardScaler(), TS_DATA_COLNAMES) # Apply to all columns with TS data\n",
    "                                    ])\n",
    "            scaler.fit(single_segment_resting)\n",
    "\n",
    "            \"\"\" Load data from VIDEO stage and filter it  \"\"\"\n",
    "            # Extract data from VIDEO stage\n",
    "            single_segment_ts = data.loc[(participant,segment)]\n",
    "            single_segment_ts = single_segment_ts[ TS_DATA_COLNAMES ]\n",
    "            \n",
    "            # Filter datapoints that are larger than N*std\n",
    "            single_segment_ts = filter_outliers_from_df(single_segment_ts)\n",
    "\n",
    "            \"\"\" Generate indices for sliding windows \"\"\"\n",
    "            window_indices = generate_sliding_windows(single_segment_ts,\n",
    "                                                window_width_seconds = WINDOW_WIDTH_SECS,\n",
    "                                                window_overlap_seconds = WINDOW_OVERLAP_SECS,\n",
    "                                                verbose=True)\n",
    "\n",
    "            # Iterator to generate sliding windows\n",
    "            for w_counter, (w_start, w_end) in enumerate(window_indices):\n",
    "                df_window = single_segment_ts.loc[w_start:w_end]\n",
    "\n",
    "                # To avoid non-complete window sizes. \n",
    "                # Analyze the window if the number of samples is >95% of expected number of samples\n",
    "                if(df_window.shape[0] < 0.95*WINDOW_WIDTH_SECS*ORIG_SAMP_FREQUENCY_HZ):\n",
    "                    print(f\"Skipping window: Fewer samples than expected in [{w_start},{w_end}] - Samples: {df_window.shape[0]}<95%*{WINDOW_WIDTH_SECS*ORIG_SAMP_FREQUENCY_HZ}\")\n",
    "                    continue\n",
    "            \n",
    "                # DataFrame with general information and target class in \"segment\"\n",
    "                df_this_feature_extraction = pd.DataFrame({\n",
    "                                                \"participant\":  [participant],\n",
    "                                                \"segment\":      [segment],\n",
    "                                                \"i_window\":     [w_counter],\n",
    "                                            })\n",
    "                \n",
    "                \"\"\" Extract HRV and statistical features from window \"\"\"\n",
    "                all_features = extract_features_from_ts_window(single_segment_ts, \n",
    "                                                                ORIG_SAMP_FREQUENCY_HZ,\n",
    "                                                                PPG_COLNAME, scaler,\n",
    "                                                                columns_to_normalize=TS_DATA_COLNAMES)\n",
    "\n",
    "                \"\"\" Create final feature vector for the window\"\"\"\n",
    "                df_this_feature_extraction = pd.concat([df_this_feature_extraction, all_features], axis=1)\n",
    "                \n",
    "                df_feature_extraction = df_this_feature_extraction if (df_feature_extraction is None) else pd.concat([df_feature_extraction, df_this_feature_extraction], axis=0, ignore_index=True)\n",
    "\n",
    "\n",
    "                # Saving .csv\n",
    "                df_feature_extraction.to_csv( FEATURE_BASED_DATASET_FILENAME, index=False)\n",
    "\n",
    "                \"\"\" Save plots with HRV features \"\"\"\n",
    "                        \n",
    "                # # Save HRV features plot\n",
    "                # save_path_plot = gen_path_plot(f\"Features/Participant{participant}/HRV_{segment}_w{w}\")\n",
    "                # fig = plt.gcf().set_size_inches(8, 5)\n",
    "                # plt.tight_layout()\n",
    "                # plt.savefig(save_path_plot)\n",
    "                # plt.close(fig)\n",
    "\n",
    "                # # Save PPG plot\n",
    "                # save_path_plot = gen_path_plot(f\"Features/Participant{participant}/PPG_{segment}_w{w}\")\n",
    "                # nk.ppg_plot(signals, sampling_rate=ORIG_SAMP_FREQUENCY_HZ)\n",
    "                # fig = plt.gcf().set_size_inches(8, 5)\n",
    "                # plt.tight_layout()\n",
    "                # plt.savefig(save_path_plot)\n",
    "                # plt.close(fig)\n",
    "\n",
    "                # # # Save statistical features plot - TAKES TOO LONG!\n",
    "                # # save_path_plot = gen_path_plot(f\"Features/Participant{participant}/{segment}_{w}_ALL\")\n",
    "                # # statistical_features.plot(subplots=True,figsize=(10,2*statistical_features.shape[1]))\n",
    "                # # plt.savefig(save_path_plot)\n",
    "                # # plt.close(fig)\n",
    "\n",
    "        # df_feature_extraction.reset_index(drop=True, inplace=True)\n",
    "    print(\"\\n\\n End\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a LARGE figure with all the features\n",
    "df_feature_extraction.plot(subplots=True,figsize=(3*participants_ids.size,2*df_feature_extraction.shape[1]))\n",
    "save_path_plot = gen_path_plot(f\"features/_ALL\")\n",
    "# plt.savefig(save_path_plot)\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RELOAD_TRIES = 3\n",
    "    \n",
    "# # Where the compiled dataset will be stored\n",
    "# FEATURE_BASED_DATASET_FILENAME = gen_path_temp(\"Dataset_DRAP_ManualFeaturesHRVandStatistics\", extension=\".csv\")\n",
    "\n",
    "# # DF containing the final dataframe for classification\n",
    "# df_feature_extraction = None\n",
    "\n",
    "# ### INPUTS / OUTPUTS\n",
    "# \"\"\"EDIT CUSTOM FILENAMES\"\"\"\n",
    "# input_files = [FEATURE_BASED_DATASET_FILENAME]\n",
    "\n",
    "# # Try to load files maximum two times\n",
    "# for tries in range(RELOAD_TRIES):\n",
    "#     try:\n",
    "#         ### LOAD FILE\n",
    "#         print(f\"Trying {tries+1}/{RELOAD_TRIES} to load files: {input_files}\")\n",
    "        \n",
    "#         ### CUSTOM SECTION TO READ FILES\n",
    "#         \"\"\"EDIT CUSTOM READ\"\"\"\n",
    "#         df_feature_extraction = pd.read_csv(input_files[0])\n",
    "#         print(f\"File {input_files[0]} was successfully loaded\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         ### CREATE FILE\n",
    "#         print(f\"File not found. Creating again! {e}\")\n",
    "\n",
    "#         ### CUSTOM SECTION TO CREATE FILES \n",
    "#         \"\"\"EDIT CUSTOM WRITE\"\"\"\n",
    "\n",
    "#         # Iterate over participants\n",
    "#         for participant in participants_ids:\n",
    "#             # Iterate over segments\n",
    "#             for segment in [\"VideoNegative\", \"VideoPositive\"]:\n",
    "\n",
    "#                 \"\"\" Take the data from RESTING stages to standardize the data during VIDEO\"\"\"\n",
    "#                 # Extract data from RESTING stage\n",
    "#                 single_segment_resting = data.loc[(participant,\"Resting_\"+segment)]\n",
    "#                 single_segment_resting = single_segment_resting[ TS_DATA_COLNAMES ]\n",
    "\n",
    "#                 # Filter datapoints that are larger than N*std\n",
    "#                 single_segment_resting = filter_outliers_from_df(single_segment_resting)\n",
    "\n",
    "#                 # Standardizer per column over data in the resting stage\n",
    "#                 scaler = ColumnTransformer( [ \n",
    "#                                             (\"\", StandardScaler(), TS_DATA_COLNAMES) # Apply to all columns with TS data\n",
    "#                                         ])\n",
    "#                 scaler.fit(single_segment_resting)\n",
    "\n",
    "#                 \"\"\" Create overlapping windows \"\"\"\n",
    "#                 # Extract data from VIDEO stage\n",
    "#                 single_segment_ts = data.loc[(participant,segment)]\n",
    "#                 single_segment_ts = single_segment_ts[ TS_DATA_COLNAMES ]\n",
    "                \n",
    "#                 # Filter datapoints that are larger than N*std\n",
    "#                 single_segment_ts = filter_outliers_from_df(single_segment_ts)\n",
    "\n",
    "                \n",
    "\n",
    "#                 # Iterator to generate sliding windows\n",
    "#                 for w, window_start in enumerate(np.arange(0, single_segment_ts.index[-1], WINDOW_OVERLAP_SECS)):\n",
    "#                     window_end = window_start + WINDOW_WIDTH_SECS\n",
    "#                     df_window = single_segment_ts.loc[window_start:window_end]\n",
    "\n",
    "#                     # To avoid non-complete window sizes. \n",
    "#                     # Analyze the window if the number of samples is >95% of expected number of samples\n",
    "#                     if(df_window.shape[0] >= 0.95*WINDOW_WIDTH_SECS*ORIG_SAMP_FREQUENCY_HZ):\n",
    "#                         # print(window_start, window_end, df_window.shape)\n",
    "\n",
    "#                         # DataFrame with general information and target class in \"segment\"\n",
    "#                         df_this_feature_extraction = pd.DataFrame({\n",
    "#                                                         \"participant\":  [participant],\n",
    "#                                                         \"segment\":      [segment],\n",
    "#                                                         \"i_window\":     [w],\n",
    "#                                                     })\n",
    "\n",
    "#                         \"\"\" Extract HRV features from original data window\"\"\"\n",
    "#                         # Extract HRV features from PPG\n",
    "#                         ppg = df_window.PPG\n",
    "#                         signals, info = nk.ppg_process(ppg, sampling_rate=ORIG_SAMP_FREQUENCY_HZ)\n",
    "#                         peaks = signals.PPG_Peaks\n",
    "#                         hrv_time = nk.hrv_time(peaks, sampling_rate=ORIG_SAMP_FREQUENCY_HZ, show=True) # NOTE: Change `show=True` if uncommenting before\n",
    "#                         hrv_time_features = hrv_time[ HRV_SUBSET_FEATURES ]\n",
    "#                         ### NOTE: Frequency features are not used because 15sec window is not enough for most features!\n",
    "#                         # hrv_freq = nk.hrv_frequency(peaks, sampling_rate=ORIG_SAMP_FREQUENCY_HZ, show=True, normalize=True)\n",
    "#                         # hrv_allfeatures = nk.hrv(peaks, sampling_rate=ORIG_SAMP_FREQUENCY_HZ, show=True)\n",
    "\n",
    "#                         \"\"\" Apply standardization to the data from the window \"\"\"\n",
    "#                         # Extract data from experimental segment\n",
    "#                         df_window = df_window       ## Where the data is contained\n",
    "#                         # Apply standardization on the VIDEO experimental stage\n",
    "#                         # Normalize the data from each participant w.r.t to the same variable during the corresponding resting stage.\n",
    "#                         df_window_norm = pd.DataFrame(data = scaler.transform(df_window), \n",
    "#                                                                         columns = TS_DATA_COLNAMES, \n",
    "#                                                                         index = df_window.index)\n",
    "\n",
    "#                         \"\"\" Create statistical feature \"\"\"\n",
    "#                         statistical_features = calculate_statistical_features(df_window_norm)\n",
    "\n",
    "#                         \"\"\" Create final feature vector for the window\"\"\"\n",
    "#                         df_this_feature_extraction = pd.concat([df_this_feature_extraction, hrv_time_features, statistical_features], axis=1)\n",
    "\n",
    "#                         df_feature_extraction = df_this_feature_extraction if (df_feature_extraction is None) else pd.concat([df_feature_extraction, df_this_feature_extraction], axis=0)\n",
    "\n",
    "\n",
    "#                         \"\"\" Save plots with HRV features \"\"\"\n",
    "                                \n",
    "#                         # Save HRV features plot\n",
    "#                         save_path_plot = gen_path_plot(f\"Features/Participant{participant}/HRV_{segment}_w{w}\")\n",
    "#                         fig = plt.gcf().set_size_inches(8, 5)\n",
    "#                         plt.tight_layout()\n",
    "#                         plt.savefig(save_path_plot)\n",
    "#                         plt.close(fig)\n",
    "\n",
    "#                         # Save PPG plot\n",
    "#                         save_path_plot = gen_path_plot(f\"Features/Participant{participant}/PPG_{segment}_w{w}\")\n",
    "#                         nk.ppg_plot(signals, sampling_rate=ORIG_SAMP_FREQUENCY_HZ)\n",
    "#                         fig = plt.gcf().set_size_inches(8, 5)\n",
    "#                         plt.tight_layout()\n",
    "#                         plt.savefig(save_path_plot)\n",
    "#                         plt.close(fig)\n",
    "\n",
    "#                         # # Save statistical features plot - TAKES TOO LONG!\n",
    "#                         # save_path_plot = gen_path_plot(f\"Features/Participant{participant}/{segment}_{w}_ALL\")\n",
    "#                         # statistical_features.plot(subplots=True,figsize=(10,2*statistical_features.shape[1]))\n",
    "#                         # plt.savefig(save_path_plot)\n",
    "#                         # plt.close(fig)\n",
    "\n",
    "#             df_feature_extraction.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "#         \"\"\" Save large figure visualizing all the new dataset\"\"\"\n",
    "#         # Save a LARGE figure with all the features\n",
    "#         save_path_plot = gen_path_plot(f\"Features/_ALL\")\n",
    "#         df_feature_extraction.plot(subplots=True,figsize=(3*participants_ids.size,2*df_feature_extraction.shape[1]))\n",
    "#         plt.savefig(save_path_plot)\n",
    "#         plt.close()\n",
    "\n",
    "#     # Saving .csv\n",
    "#     df_feature_extraction.to_csv( input_files[0], index=False)\n",
    "#     print(\"\\n\\n End\")\n",
    "    \n",
    "#     # Finish iteration\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Analysis 3: Classification\n",
    "\n",
    "- Select subset of features: `[Cardiac, Motor, Facial]`\n",
    "- Configure the train-test strategy for CV with [Leave-One-Subject-Out (LOSO)](https://scikit-learn.org/stable/modules/cross_validation.html#leave-one-group-out)\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X = df_feature_extraction.drop([\"segment\"], axis=1)\n",
    "data_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Y = df_feature_extraction[\"segment\"].map(CLASSES_MAPPING)\n",
    "data_Y.value_counts().plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_participant = df_feature_extraction.participant\n",
    "data_participant.value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection per data modality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrv_colnames = data_X.columns[ [ (col.startswith(\"HR\")| col.startswith(\"PPG\")) for col in data_X.columns] ].sort_values().values\n",
    "hrv_colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imu_colnames = data_X.columns[ [ (col.startswith(\"ACC\")) for col in data_X.columns] ].sort_values().values\n",
    "imu_colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emg_colnames = data_X.columns[ [ (col.startswith(\"EMG\")) for col in data_X.columns] ].sort_values().values\n",
    "emg_colnames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation plots\n",
    "\n",
    "Standardize [$\\mathcal{N}(0,1)$] each of the column features and map the correlation among variables and vs. target variable `segment`.\n",
    "\n",
    "*Generating these images take about >3h if facial features are included*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test plot\n",
    "# save_path_plot = gen_path_plot(f\"Features/_CorrelationPlot_test\")\n",
    "# df_plot = df_feature_extraction[hrv_colnames[:5]]\n",
    "# df_plot = pd.DataFrame(data=StandardScaler().fit_transform(df_plot), \n",
    "#                         columns=df_plot.columns, \n",
    "#                         index=df_plot.index)\n",
    "# sns.pairplot(pd.concat([data_Y, df_plot], axis=1),\n",
    "#                 kind=\"reg\",\n",
    "#                 diag_kind=\"kde\")\n",
    "# plt.savefig(save_path_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name and columns of the corresponding data modalities\n",
    "corr_plots_config = {\n",
    "    \"hrv\": hrv_colnames,\n",
    "    \"imu\": imu_colnames,\n",
    "    \"emg\": emg_colnames,\n",
    "}\n",
    "\n",
    "for k,v in corr_plots_config.items():\n",
    "    # Select subfeatures from large dataset\n",
    "    df_plot = df_feature_extraction[v]\n",
    "    # Standardize the features (but not the target)\n",
    "    df_plot = pd.DataFrame(data=StandardScaler().fit_transform(df_plot), \n",
    "                            columns=df_plot.columns, \n",
    "                            index=df_plot.index)\n",
    "    # Concatenate target and features from the specific modality\n",
    "    df_plot = pd.concat([data_Y, df_plot],axis=1)\n",
    "\n",
    "    #### SNS Pairplot - Takes a long time!! Around 3 hours for facial features. 10 mins for others!\n",
    "    # # save_path_plot = gen_path_plot(f\"Features/_PairPlot_{k}\")\n",
    "    # # sns.pairplot(df_plot, kind=\"reg\", diag_kind=\"kde\")\n",
    "    # # plt.savefig(save_path_plot)\n",
    "    # # plt.close()\n",
    "\n",
    "    # Generate correlation plot and save DataFrame as HTML (it's not a matplotlib Figure)\n",
    "    save_path_plot = gen_path_plot(f\"Features/_CorrelationPlot_{k}\", extension=\".html\")\n",
    "    corr = df_plot.corr()\n",
    "    corr_style = corr.style.background_gradient(cmap='coolwarm', axis=None).format(precision=2)\n",
    "    corr_style.to_html(save_path_plot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification models\n",
    "\n",
    "Important reading:\n",
    "- [Common pitfalls in the interpretation of coeffs in linear models.](https://scikit-learn.org/stable/auto_examples/inspection/plot_linear_model_coefficient_interpretation.html#sphx-glr-auto-examples-inspection-plot-linear-model-coefficient-interpretation-py)\n",
    "\n",
    "Methods to compare:\n",
    "- **Linear SVM with Lasso Regularization:** The L1-regularization tends to prefer solution with fewer non-zero coefficients compared to L2 (Ridge) regression, thus reducing the number of features upon which the given solution is dependent. As we intend to highlight the most important features, we use this regression as a baseline method.\n",
    "- *Others in the variable `classifiers_hyperparams`*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Testing Classification pipeline*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example of iterator for Cross-validation per subject\n",
    "\n",
    "# Feature subset\n",
    "feature_subset_colnames = hrv_colnames   # imu_colnames, emg_colnames\n",
    "\n",
    "# Features\n",
    "x = data_X[feature_subset_colnames]\n",
    "# Target\n",
    "y = data_Y\n",
    "# Groups indices (participants' ids)\n",
    "group_cv = data_participant\n",
    "\n",
    "loso_cv = LeaveOneGroupOut()\n",
    "cv_splits = loso_cv.split(x, y, groups=group_cv)\n",
    "for trn_idx, tst_idx in cv_splits:\n",
    "    print(\"TRN: %s \\t TST: %s\" % (data_participant[trn_idx].unique(), data_participant[tst_idx].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_modality_colnames = { \n",
    "            \"hrv\": hrv_colnames, \n",
    "            \"imu\": imu_colnames, \n",
    "            \"emg\": emg_colnames,\n",
    "            \"all\": list(hrv_colnames) + list(imu_colnames) + list(emg_colnames),\n",
    "    }\n",
    "\n",
    "# ClassifierName: {\"clf\":model, \"pgrid\":parameters)\n",
    "classifiers_hyperparams = {\n",
    "    # \"LinearLasso\": {    \"clf\": Lasso(alpha=0.01, max_iter=10000),\n",
    "    #                     \"pgrid\": {'alpha': np.logspace(-5, 5,11) }},\n",
    "    \"LinearRidge\": {    \"clf\": RidgeClassifier(alpha=0.01, max_iter=1000),\n",
    "                        \"pgrid\": {'alpha': np.logspace(-5, 5,11) }},\n",
    "    \"LinearSVM\": {      \"clf\": LinearSVC(C = 1, penalty=\"l1\", dual=False, max_iter=20000),\n",
    "                        \"pgrid\": {'C': [1, 10, 100, 1000]}},\n",
    "    \"GaussianSVM\": {    \"clf\": SVC(kernel='rbf', gamma='auto', C = 1),\n",
    "                        \"pgrid\": {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001]}},\n",
    "    \"RF\": {             \"clf\": RandomForestClassifier(criterion='entropy', random_state=experiment_config.MC_RANDOM_SEED),\n",
    "                        \"pgrid\": {'n_estimators': [10, 50, 100], 'max_depth': [5, 10, 20]}},\n",
    "    # \"KNN\": {            \"clf\": KNeighborsClassifier(),\n",
    "    #                     \"pgrid\": {'n_neighbors': [3, 5, 7, 13, 15]}},\n",
    "    # \"GBM\": {            \"clf\": GradientBoostingClassifier(criterion='friedman_mse', random_state=experiment_config.MC_RANDOM_SEED),\n",
    "    #                     \"pgrid\": {'n_estimators': [10, 20, 50], 'max_depth': [5, 10, 20]}},\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Where the compiled dataset will be stored\n",
    "MODEL_TRAINING_RESULTS_FILENAME = gen_path_results(\"2_Results_ModelTrainingCV_PerModalityPerSubject\", extension=\".csv\")\n",
    "\n",
    "# Load or create dataframe with results\n",
    "df_results_hyperparam_opt = None\n",
    "\n",
    "\n",
    "### INPUTS / OUTPUTS\n",
    "\"\"\"EDIT CUSTOM FILENAMES\"\"\"\n",
    "input_files = [MODEL_TRAINING_RESULTS_FILENAME]\n",
    "\n",
    "# Try to load files maximum two times\n",
    "for tries in range(RELOAD_TRIES):\n",
    "    try:\n",
    "        ### LOAD FILE\n",
    "        print(f\"Trying {tries+1}/{RELOAD_TRIES} to load files: {input_files}\")\n",
    "        \n",
    "        ### CUSTOM SECTION TO READ FILES\n",
    "        \"\"\"EDIT CUSTOM READ\"\"\"\n",
    "        df_results_hyperparam_opt = pd.read_csv(input_files[0])\n",
    "        print(f\"File {input_files[0]} was successfully loaded\")\n",
    "        break\n",
    "\n",
    "    except Exception as e:\n",
    "        ### CREATE FILE\n",
    "        print(f\"File not found. Creating again! {e}\")\n",
    "        \n",
    "        ### CUSTOM SECTION TO CREATE FILES \n",
    "        \"\"\"EDIT CUSTOM WRITE\"\"\"\n",
    "\n",
    "\n",
    "        #### ITERATION FOR THE EXPERIMENT\n",
    "        ## Iteration per data type\n",
    "        for modality_name, modality_colnames in data_modality_colnames.items(): \n",
    "            # modality_name = \"hrv\"\n",
    "            # modality_colnames = data_modality_colnames[modality_name]\n",
    "            #### ABOVE FOR TESTING\n",
    "\n",
    "            # Subset of features\n",
    "            data_mod_x = data_X[modality_colnames].values.copy()   # Features\n",
    "            data_mod_y = data_Y.values.copy()       # Target\n",
    "            subject_ids = data_participant.values.copy()  # Groups indices (participants' ids)\n",
    "\n",
    "            # Split dataset with LOSO-CV\n",
    "            cv_loso_subj = LeaveOneGroupOut()\n",
    "            cv_splits_subjects = cv_loso_subj.split(data_mod_x, data_mod_y, groups=subject_ids)\n",
    "\n",
    "            # Iteration per subject (participant)\n",
    "            for trn_subj_idx, tst_subj_idx in cv_splits_subjects:\n",
    "\n",
    "                # The dataset that is not belonging to the TEST subject will be further divided for hyperparam optimization.\n",
    "                x = data_mod_x[trn_subj_idx]             # Data to be used to create a model for TEST subject\n",
    "                x_test_subj = data_mod_x[tst_subj_idx]   \n",
    "                y = data_mod_y[trn_subj_idx]\n",
    "                y_test_subj = data_mod_y[tst_subj_idx]\n",
    "                subjects_cv = data_participant[trn_subj_idx].values\n",
    "                subject_in_test_set = np.unique(data_participant[tst_subj_idx].values)[0]   # Store the participant id in the test set\n",
    "                \n",
    "                # print(f\"TRAIN SUBJECT IDS: {np.unique(subjects_cv)} \\t TEST SUBJECT: {subject_in_test_set}\")\n",
    "                # print(f\"SHAPE : x:{x.shape}, x_test_subj:{x_test_subj.shape}, y:{y.shape}, y_test_subj:{y_test_subj.shape}, subjects_cv:{subjects_cv.shape}\")\n",
    "\n",
    "                # Create pipeline\n",
    "                scaler = StandardScaler().fit(x)\n",
    "                x_scaled = scaler.transform(x)\n",
    "\n",
    "                for clf_name, clf_data in classifiers_hyperparams.items(): \n",
    "                    # clf_name = \"GaussianSVM\"\n",
    "                    # clf_data = classifiers_hyperparams[clf_name]\n",
    "                    #### ABOVE FOR TESTING\n",
    "\n",
    "                    clf = clf_data[\"clf\"]\n",
    "                    pgrid = clf_data[\"pgrid\"]\n",
    "                    \n",
    "                    # Leave-One-Subject-Out CV also to optimize the hyperparameters and select a model\n",
    "                    cv_loso_fold = LeaveOneGroupOut()\n",
    "                    cv_fold_per_subject = cv_loso_subj.split(x, y, groups = subjects_cv)    \n",
    "\n",
    "                    gr_search = GridSearchCV(clf, pgrid, cv=cv_fold_per_subject, scoring=SCORING_METRICS, refit=\"accuracy\", n_jobs=-1)\n",
    "                    gr_search.fit(x_scaled, y)\n",
    "\n",
    "                    # Get results per fold and add best results\n",
    "                    df_this_hyperparam_optim = pd.DataFrame(gr_search.cv_results_)\n",
    "                    df_this_hyperparam_optim.insert(0,\"best_trn_score_\", str(gr_search.best_score_))\n",
    "                    df_this_hyperparam_optim.insert(0,\"best_params_\", str(gr_search.best_params_))\n",
    "                    df_this_hyperparam_optim.insert(0,\"best_estimator_\", str(gr_search.best_estimator_))\n",
    "\n",
    "                    # Insert general information in long format\n",
    "                    df_this_hyperparam_optim.insert(0,\"classifier\", clf_name)\n",
    "                    df_this_hyperparam_optim.insert(0, \"test_subject_id\",subject_in_test_set)\n",
    "                    df_this_hyperparam_optim.insert(0, \"data_modality\", modality_name)\n",
    "                    df_this_hyperparam_optim.insert(0, \"pipeline_step\", \"hyperparam_opt\")\n",
    "\n",
    "                    # Append to the main dataframe with the results \n",
    "                    df_results_hyperparam_opt = df_this_hyperparam_optim if (df_results_hyperparam_opt is None) else pd.concat([df_results_hyperparam_opt, df_this_hyperparam_optim], axis=0, ignore_index=True)\n",
    "                \n",
    "                # End of classifiers\n",
    "            # End of subjects\n",
    "            # Saving .csv\n",
    "            df_results_hyperparam_opt.to_csv( input_files[0], index=False)\n",
    "\n",
    "            #End of data modalities\n",
    "            print(\"The experimental setup has finished\")\n",
    "\n",
    "        ## ---- CONTROL RETRIES\n",
    "        if tries+1 < RELOAD_TRIES:\n",
    "            continue\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "print(\"\\n\\n End\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TODO:` Summarize the classification task in plots. Perhaps a critical diagram difference showing the ranks of each classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_hyperparam_opt.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary_classif = df_results_hyperparam_opt[ (df_results_hyperparam_opt.classifier != \"LinearLasso\") & (df_results_hyperparam_opt.rank_test_accuracy == 1) ]\n",
    "# df_summary_classif.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plots:**\n",
    "- What is the mean and std accuracy of each classifier (best at hyperparam optimization process) among the 15 participants, per data modality?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of test results\n",
    "dd = df_summary_classif.groupby([\"test_subject_id\", \"data_modality\",\"classifier\"]).first()[ [\"mean_test_accuracy\",\"std_test_accuracy\"] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean test accuracy among 15 participants per data modality\n",
    "df_temp_mean = dd[\"mean_test_accuracy\"].unstack(level=\"test_subject_id\").mean(axis=1)\n",
    "df_temp_std = dd[\"std_test_accuracy\"].unstack(level=\"test_subject_id\").mean(axis=1)\n",
    "\n",
    "df_temp_mean.unstack(level=\"classifier\").plot.bar(figsize=(6,4), yerr = df_temp_std.unstack(level=\"classifier\"))\n",
    "plt.legend(bbox_to_anchor=(0, 1, 1, 0), loc=\"lower left\", mode=\"expand\", ncol=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean test accuracy among 7 classifiers per participant\n",
    "df_temp_mean = dd[\"mean_test_accuracy\"].unstack(level=\"classifier\").mean(axis=1)\n",
    "df_temp_std = dd[\"std_test_accuracy\"].unstack(level=\"classifier\").mean(axis=1)\n",
    "\n",
    "df_temp_mean.unstack(level=\"data_modality\").plot.barh(figsize=(5,6), width=0.7)#, xerr = df_temp_std.unstack(level=\"data_modality\"))\n",
    "plt.grid(axis='y')\n",
    "# plt.yticks(np.arange(-0.5,15.5,1))\n",
    "plt.xlim([0,1])\n",
    "plt.legend(bbox_to_anchor=(0.2, -0.04, 0.6, 0), loc=\"upper left\", mode=\"expand\", ncol=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over participants to know the best model per subject and its hyperparams.\n",
    "for participant in participants_ids:\n",
    "    # participant = 0\n",
    "    query = ((df_results_hyperparam_opt.test_subject_id == participant) & \\\n",
    "                (df_results_hyperparam_opt.rank_test_accuracy == 1) & \\\n",
    "                    (df_results_hyperparam_opt.data_modality == \"all\") )\n",
    "    best_results_participant = df_results_hyperparam_opt[ query ]\n",
    "    best_classifier_gridsearch = best_results_participant[ best_results_participant.mean_test_accuracy == best_results_participant.mean_test_accuracy.max() ]\n",
    "    best_clf_name = best_classifier_gridsearch.classifier\n",
    "\n",
    "    # Apply the classification on the test subject\n",
    "    print(f\"P{participant} - Best clf: {best_clf_name}\\n\\tBest performance {best_classifier_gridsearch.mean_test_accuracy.values}\\n\\tBest params {best_classifier_gridsearch.params.values}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Analysis 4: Feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a baseline, we can apply [`SelectKBest`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html) to check the K most significant features from based on a F-test.\n",
    "\n",
    "For **Linear SVM** model, we can apply [`SelectFromModel`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFromModel.html#sklearn.feature_selection.SelectFromModel) or `Sequential Feature Selection` or `Recursive Feature Elimination` to choose K-features after the model has been trained. It provides info about `feature_importances_` when trained.\n",
    "\n",
    "For **Gaussian SVM** and **RF** we can apply Forward [`Sequential Feature Selection`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SequentialFeatureSelector.html#sklearn.feature_selection.SequentialFeatureSelector) although it [takes a lot of time](https://scikit-learn.org/stable/auto_examples/feature_selection/plot_select_from_model_diabetes.html#discussion). Only Forward because SFS uses CV internally to add features, and it's faster to go from 0 to 20 (forward) than going from >100 down to 20 features as in the backwards variant. Unfortunately, others like [`Recursive Feature Elimination`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html#sklearn.feature_selection.RFE) cannot be applied with Gaussian SVM because it does not provide coefficients `coef_` or `feature_importances_` when fitted in the data.\n",
    "\n",
    "Then, apply my method using `LIME` and compare to the results from the other 3 feature selection models.\n",
    "\n",
    "- RQ: Which are the top-K features and how do they affect the models performance (*3 models x 15 participants*)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check mlxtend SFS algorithm [in this link](http://rasbt.github.io/mlxtend/api_subpackages/mlxtend.feature_selection/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FEATURES_TO_SELECT = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We continue exploring these three models based on the initial analysis.\n",
    "best_models_after_hyperparam_opt = {\n",
    "    \"LinearSVM\":    LinearSVC(C = 1, penalty=\"l1\", dual=False, max_iter=50000),         # As a reference for interpretable linear models.\n",
    "    \"GaussianSVM\":  SVC(kernel='rbf', gamma=0.001, C = 100, probability=True),          # Best performing model (Kernel-based)\n",
    "    \"RF\":           RandomForestClassifier(criterion='entropy',                         # Best performing model (Tree-based)\n",
    "                                            n_estimators=50, \n",
    "                                            max_depth= 20, \n",
    "                                            random_state=experiment_config.MC_RANDOM_SEED, \n",
    "                                            n_jobs=-1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_classification_results_to_df(df, classification_report, prefix):\n",
    "    \"\"\"Returns a dataframe from the dictionary generated with `sklearn.classification_report()`\"\"\"\n",
    "    df[prefix+\"_accuracy\"] = classification_report[\"accuracy\"]\n",
    "    df[prefix+\"_precision_macro\"] = classification_report['macro avg'][\"precision\"]\n",
    "    df[prefix+\"_recall_macro\"] = classification_report['macro avg'][\"recall\"]\n",
    "    df[prefix+\"_f1_macro\"] = classification_report['macro avg'][\"f1-score\"]\n",
    "    df[prefix+\"_support\"] = classification_report['macro avg'][\"support\"]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_results_after_feature_selection(clf, colnames, df_results, x_trn, y_trn, x_tst, y_tst):\n",
    "    \"\"\"Runs `predict` on a trained classifier `clf` with the specified `colnames` and \n",
    "    returns the classification report for the train and the test sets,\n",
    "    concatenated to the dataframe `df_results`.\n",
    "    \"\"\"\n",
    "    # Evaluate in training set\n",
    "    cm_results = classification_report(y_trn, clf.predict(x_trn[colnames]), zero_division=0, output_dict=True)\n",
    "    df_results = add_classification_results_to_df(df_results, cm_results, \"train\")\n",
    "\n",
    "    # Evaluate on test set\n",
    "    y_true = y_tst\n",
    "    y_pred = clf.predict(x_tst[colnames])\n",
    "\n",
    "    cm_results = classification_report(y_true, y_pred, zero_division=0, output_dict=True)\n",
    "    df_results = add_classification_results_to_df(df_results, cm_results, \"test\")\n",
    "    return df_results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My approach to be compared with intrinsic, F-score, RFE, SFS, etc.\n",
    "\n",
    "def feature_importance_with_LIME(clf, x_trn, x_tst, y_tst,\n",
    "                                    feature_colnames,\n",
    "                                    class_names = [\"Negative\", \"Positive\"]):\n",
    "    \"\"\"\n",
    "    TODO: Write a function that takes an estimator and calculates the overall feature importance\n",
    "    on the test set. This is the result that will be compared with the other feature importance \n",
    "    algorithms to know how much do they increase the test_accuracy pre and post feature selection.\n",
    "\n",
    "    :Params:\n",
    "    `clf`: sklearn classifier.\n",
    "                Classifier over which to do the feature importance analysis. \n",
    "                It corresponds to a sklearn classifier with the method `predict_proba()`.\n",
    "\n",
    "    :Returns:\n",
    "    A pandas Series with `feature_colnames` as index and values corresponding to the feature\n",
    "    importance of each feature based on the sum of the feature importance per individual \n",
    "    explanation according to LIME.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Configure LIME explainer\n",
    "    explainer = lime_tabular.LimeTabularExplainer(\n",
    "        training_data = x_trn.values,\n",
    "        feature_names = feature_colnames,\n",
    "        class_names = class_names,\n",
    "        mode = \"classification\",\n",
    "        feature_selection = \"highest_weights\",\n",
    "        random_state=experiment_config.MC_RANDOM_SEED\n",
    "    )\n",
    "\n",
    "    results_explanation = None\n",
    "\n",
    "    # Compare how many samples produce the same values between `predict()` and `predict_proba()`\n",
    "    y_predprob = np.argmax(clf.predict_proba(x_tst), axis=1)\n",
    "    y_predprob[ y_predprob==0 ] = -1 # Replace the original class labels for comparison.\n",
    "    y_idx_same_predictions = np.arange(y_predprob.size)[(y_tst == y_predprob)]\n",
    "\n",
    "    for i,instance_idx in enumerate(y_idx_same_predictions[0:3]): ### TODO! CHANGE!\n",
    "        NUM_INSTANCE_TO_EXPLAIN = instance_idx\n",
    "\n",
    "        # LIME\n",
    "        # Execute explanation\n",
    "        explanation = explainer.explain_instance(\n",
    "            data_row = x_tst.values[NUM_INSTANCE_TO_EXPLAIN],\n",
    "            top_labels = 1,\n",
    "            num_features = N_FEATURES_TO_SELECT,\n",
    "            predict_fn = clf.predict_proba      # Classifier!\n",
    "        )\n",
    "        exp_dict = explanation.as_map()\n",
    "        #### explanation.show_in_notebook() In case explanation needs to be shown in notebook.\n",
    "\n",
    "        # Extract specific results from explanation\n",
    "        y_true_instance = y_tst.values[NUM_INSTANCE_TO_EXPLAIN]\n",
    "        y_predicted_lime = [*exp_dict][0]\n",
    "        dict_this_explanation = {\n",
    "            \"instance_idx\": [NUM_INSTANCE_TO_EXPLAIN],\n",
    "            \"y_true\": [y_true_instance],\n",
    "            \"y_predicted_lime\": [ y_predicted_lime], # Predictions are {0,1} and true labels are {-1,1}\n",
    "        }\n",
    "        print(f\"Explaining instance {i+1}/{y_idx_same_predictions.size}(T:{y_tst.size}) - y_true={y_true_instance}\")\n",
    "\n",
    "        df_this_explanation = pd.DataFrame(dict_this_explanation)\n",
    "        # Generate a DataFrame with feature names as columns and full of NaN. These values are replaced depending on feature importance\n",
    "        empty_featlist = pd.DataFrame(data=[[np.nan]*x_trn.columns.size], columns=x_trn.columns, dtype=float)\n",
    "        df_this_explanation = pd.concat([df_this_explanation, empty_featlist], axis=1)\n",
    "\n",
    "        # Extract list of tuples with (feature_index, feature_importance)    \n",
    "        feat_importance_instance = exp_dict[y_predicted_lime]\n",
    "        # Transform the feature importances to a Series, normalized by max importance\n",
    "        df_featimp_instance = {feature_colnames[fidx]:[fval] for fidx,fval in feat_importance_instance}\n",
    "        max_fi = np.abs(list(df_featimp_instance.values())).max()     # Normalize with maximum feature importance\n",
    "        df_featimp_instance = pd.Series({k: v/max_fi for k,v in df_featimp_instance.items()})\n",
    "\n",
    "        # Replace the NaN values from the most important features into numbers.\n",
    "        df_this_explanation[df_featimp_instance.index] = df_featimp_instance.values\n",
    "\n",
    "        results_explanation = df_this_explanation if (results_explanation is None) else pd.concat([results_explanation, df_this_explanation], axis=0, ignore_index=True)\n",
    "\n",
    "    # Aggregate results over all individual explanations by adding their corresponding\n",
    "    # feature importance among valid predictions. Then choose the top K.\n",
    "    feature_importance = results_explanation[x_trn.columns].sum(axis=0).astype(float)\n",
    "    res_individual_explanations = results_explanation\n",
    "    return res_individual_explanations, feature_importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where the compiled dataset will be stored\n",
    "FEATIMPORT_PERFORMANCE_RESULTS_FILENAME = gen_path_results(\"3_Results_FeatImp_PerformanceClassification\", extension=\".csv\")\n",
    "FEATIMPORT_MATRIX_RESULTS_FILENAME = gen_path_results(\"3_Results_FeatImp_MatrixFeatures\", extension=\".csv\")\n",
    "\n",
    "FEATIMPORT_INDIVIDUAL_EXP_FILENAME = gen_path_results(\"3_Results_FeatImpLIME_IndividualExplanations\", extension=\".csv\")\n",
    "\n",
    "# Stores the classification performance\n",
    "df_results_aggregated = None\n",
    "# Stores a matrix indicating the feature importance indicated by each method.\n",
    "df_ranking_feature_importance = None\n",
    "\n",
    "# Store individual LIME explanations\n",
    "df_individual_explanations_lime = None\n",
    "\n",
    "\n",
    "### INPUTS / OUTPUTS\n",
    "\"\"\"EDIT CUSTOM FILENAMES\"\"\"\n",
    "input_files = [FEATIMPORT_PERFORMANCE_RESULTS_FILENAME, \n",
    "                FEATIMPORT_MATRIX_RESULTS_FILENAME,\n",
    "                FEATIMPORT_INDIVIDUAL_EXP_FILENAME]\n",
    "\n",
    "# Try to load files maximum two times\n",
    "for tries in range(RELOAD_TRIES):\n",
    "    try:\n",
    "        ### LOAD FILE\n",
    "        print(f\"Trying {tries+1}/{RELOAD_TRIES} to load files: {input_files}\")\n",
    "        \n",
    "        ### CUSTOM SECTION TO READ FILES\n",
    "        \"\"\"EDIT CUSTOM READ\"\"\"\n",
    "        df_results_aggregated = pd.read_csv(input_files[0])\n",
    "        print(f\"File {input_files[0]} was successfully loaded\")\n",
    "        df_ranking_feature_importance= pd.read_csv(input_files[1])\n",
    "        print(f\"File {input_files[1]} was successfully loaded\")\n",
    "        df_individual_explanations_lime = pd.read_csv(input_files[2])\n",
    "        print(f\"File {input_files[2]} was successfully loaded\")\n",
    "        break\n",
    "\n",
    "    except Exception as e:\n",
    "        ### CREATE FILE\n",
    "        print(f\"File not found. Creating again! {e}\")\n",
    "        \n",
    "        ### CUSTOM SECTION TO CREATE FILES \n",
    "        \"\"\"EDIT CUSTOM WRITE\"\"\"\n",
    "\n",
    "\n",
    "        ##################### BEGINNING OF EXPERIMENT\n",
    "        \n",
    "        modality_name = \"all\"\n",
    "        modality_colnames = data_modality_colnames[modality_name]\n",
    "\n",
    "        # Iterate over participants\n",
    "        # for participant in participants_ids:\n",
    "        participant = 0     ### TODO!!!!!!!!!! Change\n",
    "\n",
    "        ### Preprocessing\n",
    "        # Select the participants data to test the best classifier on them.\n",
    "        x_trn = data_X[modality_colnames][data_participant != participant].copy()   # Features\n",
    "        x_tst = data_X[modality_colnames][data_participant == participant].copy()   # Features\n",
    "        y_trn = data_Y[data_participant != participant].copy()   # Target\n",
    "        y_tst = data_Y[data_participant == participant].copy()   # Target\n",
    "\n",
    "        # Standardization\n",
    "        scaler = StandardScaler().fit(x_trn)\n",
    "        x_trn_scaled = scaler.transform(x_trn)\n",
    "        x_tst_scaled = scaler.transform(x_tst)\n",
    "        # Leave in pandas.DataFrame format to keep column names in feature importance analysis\n",
    "        x_trn_scaled = pd.DataFrame(data=x_trn_scaled, columns=data_X[modality_colnames].columns)\n",
    "        x_tst_scaled = pd.DataFrame(data=x_tst_scaled, columns=data_X[modality_colnames].columns)\n",
    "\n",
    "        for clf_name, clf in best_models_after_hyperparam_opt.items():\n",
    "            # clf_name = \"RF\"\n",
    "            # clf = best_models_after_hyperparam_opt[clf_name]\n",
    "            print(f\"P {participant} - Classifier {clf_name}\")\n",
    "\n",
    "            # Classification results PRE-FEATURE SELECTION\n",
    "            df_this_result_agg = {}\n",
    "            df_this_result_agg[\"pipeline_step\"] = [\"pre_feat_impor\"]\n",
    "            df_this_result_agg[\"data_modality\"] = [modality_name]\n",
    "            df_this_result_agg[\"test_subject_id\"] = [participant]\n",
    "            df_this_result_agg[\"classifier\"] = [clf_name]\n",
    "            df_this_result_agg = pd.DataFrame(df_this_result_agg)\n",
    "\n",
    "            # Train the model\n",
    "            clf.fit(x_trn_scaled[x_trn_scaled.columns], y_trn)\n",
    "            df_this_result_agg = classification_results_after_feature_selection(clf, x_trn_scaled.columns, \n",
    "                                                                                    df_this_result_agg, \n",
    "                                                                                    x_trn_scaled, \n",
    "                                                                                    y_trn, \n",
    "                                                                                    x_tst_scaled, \n",
    "                                                                                    y_tst)\n",
    "\n",
    "            # Add to df with classification results\n",
    "            df_results_aggregated = df_this_result_agg if (df_results_aggregated is None) else pd.concat([df_results_aggregated, df_this_result_agg], axis=0)\n",
    "\n",
    "            ### UNTIL THIS POINT WE HAVE THE BASELINE RESULT OF EACH CLASSIFIER ON THE TRAINING AND TEST SET.\n",
    "            # Now, let's apply different feature importance methods to know whether the subset improves performance\n",
    "\n",
    "            # %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% FEATURE IMPORTANCE COMPARISON %%%%%%%%%%%%%%%%%%%\n",
    "            \n",
    "            if(clf_name != \"GaussianSVM\"):\n",
    "                #################### Intrinsic\n",
    "                feature_selection_step_name = \"Intrinsic\"\n",
    "\n",
    "                df_this_ranking_feat_imp = {} # Stores the feature importance values assigned from each classifier\n",
    "                df_this_ranking_feat_imp[\"pipeline_step\"] = [feature_selection_step_name]\n",
    "                df_this_ranking_feat_imp[\"data_modality\"] = [modality_name]\n",
    "                df_this_ranking_feat_imp[\"test_subject_id\"] = [participant]\n",
    "                df_this_ranking_feat_imp[\"classifier\"] = [clf_name]\n",
    "                df_this_ranking_feat_imp = pd.DataFrame(df_this_ranking_feat_imp)\n",
    "\n",
    "                empty_featlist = pd.DataFrame(data=[[np.nan]*x_trn_scaled.columns.size], columns=x_trn_scaled.columns)\n",
    "                df_this_ranking_feat_imp = pd.concat([df_this_ranking_feat_imp, empty_featlist], axis=1)\n",
    "\n",
    "                ### METHOD\n",
    "                fi_scores = None\n",
    "                if clf_name == \"LinearSVM\":\n",
    "                    fi_scores = clf.coef_\n",
    "                elif clf_name == \"RF\":\n",
    "                    fi_scores = clf.feature_importances_\n",
    "                else: # E.g., SVM does not have intrinsic feature importance.\n",
    "                    fi_scores = np.ones(x_trn_scaled.columns.size)\n",
    "                \n",
    "                # F-score Select the K-most important features after training\n",
    "                alg_feat_import = pd.Series(data=fi_scores[0], index=x_trn_scaled.columns).nlargest(N_FEATURES_TO_SELECT)\n",
    "                alg_feat_import /= alg_feat_import.max()\n",
    "\n",
    "                # Add to array\n",
    "                df_this_ranking_feat_imp[alg_feat_import.index] = alg_feat_import.values\n",
    "                df_ranking_feature_importance = df_this_ranking_feat_imp if (df_ranking_feature_importance is None) else pd.concat([df_ranking_feature_importance, df_this_ranking_feat_imp], axis=0)\n",
    "\n",
    "                # Classification results\n",
    "                df_this_result_agg = {}\n",
    "                df_this_result_agg[\"pipeline_step\"] = [feature_selection_step_name]\n",
    "                df_this_result_agg[\"data_modality\"] = [modality_name]\n",
    "                df_this_result_agg[\"test_subject_id\"] = [participant]\n",
    "                df_this_result_agg[\"classifier\"] = [clf_name]\n",
    "                df_this_result_agg = pd.DataFrame(df_this_result_agg)\n",
    "\n",
    "                clf_feat_imp = clone(clf)\n",
    "                clf_feat_imp.fit(x_trn_scaled[alg_feat_import.index], y_trn)\n",
    "                df_this_result_agg = classification_results_after_feature_selection(clf_feat_imp, alg_feat_import.index,  # Here are the colnames\n",
    "                                                                                        df_this_result_agg, \n",
    "                                                                                        x_trn_scaled, \n",
    "                                                                                        y_trn, \n",
    "                                                                                        x_tst_scaled, \n",
    "                                                                                        y_tst)\n",
    "\n",
    "                # Add to df with classification results\n",
    "                df_results_aggregated = df_this_result_agg if (df_results_aggregated is None) else pd.concat([df_results_aggregated, df_this_result_agg], axis=0)\n",
    "\n",
    "            #################### F-score\n",
    "            feature_selection_step_name = \"F-score\"\n",
    "\n",
    "            df_this_ranking_feat_imp = {} # Stores the feature importance values assigned from each classifier\n",
    "            df_this_ranking_feat_imp[\"pipeline_step\"] = [feature_selection_step_name]\n",
    "            df_this_ranking_feat_imp[\"data_modality\"] = [modality_name]\n",
    "            df_this_ranking_feat_imp[\"test_subject_id\"] = [participant]\n",
    "            df_this_ranking_feat_imp[\"classifier\"] = [clf_name]\n",
    "            df_this_ranking_feat_imp = pd.DataFrame(df_this_ranking_feat_imp)\n",
    "\n",
    "            empty_featlist = pd.DataFrame(data=[[np.nan]*x_trn_scaled.columns.size], columns=x_trn_scaled.columns)\n",
    "            df_this_ranking_feat_imp = pd.concat([df_this_ranking_feat_imp, empty_featlist], axis=1)\n",
    "            \n",
    "            ### METHOD\n",
    "            selector = SelectKBest(f_classif, k=N_FEATURES_TO_SELECT)\n",
    "            selector.fit(x_trn_scaled, y_trn)\n",
    "            fi_scores = -np.log10(selector.pvalues_)\n",
    "\n",
    "            # F-score Select the K-most important features after training\n",
    "            alg_feat_import = pd.Series(data=fi_scores, index=x_trn_scaled.columns)[selector.get_feature_names_out()]\n",
    "            alg_feat_import /= alg_feat_import.max()\n",
    "\n",
    "            df_this_ranking_feat_imp[alg_feat_import.index] = alg_feat_import.values\n",
    "            df_ranking_feature_importance = df_this_ranking_feat_imp if (df_ranking_feature_importance is None) else pd.concat([df_ranking_feature_importance, df_this_ranking_feat_imp], axis=0)\n",
    "\n",
    "            # Classification results\n",
    "            df_this_result_agg = {}\n",
    "            df_this_result_agg[\"pipeline_step\"] = [feature_selection_step_name]\n",
    "            df_this_result_agg[\"data_modality\"] = [modality_name]\n",
    "            df_this_result_agg[\"test_subject_id\"] = [participant]\n",
    "            df_this_result_agg[\"classifier\"] = [clf_name]\n",
    "            df_this_result_agg = pd.DataFrame(df_this_result_agg)\n",
    "\n",
    "            clf_feat_imp = clone(clf)\n",
    "            clf_feat_imp.fit(x_trn_scaled[alg_feat_import.index], y_trn)\n",
    "            df_this_result_agg = classification_results_after_feature_selection(clf_feat_imp, alg_feat_import.index,  # Here are the colnames\n",
    "                                                                                    df_this_result_agg, \n",
    "                                                                                    x_trn_scaled, \n",
    "                                                                                    y_trn, \n",
    "                                                                                    x_tst_scaled, \n",
    "                                                                                    y_tst)\n",
    "\n",
    "            # Add to df with classification results\n",
    "            df_results_aggregated = df_this_result_agg if (df_results_aggregated is None) else pd.concat([df_results_aggregated, df_this_result_agg], axis=0)\n",
    "\n",
    "            #################### RFE\n",
    "\n",
    "            if(clf_name != \"GaussianSVM\"):\n",
    "\n",
    "                feature_selection_step_name = \"RFE\"\n",
    "\n",
    "                df_this_ranking_feat_imp = {} # Stores the feature importance values assigned from each classifier\n",
    "                df_this_ranking_feat_imp[\"pipeline_step\"] = [feature_selection_step_name]\n",
    "                df_this_ranking_feat_imp[\"data_modality\"] = [modality_name]\n",
    "                df_this_ranking_feat_imp[\"test_subject_id\"] = [participant]\n",
    "                df_this_ranking_feat_imp[\"classifier\"] = [clf_name]\n",
    "                df_this_ranking_feat_imp = pd.DataFrame(df_this_ranking_feat_imp)\n",
    "\n",
    "                empty_featlist = pd.DataFrame(data=[[np.nan]*x_trn_scaled.columns.size], columns=x_trn_scaled.columns)\n",
    "                df_this_ranking_feat_imp = pd.concat([df_this_ranking_feat_imp, empty_featlist], axis=1)\n",
    "                \n",
    "                ### METHOD\n",
    "                selector = RFE(clf, n_features_to_select=N_FEATURES_TO_SELECT)\n",
    "                selector.fit(x_trn_scaled, y_trn)\n",
    "                fi_scores = selector.ranking_\n",
    "\n",
    "                # RFE Select the K-most important features after training - No values, just the features\n",
    "                alg_feat_import = pd.Series(data=fi_scores, index=x_trn_scaled.columns)[selector.get_feature_names_out()]\n",
    "                alg_feat_import = 1/alg_feat_import # The RFE provides a ranking. Number 1 should still be 1\n",
    "\n",
    "                df_this_ranking_feat_imp[alg_feat_import.index] = alg_feat_import.values\n",
    "                df_ranking_feature_importance = df_this_ranking_feat_imp if (df_ranking_feature_importance is None) else pd.concat([df_ranking_feature_importance, df_this_ranking_feat_imp], axis=0)\n",
    "\n",
    "                # Classification results\n",
    "                df_this_result_agg = {}\n",
    "                df_this_result_agg[\"pipeline_step\"] = [feature_selection_step_name]\n",
    "                df_this_result_agg[\"data_modality\"] = [modality_name]\n",
    "                df_this_result_agg[\"test_subject_id\"] = [participant]\n",
    "                df_this_result_agg[\"classifier\"] = [clf_name]\n",
    "                df_this_result_agg = pd.DataFrame(df_this_result_agg)\n",
    "\n",
    "                clf_feat_imp = clone(clf)\n",
    "                clf_feat_imp.fit(x_trn_scaled[alg_feat_import.index], y_trn)\n",
    "                df_this_result_agg = classification_results_after_feature_selection(clf_feat_imp, alg_feat_import.index,  # Here are the colnames\n",
    "                                                                                        df_this_result_agg, \n",
    "                                                                                        x_trn_scaled, \n",
    "                                                                                        y_trn, \n",
    "                                                                                        x_tst_scaled, \n",
    "                                                                                        y_tst)\n",
    "\n",
    "                # Add to df with classification results\n",
    "                df_results_aggregated = df_this_result_agg if (df_results_aggregated is None) else pd.concat([df_results_aggregated, df_this_result_agg], axis=0)\n",
    "\n",
    "            #################### forward SFS\n",
    "            feature_selection_step_name = \"fSFS\"\n",
    "\n",
    "            df_this_ranking_feat_imp = {} # Stores the feature importance values assigned from each classifier\n",
    "            df_this_ranking_feat_imp[\"pipeline_step\"] = [feature_selection_step_name]\n",
    "            df_this_ranking_feat_imp[\"data_modality\"] = [modality_name]\n",
    "            df_this_ranking_feat_imp[\"test_subject_id\"] = [participant]\n",
    "            df_this_ranking_feat_imp[\"classifier\"] = [clf_name]\n",
    "            df_this_ranking_feat_imp = pd.DataFrame(df_this_ranking_feat_imp)\n",
    "            # Generate a DataFrame with feature names as columns and full of NaN. These values are replaced depending on feature importance\n",
    "            empty_featlist = pd.DataFrame(data=[[np.nan]*x_trn_scaled.columns.size], columns=x_trn_scaled.columns)\n",
    "            df_this_ranking_feat_imp = pd.concat([df_this_ranking_feat_imp, empty_featlist], axis=1)\n",
    "\n",
    "            ### METHOD\n",
    "            selector = SFS(clf, k_features=N_FEATURES_TO_SELECT, forward=True, scoring=\"accuracy\", cv=5, n_jobs=-1)\n",
    "            selector.fit(x_trn_scaled, y_trn)\n",
    "            # Calculate the feature ranking among the cv. Each iteration, the SFS adds a feature,\n",
    "            # and by accessing each subset we can check which was the order of features added.\n",
    "            order_fi = {}\n",
    "            subsets = selector.subsets_\n",
    "            for k,v in subsets.items():\n",
    "                this_featnames = set(subsets[k]['feature_names'])\n",
    "                if k==1:\n",
    "                    new_featname = list(this_featnames)[0]\n",
    "                else:\n",
    "                    prev_featnames = set(subsets[k-1]['feature_names'])\n",
    "                    new_featname = list(this_featnames.difference( prev_featnames ))[0]\n",
    "                order_fi[ new_featname ] = k  # The value is the ranking\n",
    "                    \n",
    "            alg_feat_import = pd.Series(data = order_fi.values(), index=order_fi.keys())\n",
    "            alg_feat_import = 1/alg_feat_import # The SFS provides a ranking. Number 1 should still be 1\n",
    "\n",
    "            df_this_ranking_feat_imp[alg_feat_import.index] = alg_feat_import.values\n",
    "            df_ranking_feature_importance = df_this_ranking_feat_imp if (df_ranking_feature_importance is None) else pd.concat([df_ranking_feature_importance, df_this_ranking_feat_imp], axis=0)\n",
    "\n",
    "            # Classification results\n",
    "            df_this_result_agg = {}\n",
    "            df_this_result_agg[\"pipeline_step\"] = [feature_selection_step_name]\n",
    "            df_this_result_agg[\"data_modality\"] = [modality_name]\n",
    "            df_this_result_agg[\"test_subject_id\"] = [participant]\n",
    "            df_this_result_agg[\"classifier\"] = [clf_name]\n",
    "            df_this_result_agg = pd.DataFrame(df_this_result_agg)\n",
    "\n",
    "            clf_feat_imp = clone(clf)\n",
    "            clf_feat_imp.fit(x_trn_scaled[alg_feat_import.index], y_trn)\n",
    "            df_this_result_agg = classification_results_after_feature_selection(clf_feat_imp, alg_feat_import.index,  # Here are the colnames\n",
    "                                                                                    df_this_result_agg,\n",
    "                                                                                    x_trn_scaled,\n",
    "                                                                                    y_trn,\n",
    "                                                                                    x_tst_scaled,\n",
    "                                                                                    y_tst)\n",
    "\n",
    "            # Add to df with classification results\n",
    "            df_results_aggregated = df_this_result_agg if (df_results_aggregated is None) else pd.concat([df_results_aggregated, df_this_result_agg], axis=0)\n",
    "\n",
    "\n",
    "            #################### LIME\n",
    "            # My method\n",
    "            if(clf_name != \"LinearSVM\"):\n",
    "\n",
    "                feature_selection_step_name = \"LIME\"\n",
    "\n",
    "                df_this_ranking_feat_imp = {} # Stores the feature importance values assigned from each classifier\n",
    "                df_this_ranking_feat_imp[\"pipeline_step\"] = [feature_selection_step_name]\n",
    "                df_this_ranking_feat_imp[\"data_modality\"] = [modality_name]\n",
    "                df_this_ranking_feat_imp[\"test_subject_id\"] = [participant]\n",
    "                df_this_ranking_feat_imp[\"classifier\"] = [clf_name]\n",
    "                df_this_ranking_feat_imp = pd.DataFrame(df_this_ranking_feat_imp)\n",
    "                # Generate a DataFrame with feature names as columns and full of NaN. These values are replaced depending on feature importance\n",
    "                empty_featlist = pd.DataFrame(data=[[np.nan]*x_trn_scaled.columns.size], columns=x_trn_scaled.columns)\n",
    "                df_this_ranking_feat_imp = pd.concat([df_this_ranking_feat_imp, empty_featlist], axis=1)\n",
    "\n",
    "                ### METHOD\n",
    "                res_individual_explanations, alg_feat_import = feature_importance_with_LIME(clf, \n",
    "                                                    x_trn_scaled, x_tst_scaled, y_tst,\n",
    "                                                    x_trn_scaled.columns, \n",
    "                                                    class_names = [\"Negative\", \"Positive\"])\n",
    "\n",
    "                # Add metadata to individual explanations\n",
    "                # Insert general information in long format\n",
    "                res_individual_explanations.insert(0,\"classifier\", clf_name)\n",
    "                res_individual_explanations.insert(0, \"test_subject_id\", participant)\n",
    "                res_individual_explanations.insert(0, \"data_modality\", modality_name)\n",
    "                res_individual_explanations.insert(0, \"pipeline_step\", feature_selection_step_name)\n",
    "\n",
    "\n",
    "                # DF to store all the history of explanations\n",
    "                df_individual_explanations_lime = res_individual_explanations if (df_individual_explanations_lime is None) else pd.concat([df_individual_explanations_lime, res_individual_explanations], axis=0, ignore_index=True)\n",
    "\n",
    "                # MyMethod Select the K-most important features after training - No values, just the features\n",
    "                alg_feat_import = alg_feat_import.nlargest(N_FEATURES_TO_SELECT)\n",
    "                alg_feat_import /= alg_feat_import.max()\n",
    "\n",
    "                df_this_ranking_feat_imp[alg_feat_import.index] = alg_feat_import.values\n",
    "                df_ranking_feature_importance = df_this_ranking_feat_imp if (df_ranking_feature_importance is None) else pd.concat([df_ranking_feature_importance, df_this_ranking_feat_imp], axis=0)\n",
    "\n",
    "\n",
    "                # Classification results\n",
    "                df_this_result_agg = {}\n",
    "                df_this_result_agg[\"pipeline_step\"] = [feature_selection_step_name]\n",
    "                df_this_result_agg[\"data_modality\"] = [modality_name]\n",
    "                df_this_result_agg[\"test_subject_id\"] = [participant]\n",
    "                df_this_result_agg[\"classifier\"] = [clf_name]\n",
    "                df_this_result_agg = pd.DataFrame(df_this_result_agg)\n",
    "\n",
    "                clf_feat_imp = clone(clf)\n",
    "                clf_feat_imp.fit(x_trn_scaled[alg_feat_import.index], y_trn)\n",
    "                df_this_result_agg = classification_results_after_feature_selection(clf_feat_imp, alg_feat_import.index,  # Here are the colnames\n",
    "                                                                                        df_this_result_agg,\n",
    "                                                                                        x_trn_scaled,\n",
    "                                                                                        y_trn,\n",
    "                                                                                        x_tst_scaled,\n",
    "                                                                                        y_tst)\n",
    "\n",
    "                # Add to df with classification results\n",
    "                df_results_aggregated = df_this_result_agg if (df_results_aggregated is None) else pd.concat([df_results_aggregated, df_this_result_agg], axis=0)\n",
    "\n",
    "            #################################\n",
    "            ###  End of participant iterations\n",
    "            # Saving .csv\n",
    "            df_results_aggregated.to_csv( input_files[0], index=False)\n",
    "            df_ranking_feature_importance.to_csv( input_files[1], index=False)\n",
    "            if (df_individual_explanations_lime is not None):\n",
    "                df_individual_explanations_lime.to_csv(input_files[2], index=False)\n",
    "\n",
    "        #End of data modalities\n",
    "        print(\"The experimental setup has finished\")\n",
    "\n",
    "        ## ---- CONTROL RETRIES\n",
    "        if tries+1 < RELOAD_TRIES:\n",
    "            continue\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "print(\"\\n\\n End\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ranking_feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_individual_explanations_lime.iloc[:,7:].sum(axis=0).astype(float).nlargest(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the increase/loss in performance after feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_aggregated.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DF below shows the feature importance assigned per each of the algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr = df_ranking_feature_importance.groupby([\"pipeline_step\",\"test_subject_id\",\"classifier\"]).sum()\n",
    "dfr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DF below shows the performance of each classifier before (`pref_feat_import`) and after each of the feature importance methods (`intrinsic`, `F-score`, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_aggregated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = df_results_aggregated.set_index([\"test_subject_id\",\"classifier\",\"pipeline_step\"])[ [\"train_accuracy\",\"test_accuracy\"] ].unstack(level=2)\n",
    "dft.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substracting the mean accuracy of each model before feature importance, to know whether it increased or decreased.\n",
    "for g, m in dft.columns:\n",
    "    if(m != \"pre_feat_impor\"):\n",
    "        dft[g][m] -= dft[g][\"pre_feat_impor\"]\n",
    "\n",
    "dft[\"test_accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the columns corresponding to features\n",
    "features = df_ranking_feature_importance.iloc[:,-len(modality_colnames):]\n",
    "\n",
    "# Plot the mean and std of the importance\n",
    "ft_order = features.mean().T.abs().argsort() # Order from higher to lower by mean importance\n",
    "ft_plot = features.mean().T.iloc[ft_order]   # Plot the bars with the mean value\n",
    "err = features.std().T.iloc[ft_order]        # Add error bars with corresponding std\n",
    "plt.axvline(x=0, color=\".5\")\n",
    "ft_plot.plot.barh(figsize=(10,20), xerr=err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_featured_based.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification\n",
    "\n",
    "`TODO:` Change the columns to drop. Select meaningful features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to define the segments of interest and the mapping for classifiers\n",
    "CLASSES_MAPPING = {\n",
    "            \"VideoNegative\": -1,\n",
    "            \"VideoNeutral\": 0,\n",
    "            \"VideoPositive\": 1,\n",
    "            }\n",
    "CLASSES_MAPPING_INVERSE = { v:k for k,v in CLASSES_MAPPING.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS_TO_DROP = [\"Time\", \"VideoID\", \"participant\", \"Valence\", \"Arousal\", \"RawX\", \"RawY\"]\n",
    "dataset = dataset_featured_based.drop(COLUMNS_TO_DROP, axis=1)\n",
    "\n",
    "data.rename(columns={\"Segment\":\"Target\"}, inplace=True)\n",
    "dataset[\"Target\"] = dataset[\"Target\"].map(CLASSES_MAPPING)\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class imbalance\n",
    "dataset[\"Target\"].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split DATA and LABELS\n",
    "data_X = dataset.drop(\"Target\", axis=1)\n",
    "data_y = dataset[\"Target\"]\n",
    "\n",
    "data_colnames = data_X.columns.values\n",
    "\n",
    "print(f\"X:{data_X.shape}, y:{data_y.shape}\\nColumns:{data_colnames}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X = data_X.values\n",
    "y = data_y.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=experiment_config.MC_RANDOM_SEED, stratify=y)\n",
    "print(f\"Train>> X:{X_train.shape}, y:{y_train.shape} \\t Test>> X:{X_test.shape}, y:{y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RELOAD_TRIES = 3\n",
    "    \n",
    "# Where the compiled dataset will be stored\n",
    "FEATURE_BASED_CLASSIFIERS_RESULTS_FILENAME = gen_path_results(\"2_ResultsPerFold_FeatureBasedClassification\", extension=\".csv\")\n",
    "\n",
    "# Load or create dataframe\n",
    "results_evaluation = None\n",
    "\n",
    "### INPUTS / OUTPUTS\n",
    "\"\"\"EDIT CUSTOM FILENAMES\"\"\"\n",
    "input_files = [FEATURE_BASED_CLASSIFIERS_RESULTS_FILENAME]\n",
    "\n",
    "# Try to load files maximum two times\n",
    "for tries in range(RELOAD_TRIES):\n",
    "    try:\n",
    "        ### LOAD FILE\n",
    "        print(f\"Trying {tries+1}/{RELOAD_TRIES} to load files: {input_files}\")\n",
    "        \n",
    "        ### CUSTOM SECTION TO READ FILES\n",
    "        \"\"\"EDIT CUSTOM READ\"\"\"\n",
    "        results_evaluation = pd.read_csv(input_files[0])\n",
    "        print(f\"File {input_files[0]} was successfully loaded\")\n",
    "\n",
    "    except Exception as e:\n",
    "        ### CREATE FILE\n",
    "        print(f\"File not found. Creating again! {e}\")\n",
    "\n",
    "        ### CUSTOM SECTION TO CREATE FILES \n",
    "        \"\"\"EDIT CUSTOM WRITE\"\"\"\n",
    "\n",
    "\n",
    "        #### ITERATION FOR THE EXPERIMENT\n",
    "\n",
    "        # # Apply StratifiedGroupKFold scheme to preserve class imbalance and groups per participant\n",
    "        # from sklearn.model_selection import StratifiedGroupKFold\n",
    "        # sgkf = StratifiedGroupKFold(N_SPLITS_CV, random_state=experiment_config.MC_RANDOM_SEED)\n",
    "\n",
    "        # Evaluate\n",
    "        for name, classifier in DICT_CLASSIFIERS.items():\n",
    "            print(f\"Currently training the classifier {name}.\")\n",
    "\n",
    "            # Get the evaluation metrics per fold after cross-validation\n",
    "            # Note that we are passing the normalized array `data_X_norm` to all classifiers\n",
    "            scores_cv = cross_validate(classifier, X_train, y_train, cv=N_SPLITS_CV, scoring=SCORING_METRICS)\n",
    "\n",
    "            #### Generate the results to populate the pandas.DataFrame\n",
    "            df_this_result = pd.DataFrame(scores_cv)\n",
    "            df_this_result[\"classifier_name\"] = name\n",
    "            df_this_result[\"fold\"] = np.arange(N_SPLITS_CV)\n",
    "\n",
    "            # Append to the main dataframe with the results \n",
    "            results_evaluation = df_this_result if (results_evaluation is None) else pd.concat([results_evaluation, df_this_result], ignore_index=True)\n",
    "\n",
    "        print(\"The experimental setup has finished\")\n",
    "\n",
    "        # Saving .csv\n",
    "        results_evaluation.to_csv( input_files[0], index=False)\n",
    "        print(\"\\n\\n End\")\n",
    "\n",
    "        ### ---- CONTROL RETRIES\n",
    "        if tries+1 < RELOAD_TRIES:\n",
    "            continue\n",
    "        else:\n",
    "            raise\n",
    "    \n",
    "    # Finish iteration\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group performance per classifier (mean+/-std)\n",
    "df_mean = results_evaluation.groupby(by=[\"classifier_name\"]).mean()\n",
    "df_std = results_evaluation.groupby(by=[\"classifier_name\"]).std()\n",
    "df_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to a text\n",
    "df_mean_str = df_mean.apply(lambda x: ['%.3f'%v for v in x.values])\n",
    "df_std_str = df_std.apply(lambda x: ['%.2f'%v for v in x.values])\n",
    "\n",
    "df_results = (df_mean_str + \" (\" + df_std_str + \")\")\n",
    "\n",
    "# Rename columns\n",
    "df_results.drop([\"fit_time\",\"score_time\",\"fold\"], axis=1, inplace=True)\n",
    "df_results.columns = [\"accuracy\",\"precision\",\"recall\",\"f1-score\"]\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate LaTeX table\n",
    "FEATURE_BASED_CLASSIFIERS_RESULTS_FILENAME = gen_path_results(\"2_ResultsPerFold_FeatureBasedClassification\", extension=\".tex\")\n",
    "df_results.to_latex(FEATURE_BASED_CLASSIFIERS_RESULTS_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define below which is the best classifier, it will generate predictions on the final Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE HERE THE BEST CLASSIFIER\n",
    "BEST_CLASSIFIER = DICT_CLASSIFIERS[\"RF\"]\n",
    "\n",
    "# Fit in the whole training set\n",
    "best_classifier = BEST_CLASSIFIER\n",
    "best_classifier = best_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Classification on test set\n",
    "y_true = y_test\n",
    "y_pred = best_classifier.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classificaiton report on TEST set\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "CLASS_NEW_NAMES = [\"Negative\",\"Neutral\",\"Positive\"]\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(cm, display_labels=CLASS_NEW_NAMES)\n",
    "disp.plot(cmap=\"GnBu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis 1B: Interpretability with LIME and SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime import lime_tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(y_true[:100]))\n",
    "print(list(y_pred[:100]))\n",
    "print(list( (y_true==y_pred)[:100] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure LIME explainer\n",
    "explainer = lime_tabular.LimeTabularExplainer(\n",
    "    training_data = X_train,\n",
    "    feature_names = data_colnames,\n",
    "    class_names = CLASS_NEW_NAMES,\n",
    "    mode = \"classification\",\n",
    "    random_state=experiment_config.MC_RANDOM_SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explanation\n",
    "NUM_INSTANCE_TO_EXPLAIN = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIME\n",
    "print(\"Preparing to explain instance with true label = \", y_test[NUM_INSTANCE_TO_EXPLAIN], \"\\t Available test instances:\", y_test.shape)\n",
    "\n",
    "explanation = explainer.explain_instance(\n",
    "    data_row = X_test[NUM_INSTANCE_TO_EXPLAIN],\n",
    "    top_labels = 1,\n",
    "    predict_fn = best_classifier.predict_proba\n",
    ")\n",
    "explanation.show_in_notebook(show_table=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dict = explanation.as_map()\n",
    "exp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_instance = y_test[NUM_INSTANCE_TO_EXPLAIN]\n",
    "y_predicted_lime = [*exp_dict][0]\n",
    "feat_importance_instance = exp_dict[y_predicted_lime]\n",
    "\n",
    "dict_this_explanation = {\n",
    "    \"y_true\": y_true_instance,\n",
    "    \"y_predicted_lime\": y_predicted_lime - 1, # Predictions are {0,1,2} and true labels are {-1,0,1}\n",
    "}\n",
    "\n",
    "for feature_index, feature_importance in feat_importance_instance:\n",
    "    print(f\"{feature_index} Feature: {data_colnames[feature_index]} = {feature_importance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RELOAD_TRIES = 3\n",
    "    \n",
    "# Where the compiled dataset will be stored\n",
    "GENERAL_LIME_EXPLANATION_FILENAME = gen_path_results(\"2b_ResultsExplanation_LIME_PerInstance\", extension=\".csv\")\n",
    "\n",
    "# Load or create dataframe\n",
    "results_explanation = None\n",
    "\n",
    "### INPUTS / OUTPUTS\n",
    "\"\"\"EDIT CUSTOM FILENAMES\"\"\"\n",
    "input_files = [GENERAL_LIME_EXPLANATION_FILENAME]\n",
    "\n",
    "# Try to load files maximum two times\n",
    "for tries in range(RELOAD_TRIES):\n",
    "    try:\n",
    "        ### LOAD FILE\n",
    "        print(f\"Trying {tries+1}/{RELOAD_TRIES} to load files: {input_files}\")\n",
    "        \n",
    "        ### CUSTOM SECTION TO READ FILES\n",
    "        \"\"\"EDIT CUSTOM READ\"\"\"\n",
    "        results_explanation = pd.read_csv(input_files[0])\n",
    "        print(f\"File {input_files[0]} was successfully loaded\")\n",
    "\n",
    "    except Exception as e:\n",
    "        ### CREATE FILE\n",
    "        print(f\"File not found. Creating again! {e}\")\n",
    "\n",
    "        ### CUSTOM SECTION TO CREATE FILES \n",
    "        \"\"\"EDIT CUSTOM WRITE\"\"\"\n",
    "        \n",
    "        for i in range(0,y_test.shape[0]):\n",
    "            NUM_INSTANCE_TO_EXPLAIN = i\n",
    "\n",
    "            # LIME\n",
    "            # Execute explanation\n",
    "            explanation = explainer.explain_instance(\n",
    "                data_row = X_test[NUM_INSTANCE_TO_EXPLAIN],\n",
    "                top_labels = 1,\n",
    "                predict_fn = best_classifier.predict_proba\n",
    "            )\n",
    "            exp_dict = explanation.as_map()\n",
    "\n",
    "            # Extract specific results from explanation\n",
    "            y_true_instance = y_test[NUM_INSTANCE_TO_EXPLAIN]\n",
    "            y_predicted_lime = [*exp_dict][0]\n",
    "            dict_this_explanation = {\n",
    "                \"y_true\": [y_true_instance],\n",
    "                \"y_predicted_lime\": [y_predicted_lime-1], # Predictions are {0,1,2} and true labels are {-1,0,1}\n",
    "            }\n",
    "\n",
    "            print(f\"Explaining instance {NUM_INSTANCE_TO_EXPLAIN}/{y_test.shape[0]-1} - y_true={y_true_instance}, y_pred={y_predicted_lime-1}\")\n",
    "\n",
    "            # Extract list of tuples with (feature_index, feature_importance)    \n",
    "            feat_importance_instance = exp_dict[y_predicted_lime]\n",
    "\n",
    "            for feature_index, importance_value in feat_importance_instance:\n",
    "                dict_this_explanation[ data_colnames[feature_index] ] = [importance_value]\n",
    "                # print(f\"{feature_index} Feature: {data_colnames[feature_index]} = {feature_importance}\")\n",
    "\n",
    "            # Convert to DataFrame\n",
    "            df_this_explanation = pd.DataFrame.from_dict(dict_this_explanation)\n",
    "\n",
    "            results_explanation = df_this_explanation if (results_explanation is None) else pd.concat([results_explanation, df_this_explanation], ignore_index=True)\n",
    "\n",
    "        results_explanation = results_explanation.reset_index()\n",
    "        print(results_explanation.shape)\n",
    "\n",
    "        # Saving .csv\n",
    "        results_explanation.to_csv( input_files[0], index=False)\n",
    "        print(\"\\n\\n End\")\n",
    "\n",
    "        ### ---- CONTROL RETRIES\n",
    "        if tries+1 < RELOAD_TRIES:\n",
    "            continue\n",
    "        else:\n",
    "            raise\n",
    "    \n",
    "    # Finish iteration\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions:**\n",
    "- What is the most important feature for each class?\n",
    "- What is the ranking or the absolute value of the explanation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_explanation[ (results_explanation.y_true == results_explanation.y_predicted_lime) ].y_true.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RELOAD_TRIES = 3\n",
    "    \n",
    "# Where the compiled dataset will be stored\n",
    "SUMMARY_LIME_EXPLANATION_FILENAME = gen_path_results(\"2c_SummaryExplanation_LIME_Globally\", extension=\".csv\")\n",
    "\n",
    "# Load or create dataframe\n",
    "df_report_explanations = None\n",
    "\n",
    "### INPUTS / OUTPUTS\n",
    "\"\"\"EDIT CUSTOM FILENAMES\"\"\"\n",
    "input_files = [SUMMARY_LIME_EXPLANATION_FILENAME]\n",
    "\n",
    "# Try to load files maximum two times\n",
    "for tries in range(RELOAD_TRIES):\n",
    "    try:\n",
    "        ### LOAD FILE\n",
    "        print(f\"Trying {tries+1}/{RELOAD_TRIES} to load files: {input_files}\")\n",
    "        \n",
    "        ### CUSTOM SECTION TO READ FILES\n",
    "        \"\"\"EDIT CUSTOM READ\"\"\"\n",
    "        df_report_explanations = pd.read_csv(input_files[0])\n",
    "        print(f\"File {input_files[0]} was successfully loaded\")\n",
    "\n",
    "    except Exception as e:\n",
    "        ### CREATE FILE\n",
    "        print(f\"File not found. Creating again! {e}\")\n",
    "\n",
    "        ### CUSTOM SECTION TO CREATE FILES \n",
    "        \"\"\"EDIT CUSTOM WRITE\"\"\"\n",
    "\n",
    "        for class_label in CLASSES_MAPPING.values():\n",
    "            \n",
    "            # Filter the test instances actually belonging to the class label\n",
    "            explanations_from_class = results_explanation[ results_explanation.y_true == class_label ]\n",
    "            explanations_correct_prediction = explanations_from_class[ (explanations_from_class.y_true == explanations_from_class.y_predicted_lime) ]\n",
    "\n",
    "            print(f\"For class label {class_label} \\tTotal instances:{explanations_from_class.shape[0]} - Correct LIME predictions {explanations_correct_prediction.shape[0]} = {explanations_correct_prediction.shape[0]/explanations_from_class.shape[0]}\")\n",
    "\n",
    "            # Extract the average, mean and size of the positive and negative feature importance\n",
    "            explanations = explanations_correct_prediction.drop([\"index\",\"y_true\",\"y_predicted_lime\"], axis=1)\n",
    "            report_explanations = {}\n",
    "            for colname in explanations.columns:\n",
    "                x = explanations[colname]\n",
    "\n",
    "                orig_N = x.shape[0]\n",
    "                x = x.dropna()\n",
    "                total_N = x.shape[0]\n",
    "                \n",
    "                report_explanations[colname] = [np.mean(x[ x >=0 ]),    np.std(x[ x >=0 ]),     np.size(x[x>=0]), \n",
    "                                                np.mean(x[ x <0 ]),     np.std(x[ x <0 ]),      np.size(x[x<0]), \n",
    "                                                np.mean(x),             np.std(x),              np.size(x),\n",
    "                                                orig_N\n",
    "                                                ]\n",
    "            report_explanations[\"Function\"] = [ \"mean\", \"std\", \"N\", \n",
    "                                                    \"mean\", \"std\", \"N\", \n",
    "                                                    \"mean\", \"std\", \"N\", \n",
    "                                                    \"orig_N\"\n",
    "                                                ]\n",
    "            report_explanations[\"Contribution\"] = [ \"Contrib(+)\", \"Contrib(+)\", \"Contrib(+)\", \n",
    "                                                        \"Contrib(-)\", \"Contrib(-)\", \"Contrib(-)\", \n",
    "                                                        \"Contrib(Total)\", \"Contrib(Total)\", \"Contrib(Total)\", \n",
    "                                                        \"TotalOrigN\"\n",
    "                                                    ]\n",
    "            report_explanations[\"Class\"] = [class_label]*len(report_explanations[colname])\n",
    "\n",
    "            this_report = pd.DataFrame(report_explanations)\n",
    "            # Concatenate results\n",
    "            df_report_explanations = this_report if (df_report_explanations is None) else pd.concat([df_report_explanations, this_report], ignore_index=True)\n",
    "        \n",
    "        print(df_report_explanations.shape)\n",
    "\n",
    "        # Saving .csv\n",
    "        df_report_explanations.to_csv( input_files[0], index=False)\n",
    "        print(\"\\n\\n End\")\n",
    "\n",
    "        ### ---- CONTROL RETRIES\n",
    "        if tries+1 < RELOAD_TRIES:\n",
    "            continue\n",
    "        else:\n",
    "            raise\n",
    "    \n",
    "    # Finish iteration\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report_explanations[\"Class\"] = df_report_explanations[\"Class\"].map(\n",
    "                                                    {\n",
    "                                                        -1:\"Negative\",\n",
    "                                                        0:\"Neutral\",\n",
    "                                                        1:\"Positive\",\n",
    "                                                    }\n",
    "                                                    )\n",
    "\n",
    "\n",
    "summarized_report_explanations = df_report_explanations.set_index([\"Function\", \"Class\", \"Contribution\"])\n",
    "summarized_report_explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADJUST_FACTOR = 1e2\n",
    "\n",
    "df_mean = summarized_report_explanations.loc[\"mean\"] * ADJUST_FACTOR\n",
    "df_std = summarized_report_explanations.loc[\"std\"] * ADJUST_FACTOR\n",
    "df_N = summarized_report_explanations.loc[\"N\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to a text\n",
    "df_mean_str = df_mean.apply(lambda x: ['%.2f'%v for v in x.values])\n",
    "df_std_str = df_std.apply(lambda x: ['%.1f'%v for v in x.values])\n",
    "df_N_str = df_N.apply(lambda x: ['%.0f'%v for v in x.values])\n",
    "\n",
    "# Create string for LaTeX table\n",
    "df_results = df_mean_str + \" (\" + df_std_str + \")[\" + df_N_str +\"]\"\n",
    "\n",
    "# Rename columns\n",
    "# df_results.drop([\"fit_time\",\"score_time\",\"fold\"], axis=1, inplace=True)\n",
    "# df_results.columns = [\"accuracy\",\"precision\",\"recall\",\"f1-score\"]\n",
    "df_results = df_results.transpose()\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_ORDER = ['HeartRate/Average',\n",
    " 'Ppg/Raw.ppg',\n",
    " 'Accelerometer/Raw.x',\n",
    " 'Accelerometer/Raw.y',\n",
    " 'Accelerometer/Raw.z',\n",
    " 'Emg/Amplitude[RightFrontalis]',\n",
    " 'Emg/Amplitude[RightZygomaticus]',\n",
    " 'Emg/Amplitude[RightOrbicularis]',\n",
    " 'Emg/Amplitude[CenterCorrugator]',\n",
    " 'Emg/Amplitude[LeftOrbicularis]',\n",
    " 'Emg/Amplitude[LeftZygomaticus]',\n",
    " 'Emg/Amplitude[LeftFrontalis]']\n",
    "\n",
    "df_results = df_results.reindex(FEATURES_ORDER)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate LaTeX table\n",
    "SUMMARY_LIME_EXPLANATION_FILENAME = gen_path_results(\"2c_SummaryExplanation_LIME_Globally\", extension=\".tex\")\n",
    "df_results.to_latex(SUMMARY_LIME_EXPLANATION_FILENAME,\n",
    "                                        caption=\"Total contributions according to local LIME explanations. Values in \\%, indicated as mean(std)[N samples]\")\n",
    "\n",
    "# Generate per class, so it's simpler to put in a LaTeX document\n",
    "for class_label in df_report_explanations[\"Class\"].unique():\n",
    "    FILENAME_CLASS_SUMMARY_EXPLANATION = gen_path_results(f\"2c_SummaryExplanation_LIME_Globally_Class_{class_label}\", extension=\".tex\")\n",
    "    df_results[class_label].to_latex(FILENAME_CLASS_SUMMARY_EXPLANATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\">> FINISHED WITHOUT ERRORS!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "metadata": {
   "interpreter": {
    "hash": "f3aec1f4fef7a88c2258d5b84a8b82909f076cff2bcb16988c856ebc42b66954"
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "5109d816b82be14675a6b11f8e0f0d2e80f029176ed3710d54e125caa8520dfd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
