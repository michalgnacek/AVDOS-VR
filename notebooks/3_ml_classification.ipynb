{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `AVDOS-VR` - Virtual Reality Affective Video Database with Physiological Signals\n",
    "\n",
    "Check `2_affect...ipynb` to see details of the affect classification\n",
    "\n",
    "This notebook runs the classification models using the file below, which is the feature-based dataset:\n",
    "- Feature based: `/temp/2_affect/Dataset_AVDOSVR_ManualFeaturesHRVandStatistics.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Path: /data0/home/v18/luva3178/dev/git_repos/AVDOS-VR/notebooks/\n"
     ]
    }
   ],
   "source": [
    "# Add files to sys.path\n",
    "from pathlib import Path\n",
    "import sys,os\n",
    "this_path = None\n",
    "try:    # WORKS WITH .py\n",
    "    this_path = str(os.path.dirname(os.path.abspath(__file__)))+\"/\" \n",
    "except: # WORKS WITH .ipynb\n",
    "    this_path = str(Path().absolute())+\"/\" \n",
    "print(\"File Path:\", this_path)\n",
    "\n",
    "# Add the level up to the file path so it recognizes the scripts inside `avdosvr`\n",
    "sys.path.append(os.path.join(this_path, \"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import classes\n",
    "import avdosvr.preprocessing       # Generate dataset index, load files, and plots.\n",
    "\n",
    "# Utils for generation of files and paths\n",
    "from avdosvr.utils import files_handler\n",
    "\n",
    "# Import data science libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "#matplotlib.rcParams['text.usetex'] = True\n",
    "import seaborn as sns\n",
    "\n",
    "# Statistical tests\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import mannwhitneyu, f_oneway\n",
    "\n",
    "# Preprocessing\n",
    "import neurokit2 as nk\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Feature based classification\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import Lasso, RidgeClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "# Feature selection\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.feature_selection import RFE\n",
    "# from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "# from lime import lime_tabular\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "# Turn off chained assignment warning\n",
    "pd.options.mode.chained_assignment = None \n",
    "\n",
    "\n",
    "\n",
    "#### DURING CROSS-VAL WHEN PRECISION=0\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UndefinedMetricWarning) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup\n",
    "\n",
    "Global variables and functions for file management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### General configuration\n",
    "\n",
    "# Path to the participants' folder w.r.t this notebook's filepath\n",
    "DATASET_ROOT_FOLDER = \"../data/\"\n",
    "\n",
    "# Used to generate the path of temporary subfolders\n",
    "NOTEBOOK_NAME = \"3_ml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to generate filepaths\n",
    "\n",
    "# MAIN FOLDERS FOR OUTPUT FILES\n",
    "ROOT = this_path + \"\"   # Root folder for all the files w.r.t this file\n",
    "TEMP_FOLDER = ROOT+\"temp/\"  # Main folder for temp files with intermediate calculations\n",
    "RESULTS_FOLDER = ROOT+\"results/\"    # Folder to recreate plots and results from analyses\n",
    "\n",
    "EXPORT_PLOTS = True\n",
    "IMG_FORMAT = \".pdf\"\n",
    "\n",
    "# Generates paths for files created from this script\n",
    "\n",
    "def gen_path_plot(filename, extension=IMG_FORMAT):\n",
    "    # Generates full paths for PLOTS just by specifying a name\n",
    "    return files_handler.generate_complete_path(filename, \\\n",
    "                                        main_folder=RESULTS_FOLDER, \\\n",
    "                                        subfolders=NOTEBOOK_NAME+\"/plots/\", \\\n",
    "                                        file_extension=extension, save_files=EXPORT_PLOTS)\n",
    "\n",
    "def gen_path_temp(filename, extension, subfolders=\"\"):\n",
    "    # Generates full paths for TEMP FILES just by specifying a name\n",
    "    return files_handler.generate_complete_path(filename, \\\n",
    "                                        main_folder=TEMP_FOLDER, \\\n",
    "                                        subfolders=NOTEBOOK_NAME+\"/\"+subfolders, \\\n",
    "                                        file_extension=extension)\n",
    "\n",
    "def gen_path_results(filename, subfolders=\"\", extension=\"\"):\n",
    "    # Generates full paths for RESULTS FILES (like pandas dataframes)\n",
    "    return files_handler.generate_complete_path(filename, \\\n",
    "                                        main_folder=RESULTS_FOLDER, \\\n",
    "                                        subfolders=NOTEBOOK_NAME+\"/\"+subfolders, \\\n",
    "                                        file_extension=extension)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Analysis 3: Valence and Arousal Classification from Physiological Signals\n",
    "\n",
    "- Select subset of features: `[Cardiac, Motor, Facial]`\n",
    "- Configure the train-test strategy for CV with [Leave-One-Subject-Out (LOSO)](https://scikit-learn.org/stable/modules/cross_validation.html#leave-one-group-out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset with extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_BASED_DATASET_FILENAME = TEMP_FOLDER + \"2_affect/Dataset_AVDOSVR_ManualFeaturesHRVandStatistics.csv\"\n",
    "\n",
    "df_feature_extraction = None\n",
    "\n",
    "if (os.path.isfile(FEATURE_BASED_DATASET_FILENAME)):\n",
    "    df_feature_extraction = pd.read_csv(FEATURE_BASED_DATASET_FILENAME)\n",
    "    print(f\"File loaded from path!\")\n",
    "else:\n",
    "    print(f\"Generate this file from NOTEBOOK 2!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify samples with insufficient HR quality\n",
    "low_quality_samples = df_feature_extraction[df_feature_extraction['Mean_BPM']==-1]\n",
    "low_quality_samples[\"segment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop low quality samples\n",
    "df_feature_extraction = df_feature_extraction.drop(low_quality_samples.index,axis=0).reset_index(drop=True)\n",
    "df_feature_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TARGET FOR CLASSIFICATION\n",
    "TARGET_AFFECT_DIMENSION = \"AROUSAL\" #  \"VALENCE\" or \"AROUSAL\"\n",
    "\n",
    "CLASSES_MAPPING = {\n",
    "                    ## 3-CLASS VALENCE\n",
    "                    \"VALENCE\": {\n",
    "                                \"Negative\": -1,\n",
    "                                \"Neutral\": 0,\n",
    "                                \"Positive\": 1,\n",
    "                                },\n",
    "\n",
    "                    # BINARY AROUSAL: Both Negative and Positive present HIGH arousing videos\n",
    "                    \"AROUSAL\":{\n",
    "                                \"Neutral\": 0,\n",
    "                                \"Negative\": 1,\n",
    "                                \"Positive\": 1,\n",
    "                                }\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X = df_feature_extraction.loc[(df_feature_extraction['segment'] == 'Positive')  | \n",
    "                                   (df_feature_extraction['segment'] == 'Negative') | \n",
    "                                   (df_feature_extraction['segment'] == 'Neutral')]\n",
    "data_X = data_X.reset_index(drop=True)\n",
    "data_X = data_X.drop([\"segment\"], axis=1)\n",
    "data_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Y = df_feature_extraction.loc[(df_feature_extraction['segment'] == 'Positive')  | \n",
    "                                   (df_feature_extraction['segment'] == 'Negative') | \n",
    "                                   (df_feature_extraction['segment'] == 'Neutral')]\n",
    "data_Y = data_Y.reset_index(drop=True)\n",
    "\n",
    "### MAPPING VIDEO GROUPS TO DIFFERENT CLASS LABELS\n",
    "data_Y = data_Y[\"segment\"].map(CLASSES_MAPPING[TARGET_AFFECT_DIMENSION])\n",
    "\n",
    "print(f\"Classifying: {TARGET_AFFECT_DIMENSION} with classes: {set(data_Y.values)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valence labels distribution\n",
    "data_Y.value_counts().plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_participant = df_feature_extraction.loc[(df_feature_extraction['segment'] == 'Positive')  | \n",
    "                                   (df_feature_extraction['segment'] == 'Negative') | \n",
    "                                   (df_feature_extraction['segment'] == 'Neutral')]\n",
    "data_participant = data_participant.reset_index(drop=True)\n",
    "data_participant = data_participant.participant\n",
    "data_participant.value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection per data modality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrv_colnames = data_X.columns[ [ (col.startswith(\"HRV\") | col.startswith(\"HeartRate\") | col.startswith(\"Ppg/\")) for col in data_X.columns] ].sort_values().values\n",
    "hrv_colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imu_colnames = data_X.columns[ [ (col.startswith(\"Accelerometer\")) | (col.startswith(\"Magnetometer\")) | (col.startswith(\"Gyroscope\")) for col in data_X.columns] ].sort_values().values\n",
    "imu_colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emg_amp_colnames = data_X.columns[ [ (col.startswith(\"Emg/Amplitude\")) for col in data_X.columns] ].sort_values().values\n",
    "emg_amp_colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emg_cont_colnames = data_X.columns[ [ (col.startswith(\"Emg/Contact\")) for col in data_X.columns] ].sort_values().values\n",
    "emg_cont_colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"HRV {hrv_colnames.size}\")\n",
    "print(f\"IMU {imu_colnames.size}\")\n",
    "print(f\"EMG Amplitude {emg_amp_colnames.size}\")\n",
    "print(f\"EMG Contact {emg_cont_colnames.size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification models\n",
    "\n",
    "Important reading: [Common pitfalls in the interpretation of coeffs in linear models.](https://scikit-learn.org/stable/auto_examples/inspection/plot_linear_model_coefficient_interpretation.html#sphx-glr-auto-examples-inspection-plot-linear-model-coefficient-interpretation-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE-BASED CLASSIFIERS CLASSIFIERS SETUP\n",
    "MC_RANDOM_SEED = 1234\n",
    "N_SPLITS_CV = 10 # Number of folds for Cross-validation\n",
    "\n",
    "# Scoring parameters: https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "SCORING_METRICS = [\"accuracy\", \"f1_macro\", \"precision_macro\", \"recall_macro\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Testing Classification pipeline*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example of iterator for Cross-validation per subject\n",
    "\n",
    "# Feature subset\n",
    "feature_subset_colnames = hrv_colnames   # imu_colnames, emg_amp_colnames, emg_cont_colnames\n",
    "\n",
    "# Features\n",
    "x = data_X[feature_subset_colnames]\n",
    "y = data_Y\n",
    "\n",
    "# Groups indices (participants' ids)\n",
    "group_cv = data_participant\n",
    "\n",
    "loso_cv = LeaveOneGroupOut()\n",
    "cv_splits = loso_cv.split(x, y, groups=group_cv)\n",
    "for trn_idx, tst_idx in cv_splits:\n",
    "    print(\"TRN: %s \\t TST: %s\" % (data_participant[trn_idx].unique(), data_participant[tst_idx].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep learner Keras CLassifier\n",
    "\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from tensorflow import keras\n",
    "def get_clf(meta, hidden_layer_sizes, dropout):\n",
    "    n_features_in_ = meta[\"n_features_in_\"]\n",
    "    n_classes_ = meta[\"n_classes_\"]\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Input(shape=(n_features_in_,)))\n",
    "    for hidden_layer_size in hidden_layer_sizes:\n",
    "        model.add(keras.layers.Dense(hidden_layer_size, activation=\"relu\"))\n",
    "        model.add(keras.layers.Dropout(dropout))\n",
    "    # model.add(keras.layers.Dense( 3 , activation=\"sigmoid\")) # For 3-class valence\n",
    "\n",
    "    ### LQ: Changing the output layer based on the classification task\n",
    "    output_dimension = 3 if TARGET_AFFECT_DIMENSION==\"VALENCE\" else 1\n",
    "\n",
    "    model.add(keras.layers.Dense( output_dimension , activation=\"sigmoid\"))\n",
    "    return model\n",
    "\n",
    "clf = KerasClassifier(\n",
    "    model=get_clf,\n",
    "    loss=\"CategoricalCrossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    optimizer__learning_rate=0.1,\n",
    "    model__hidden_layer_sizes=(100,),\n",
    "    model__dropout=0.5,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_modality_colnames = { \n",
    "            \"hrv\": hrv_colnames, \n",
    "            \"imu\": imu_colnames, \n",
    "            \"emg_amp\": emg_amp_colnames,\n",
    "            \"emg_cont\": emg_cont_colnames,\n",
    "            \"all\": list(hrv_colnames) + list(imu_colnames) + list(emg_amp_colnames) + list(emg_cont_colnames),\n",
    "    }\n",
    "\n",
    "# ClassifierName: {\"clf\":model, \"pgrid\":parameters)\n",
    "classifiers_hyperparams = {\n",
    "    \"LinearRidge\": {    \"clf\": RidgeClassifier(alpha=0.01, max_iter=1000), # n_class classifiers are trained in a one-versus-all approach. Concretely, taking advantage of the multi-variate response support in Ridge\n",
    "                        \"pgrid\": {'alpha': np.logspace(-5, 5,11) }},\n",
    "    \"GaussianSVM\": {    \"clf\": SVC(kernel='rbf', gamma='auto', C = 1),          # Multilabel in one-vs-one approach\n",
    "                        \"pgrid\": {'C': [1, 10, 100, 1000], 'gamma': [0.1, 0.01, 0.001]}},\n",
    "    \"RF\": {             \"clf\": RandomForestClassifier(criterion='entropy', random_state=MC_RANDOM_SEED, class_weight=\"balanced\"), # Multilabel classification\n",
    "                        \"pgrid\": {'n_estimators': [10, 50, 100], 'max_depth': [5, 10, 20]}},\n",
    "    \"KNN\": {            \"clf\": KNeighborsClassifier(),\n",
    "                        \"pgrid\": {'n_neighbors': [1, 5, 11, 15]}},\n",
    "    \"DL\": {\n",
    "            \"clf\": KerasClassifier(\n",
    "                model=get_clf,\n",
    "                loss=\"categorical_crossentropy\",\n",
    "                optimizer=\"adam\",\n",
    "                optimizer__learning_rate=0.1,\n",
    "                model__hidden_layer_sizes=(100,),\n",
    "                model__dropout=0.5,\n",
    "                verbose=False,\n",
    "            ),\n",
    "            \"pgrid\": {\n",
    "                'optimizer__learning_rate': [0.05, 0.001],\n",
    "                'model__hidden_layer_sizes': [(100, ), (50, 50, )],\n",
    "                'model__dropout': [0, 0.5],\n",
    "            },\n",
    "    },\n",
    "\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The execution below takes around 6 hours for 37 people on a 6-core Intel i7-8750H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading all segments for all participants and store the resting and video parts in a single large CSV.\n",
    "\n",
    "## TARGET SUFFIX\n",
    "\n",
    "DATASET_POSTPROCESSED_FILENAME = gen_path_temp(\"Results_ModelTrainingCV_PerDataModalityPerSubject_37p_\"+TARGET_AFFECT_DIMENSION, extension=\".csv\")\n",
    "\n",
    "output_filename = DATASET_POSTPROCESSED_FILENAME\n",
    "\n",
    "# Variable to store the final dataset\n",
    "df_results_hyperparam_opt = None\n",
    "\n",
    "# Check if file already exists\n",
    "if (os.path.isfile(output_filename)):\n",
    "    df_results_hyperparam_opt = pd.read_csv(output_filename)\n",
    "    print(f\"File loaded from path!\")\n",
    "# Otherwise generate it\n",
    "else:\n",
    "    print(f\"Generating file!\")\n",
    "    \n",
    "    ## Iteration per data type\n",
    "    for modality_name, modality_colnames in data_modality_colnames.items(): \n",
    "\n",
    "        # modality_name = \"hrv\"\n",
    "        # modality_colnames = data_modality_colnames[modality_name]\n",
    "        #### ABOVE FOR TESTING\n",
    "\n",
    "        # Subset of features\n",
    "        data_mod_x = data_X[modality_colnames].values.copy()   # Features\n",
    "        data_mod_y = data_Y.values.copy()\n",
    "\n",
    "        subject_ids = data_participant.values.copy()  # Groups indices (participants' ids)\n",
    "\n",
    "        # Split dataset with LOSO-CV\n",
    "        cv_loso_subj = LeaveOneGroupOut()\n",
    "        cv_splits_subjects = cv_loso_subj.split(data_mod_x, data_mod_y, groups=subject_ids)\n",
    "\n",
    "        # Iteration per subject (participant)\n",
    "        for trn_subj_idx, tst_subj_idx in cv_splits_subjects:\n",
    "\n",
    "            # The dataset that is not belonging to the TEST subject will be further divided for hyperparam optimization.\n",
    "            x = data_mod_x[trn_subj_idx]             # Data to be used to create a model for TEST subject\n",
    "            x_test_subj = data_mod_x[tst_subj_idx]\n",
    "            y = data_mod_y[trn_subj_idx]\n",
    "            y_test_subj = data_mod_y[tst_subj_idx]\n",
    "            subjects_cv = data_participant[trn_subj_idx].values\n",
    "            subject_in_test_set = np.unique(data_participant[tst_subj_idx].values)[0]   # Store the participant id in the test set\n",
    "            \n",
    "            # print(f\"TRAIN SUBJECT IDS: {np.unique(subjects_cv)} \\t TEST SUBJECT: {subject_in_test_set}\")\n",
    "            # print(f\"SHAPE : x:{x.shape}, x_test_subj:{x_test_subj.shape}, y:{y.shape}, y_test_subj:{y_test_subj.shape}, subjects_cv:{subjects_cv.shape}\")\n",
    "\n",
    "            # Create pipeline\n",
    "            scaler = StandardScaler().fit(x)\n",
    "            x_scaled = scaler.transform(x)\n",
    "\n",
    "            for clf_name, clf_data in classifiers_hyperparams.items(): \n",
    "                # clf_name = \"GaussianSVM\"\n",
    "                # clf_data = classifiers_hyperparams[clf_name]\n",
    "                #### ABOVE FOR TESTING\n",
    "\n",
    "                clf = clf_data[\"clf\"]\n",
    "                pgrid = clf_data[\"pgrid\"]\n",
    "                                \n",
    "                # Leave-One-Subject-Out CV also to optimize the hyperparameters and select a model\n",
    "                cv_loso_fold = LeaveOneGroupOut()\n",
    "                cv_fold_per_subject = cv_loso_subj.split(x, y, groups = subjects_cv)\n",
    "\n",
    "                gr_search = GridSearchCV(clf, pgrid, cv=cv_fold_per_subject, scoring=SCORING_METRICS, refit=\"accuracy\", n_jobs=1)\n",
    "                gr_search.fit(x_scaled, y)\n",
    "\n",
    "                # Get results per fold and add best results\n",
    "                df_this_hyperparam_optim = pd.DataFrame(gr_search.cv_results_)\n",
    "                df_this_hyperparam_optim.insert(0,\"best_trn_score_\", str(gr_search.best_score_))\n",
    "                df_this_hyperparam_optim.insert(0,\"best_params_\", str(gr_search.best_params_))\n",
    "                df_this_hyperparam_optim.insert(0,\"best_estimator_\", str(gr_search.best_estimator_))\n",
    "\n",
    "                # Insert general information in long format\n",
    "                df_this_hyperparam_optim.insert(0,\"classifier\", clf_name)\n",
    "                df_this_hyperparam_optim.insert(0, \"test_subject_id\",subject_in_test_set)\n",
    "                df_this_hyperparam_optim.insert(0, \"data_modality\", modality_name)\n",
    "                df_this_hyperparam_optim.insert(0, \"pipeline_step\", \"hyperparam_opt\")\n",
    "\n",
    "                # Append to the main dataframe with the results \n",
    "                df_results_hyperparam_opt = df_this_hyperparam_optim if (df_results_hyperparam_opt is None) else pd.concat([df_results_hyperparam_opt, df_this_hyperparam_optim], axis=0, ignore_index=True)\n",
    "                \n",
    "                print(f\"Data modality: {modality_name} | Clf: {clf_name} | Subject: {subject_in_test_set} \")\n",
    "\n",
    "                # Saving .csv\n",
    "                df_results_hyperparam_opt.to_csv( output_filename, index=False)\n",
    "\n",
    "            # End of classifiers\n",
    "        # End of subjects\n",
    "\n",
    "        # # Saving .csv every iteration\n",
    "        # df_results_hyperparam_opt.to_csv( output_filename )\n",
    "    print(\"\\n\\n End\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_hyperparam_opt.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over participants to know the best model per subject and its hyperparams.\n",
    "for participant in df_results_hyperparam_opt.test_subject_id.unique():\n",
    "    # participant = 0\n",
    "    # for clf_name, clf_data in classifiers_hyperparams.items():\n",
    "    query = ((df_results_hyperparam_opt.test_subject_id == participant) & \\\n",
    "                # (df_results_hyperparam_opt.rank_test_accuracy == 1) & \\\n",
    "                # (df_results_hyperparam_opt.classifier == clf_name) & \\\n",
    "                    (df_results_hyperparam_opt.data_modality == \"all\") )\n",
    "    best_results_participant = df_results_hyperparam_opt[ query ]\n",
    "    best_classifier_gridsearch = best_results_participant[ best_results_participant.mean_test_accuracy == best_results_participant.mean_test_accuracy.max() ]\n",
    "    best_clf_name = best_classifier_gridsearch.classifier\n",
    "    \n",
    "    # Apply the classification on the test subject\n",
    "    print(f\"P{participant} - Best clf: {best_clf_name}\\n\\tBest performance {best_classifier_gridsearch.mean_test_accuracy.values}\\n\\tBest params {best_classifier_gridsearch.params.values}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots and tables\n",
    "\n",
    "1. What is the mean/std accuracy/f1-score across the 39 participants?\n",
    "2. What is the mean f1-score of each classifier (best at hyperparam optimization process) per data modality among the 39 participants?\n",
    "3. Best combination of classifier/data modality per participant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the results based on the hyperparameters combination with highest f1-score\n",
    "df_summary_classif = df_results_hyperparam_opt[ (df_results_hyperparam_opt.rank_test_f1_macro == 1) ]\n",
    "df_summary_classif.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of test results\n",
    "data_results_main = df_summary_classif.groupby([\"test_subject_id\", \"data_modality\",\"classifier\"]).first()[ [\"mean_test_accuracy\",\"mean_test_f1_macro\"] ]\n",
    "data_results_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns\n",
    "data_results_main = data_results_main.reset_index()\n",
    "data_results_main.columns = [\"Subject\", \"Data Modality\", \"Classifier\", \"Accuracy\", \"F1-score\"]\n",
    "data_results_main[\"Data Modality\"].replace( dict(zip([\"all\",\"emg_amp\",\"emg_cont\",\"hrv\",\"imu\"],[\"All\",\"EMG A\", \"EMG C\", \"HRV\", \"IMU\"])), inplace=True )\n",
    "data_results_main = data_results_main.set_index([\"Subject\", \"Data Modality\", \"Classifier\"])\n",
    "data_results_main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table with scores per data modality and classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table = data_results_main.stack().reset_index()\n",
    "df_table = df_table.rename(columns={\"level_3\":\"Metric\",0:\"Value\"})\n",
    "df_table_mean = df_table.groupby([\"Data Modality\",\"Classifier\",\"Metric\"]).mean().drop(\"Subject\",axis=1).unstack([\"Classifier\",\"Metric\"])\n",
    "df_table_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table_std = df_table.groupby([\"Data Modality\",\"Classifier\",\"Metric\"]).std().drop(\"Subject\",axis=1).unstack([\"Classifier\",\"Metric\"])\n",
    "df_table_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to a text\n",
    "df_str_mean = df_table_mean.apply(lambda x: ['%.2f'%v for v in x.values])\n",
    "df_str_std = df_table_std.apply(lambda x: ['%.2f'%v for v in x.values])\n",
    "\n",
    "# df_results = (df_str_mean + \"(\" + df_str_std + \")\")\n",
    "df_results = (df_str_mean)\n",
    "\n",
    "# Rename columns\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate LaTeX table\n",
    "FEATURE_BASED_CLASSIFIERS_RESULTS_FILENAME = gen_path_results(\"results-classification-table_37p_\"+TARGET_AFFECT_DIMENSION, extension=\".tex\")\n",
    "df_results.style.to_latex(FEATURE_BASED_CLASSIFIERS_RESULTS_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean f1-score among participants\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scores across participants\n",
    "df_temp_mean = data_results_main[\"F1-score\"].reset_index()\n",
    "df_temp_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(1, 1, figsize=(9,4))\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.barplot(ax = axes, data = df_temp_mean, x=\"Data Modality\", y=\"F1-score\", hue=\"Classifier\",\n",
    "                errorbar=\"sd\", errwidth=1, capsize=0.1, palette=\"Set1\")\n",
    "# plt.legend(bbox_to_anchor=(0, 1, 1, 0), loc=\"lower left\", mode=\"expand\", ncol=4)\n",
    "plt.xlabel(None)\n",
    "plt.grid(True)\n",
    "plt.ylim([0,1])\n",
    "\n",
    "plt.tight_layout()\n",
    "save_path_plot = gen_path_plot(f\"results-classif-barplot-per-data-modality_37p_\"+TARGET_AFFECT_DIMENSION)\n",
    "plt.savefig(save_path_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best combination data modality/classifier per participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1-score per subject\n",
    "fig,axes = plt.subplots(1, 1, figsize=(11,6))\n",
    "df_heatmap = df_temp_mean.pivot(index=[\"Data Modality\",\"Classifier\"], columns=\"Subject\", values=\"F1-score\")\n",
    "sns.heatmap(df_heatmap, ax=axes, cmap=\"Spectral\", vmin=0, vmax=1, cbar_kws={\"label\": \"F1-score\"})\n",
    "plt.xlabel('Participant ID')\n",
    "plt.ylabel(None)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "save_path_plot = gen_path_plot(f\"results-classif-heatmap-per-subject_37p_\"+TARGET_AFFECT_DIMENSION)\n",
    "plt.savefig(save_path_plot, bbox_inches='tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\">> FINISHED WITHOUT ERRORS!!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "metadata": {
   "interpreter": {
    "hash": "f3aec1f4fef7a88c2258d5b84a8b82909f076cff2bcb16988c856ebc42b66954"
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "e8be33a246b23b79b36555b26872bcac753cc5311773880d7b4abb5b9e455248"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
